#!/usr/bin/env python3
"""
BYBIT COPY TRADING SYSTEM - –≠–¢–ê–ü 1 (–û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
–í–µ—Ä—Å–∏—è 5.0 - –í–°–ï WEBSOCKET –ü–†–û–ë–õ–ï–ú–´ –†–ï–®–ï–ù–´!

üéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –ù–ê –û–°–ù–û–í–ï –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:
- ‚úÖ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–´ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–∑ websocket_fixed_functions.py
- ‚úÖ –ó–ê–ú–ï–ù–ï–ù–ê —Ñ—É–Ω–∫—Ü–∏—è is_websocket_open() –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤
- ‚úÖ –ó–ê–ú–ï–ù–ï–ù–ê —Ñ—É–Ω–∫—Ü–∏—è close_websocket_safely() –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤  
- ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û —Å–≤–æ–π—Å—Ç–≤–æ closed –≤ FixedWebSocketManager
- ‚úÖ –î–û–ë–ê–í–õ–ï–ù–ê –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è diagnose_websocket_issue()
- ‚úÖ ws.state.name = "OPEN" - –†–ê–ë–û–ß–ò–ô –ú–ï–¢–û–î –¥–ª—è websockets 15.0.1
- ‚úÖ ws.closed –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢ –≤ websockets 15.0.1 - –ò–°–ü–†–ê–í–õ–ï–ù–û

üîß –†–ï–ó–£–õ–¨–¢–ê–¢: –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å websockets 15.0.1!
"""

import asyncio, random, functools
import time
import json
import hmac
import numpy as np
import hashlib
import logging, logging.handlers
import requests
import websockets
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
from urllib.parse import urlencode
from dataclasses import dataclass
from enum import Enum, auto
import psutil
import gc
from collections import deque, defaultdict, OrderedDict
import traceback
import sys
import weakref
import signal
import os
import statistics
import uuid
import os, socket
from decimal import Decimal
import asyncio
from datetime import timezone

from sys_events_logger import sys_logger
from signals_logger import signals_logger
from positions_db_writer import positions_writer
# from positions_store import positions_store

# –ï–¥–∏–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
SYSTEM_LOGGER_NAME = "bybit_trading_system"
system_logger = logging.getLogger(SYSTEM_LOGGER_NAME)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º –û–î–ò–ù —Ä–∞–∑ –∏ –Ω–µ –¥–∞—ë–º —Å–æ–æ–±—â–µ–Ω–∏—è–º ¬´—É—Ç–µ–∫–∞—Ç—å¬ª –≤–≤–µ—Ä—Ö
if not getattr(system_logger, "_configured", False):
    system_logger.setLevel(logging.INFO)
    system_logger.propagate = False  # –∫–ª—é—á: –Ω–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —Ä–æ–¥–∏—Ç–µ–ª—é

    # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —É–±–µ—Ä—ë–º –ª—é–±—ã–µ —Ä–∞–Ω–µ–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ —Ö–µ–Ω–¥–ª–µ—Ä—ã
    for h in list(system_logger.handlers):
        system_logger.removeHandler(h)

    fmt = logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s")
    sh = logging.StreamHandler()
    sh.setFormatter(fmt)
    system_logger.addHandler(sh)

    # –ø–æ–º–µ—á–∞–µ–º, —á—Ç–æ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–∏–ª–∏, —á—Ç–æ–±—ã –Ω–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
    system_logger._configured = True

# –õ–æ–∫–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ —Ö–µ–Ω–¥–ª–µ—Ä –∏ —Ç–æ–∂–µ –Ω–µ –ø—Ä–æ–ø–∞–≥–∏—Ä—É–µ—Ç
logger = logging.getLogger("enhanced_trading_system_final_fixed")
# –ö–†–ò–¢–ò–ß–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DEBUG –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ API –∏ WS
logger.setLevel(logging.DEBUG)
logger.propagate = False
if not logger.handlers:
    for h in system_logger.handlers:
        logger.addHandler(h)


# ================================
# –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –ò–ú–ü–û–†–¢–´ –ò –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ================================
# 1) –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã: –±–µ—Ä—ë–º recv_window –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞,
#    –∞ –∫–ª—é—á–∏ ‚Äî —Ç–æ–ª—å–∫–æ –∏–∑ –ë–î —á–µ—Ä–µ–∑ CredentialsStore (–æ–±—ë—Ä—Ç–∫–∞ –≤ config.py)
from config import get_api_credentials, BYBIT_RECV_WINDOW, DEFAULT_TRADE_ACCOUNT_ID, BALANCE_ACCOUNT_TYPE, TARGET_ACCOUNT_ID

log = logging.getLogger(__name__)

# 2) Telegram-–∫–æ–Ω—Ñ–∏–≥ (–∫–∞–∫ –∏ –±—ã–ª)
try:
    from telegram_cfg import TELEGRAM_TOKEN, TELEGRAM_CHAT_ID
except Exception as e:
    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å telegram_cfg.py: {e}")
    TELEGRAM_TOKEN = None
    TELEGRAM_CHAT_ID = None

# 3) –ö–∞–∫–∏–º–∏ account_id –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è.
#    TARGET_ACCOUNT_ID ‚Äî –∞–∫–∫–∞—É–Ω—Ç, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –≤—ã—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–¥–µ—Ä–∞ (–¥–µ–º–æ/–ø—Ä–æ–¥).
#    DONOR_ACCOUNT_ID  ‚Äî –∏—Å—Ç–æ—á–Ω–∏–∫ read-only —Å mainnet (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –¥–æ–Ω–æ—Ä—Å–∫–∏–π –ø–æ—Ç–æ–∫/—Å–∏–≥–Ω–∞–ª—ã).
TARGET_ACCOUNT_ID = int(os.getenv("TARGET_ACCOUNT_ID", str(DEFAULT_TRADE_ACCOUNT_ID)))
DONOR_ACCOUNT_ID  = int(os.getenv("DONOR_ACCOUNT_ID", "2"))  # –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ .env

# 4) –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –∫–ª—é—á–∏ –∏–∑ –ë–î (AES-GCM).
#    –í–∞–∂–Ω–æ: –ë–û–õ–¨–®–ï –ù–ï –ü–ê–î–ê–ï–ú –Ω–∞ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è, –µ—Å–ª–∏ –∫–ª—é—á–µ–π –Ω–µ—Ç.
#    –î–∞—ë–º –º–æ–¥—É–ª—é –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –≤ SETUP MODE, —á—Ç–æ–±—ã –∏—Ö –≤–≤–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ /keys.
_creds_target = get_api_credentials(TARGET_ACCOUNT_ID)
if not _creds_target:
    os.environ["SETUP_MODE_NO_KEYS"] = "1"
    MAIN_API_KEY = None
    MAIN_API_SECRET = None
    log.warning(
        "–ö–ª—é—á–∏ –≤ –ë–î –¥–ª—è TARGET_ACCOUNT_ID=%s –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–ø—É—Å–∫ –≤ SETUP MODE. "
        "–í–≤–µ–¥–∏—Ç–µ –∏—Ö —á–µ—Ä–µ–∑ /keys –≤ Telegram –∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ü—Ä–∏–º–µ–Ω–∏—Ç—å –±–µ–∑ —Ä–µ—Å—Ç–∞—Ä—Ç–∞¬ª.",
        TARGET_ACCOUNT_ID
    )
else:
    MAIN_API_KEY, MAIN_API_SECRET = _creds_target  # ‚Üê –∏–º–µ–Ω–∞ –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

# –î–æ–Ω–æ—Ä—Å–∫–∏–µ –∫–ª—é—á–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
_creds_donor = get_api_credentials(DONOR_ACCOUNT_ID)
if _creds_donor:
    SOURCE_API_KEY, SOURCE_API_SECRET = _creds_donor
else:
    # –µ—Å–ª–∏ –¥–æ–Ω–æ—Ä –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º None, –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ —Å–º–æ–∂–µ—Ç —ç—Ç–æ —É—á–∏—Ç—ã–≤–∞—Ç—å
    SOURCE_API_KEY = None
    SOURCE_API_SECRET = None

# 5) –ê–¥—Ä–µ—Å–∞/—ç–Ω–¥–ø–æ–π–Ω—Ç—ã ‚Äî –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ .env, –Ω–æ –¥–µ—Ñ–æ–ª—Ç—ã —Ç–µ –∂–µ, —á—Ç–æ –±—ã–ª–∏
ENVIRONMENT = os.getenv("ENVIRONMENT", "dev").lower()
IS_PROD = (ENVIRONMENT == "prod")

# –û—Å–Ω–æ–≤–Ω–æ–π URL –¥–ª—è API
if IS_PROD:
    # –í –ø—Ä–æ–¥–µ –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π API
    MAIN_API_URL = os.getenv("MAIN_API_URL", "https://api.bybit.com")
    SOURCE_API_URL = os.getenv("SOURCE_API_URL", "https://api.bybit.com")
    logger.info("ENVIRONMENT=prod. Using PRODUCTION API endpoints: %s", MAIN_API_URL)
else:
    # –í dev/test –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    MAIN_API_URL = os.getenv("MAIN_API_URL", "https://api-demo.bybit.com")
    SOURCE_API_URL = os.getenv("SOURCE_API_URL", "https://api.bybit.com") # –¥–æ–Ω–æ—Ä –º–æ–∂–µ—Ç –æ—Å—Ç–∞–≤–∞—Ç—å—Å—è –Ω–∞ –ø—Ä–æ–¥–µ
    logger.info("ENVIRONMENT=%s. Using DEMO API endpoint: %s", ENVIRONMENT, MAIN_API_URL)


# WebSocket URLs (Bybit v5)
if IS_PROD:
    SOURCE_WS_URL = os.getenv("SOURCE_WS_URL", "wss://stream.bybit.com/v5/private")
    PUBLIC_WS_URL = os.getenv("PUBLIC_WS_URL", "wss://stream.bybit.com/v5/public/linear")
    logger.info("ENVIRONMENT=prod. Using PRODUCTION WebSocket endpoints.")
else:
    # –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–µ–º–æ-WS, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    SOURCE_WS_URL = os.getenv("SOURCE_WS_URL", "wss://stream-demo.bybit.com/v5/private")
    PUBLIC_WS_URL = os.getenv("PUBLIC_WS_URL", "wss://stream-demo.bybit.com/v5/public/linear")
    logger.info("ENVIRONMENT=%s. Using DEMO WebSocket endpoints.", ENVIRONMENT)

# –¥–∞–ª—å—à–µ –∏–¥—ë—Ç —Ç–≤–æ–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥: RATE_LIMITS, —Ç–∞–π–º–∏–Ω–≥–∏, –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ —Ç.–¥.

# Rate limiting –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
RATE_LIMITS = {
    'rest_per_minute': 120,
    'rest_per_second': 10,
    'websocket_per_second': 10,
    'websocket_connections_max': 5
}

# ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è ping/pong
WEBSOCKET_PING_INTERVAL = 20  # —Å–µ–∫—É–Ω–¥ (—Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Bybit)
WEBSOCKET_PONG_TIMEOUT = 30   # ‚úÖ –£–í–ï–õ–ò–ß–ï–ù–û –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
WEBSOCKET_TIMEOUT = 15        # —Å–µ–∫—É–Ω–¥ –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π
RECONNECT_DELAYS = [1, 2, 5, 10, 30, 60]  # Exponential backoff
MAX_RECONNECT_ATTEMPTS = 10

# Production –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
PRODUCTION_CONFIG = {
    'max_memory_mb': 1000,
    'max_queue_size': 500,
    'health_check_interval': 60,
    'stats_report_interval': 300,
    'cleanup_interval': 3600
}

class DataState(Enum):
    OK = auto()
    STALE = auto()
    UNAVAILABLE = auto()

class RiskDataContext:
    def __init__(self, cfg):
        self.cfg = cfg
        self.dd_percent = 0.0
        self.daily_dd_percent = 0.0
        self.high_watermark: Optional[float] = None
        self._last_valid_equity: Optional[float] = None
        self.last_equity_ok_ts = 0.0
        self.equity_state = DataState.UNAVAILABLE
        self._dd_hits = 0

    def update_equity(self, equity: Optional[float]) -> None:
        now = time.time()
        if equity is None:
            self.equity_state = (
                DataState.UNAVAILABLE if now - self.last_equity_ok_ts > self.cfg.SAFE_MODE["data_stale_ttl_sec"]
                else DataState.STALE
            )
            self._dd_hits = 0
            return
        self.equity_state = DataState.OK
        self.last_equity_ok_ts = now
        self._last_valid_equity = equity
        if self.high_watermark is None:
            self.high_watermark = equity
        self.high_watermark = max(self.high_watermark, equity)
        if self.high_watermark > 0:
            self.dd_percent = max(0.0, (self.high_watermark - equity) / self.high_watermark)
        else:
            self.dd_percent = 0.0

    def update_daily_dd(self, daily_equity: Optional[float], daily_high: Optional[float]) -> None:
        if daily_equity and daily_high and daily_high > 0:
            self.daily_dd_percent = max(0.0, (daily_high - daily_equity) / daily_high)

    def dd_confirmed(self, positional_dd: Optional[float] = None) -> bool:
        if self.equity_state is not DataState.OK:
            self._dd_hits = 0
            return False
        dd2 = self.dd_percent if positional_dd is None else positional_dd
        if self.dd_percent >= self.cfg.RISK["drawdown_limit"] and dd2 >= self.cfg.RISK["drawdown_limit"]:
            self._dd_hits += 1
        else:
            self._dd_hits = 0
        return self._dd_hits >= self.cfg.SAFE_MODE["risk_confirm_reads"]

    def is_data_reliable(self) -> bool:
        return self.equity_state is DataState.OK

class SystemMode(Enum):
    RUNNING = "RUNNING"
    SAFE_MODE = "SAFE_MODE"
    EMERGENCY_STOP = "EMERGENCY_STOP"

class HealthSupervisor:
    
    def __init__(self, cfg, risk_ctx: RiskDataContext, notifier=None):
        self.cfg = cfg
        self.risk = risk_ctx
        self.notifier = notifier
        self.mode = SystemMode.RUNNING
        self.fail_consecutive = 0
        self.copy_enabled = True

    async def on_api_failure(self, reason: str):
        self.fail_consecutive += 1
        if (self.cfg.SAFE_MODE["enabled"]
            and self.mode is SystemMode.RUNNING
            and (self.fail_consecutive >= self.cfg.SAFE_MODE["network_error_tolerance"]
                 or not self.risk.is_data_reliable())):
            await self.enter_safe_mode(f"API degraded: {reason}")
        if (self.fail_consecutive >= self.cfg.SAFE_MODE["api_retry_limit"]
            and self.risk.dd_confirmed()):
            await self.trigger_emergency_stop("API degraded + confirmed DD")

    async def on_api_success(self):
        if self.fail_consecutive:
            self.fail_consecutive = 0
        if self.mode is SystemMode.SAFE_MODE and self.risk.is_data_reliable():
            self.mode = SystemMode.RUNNING
            self.copy_enabled = True
            await self._notify("‚úÖ SAFE MODE exited: API recovered, data OK.")

    async def enter_safe_mode(self, msg: str):
        if self.mode is SystemMode.SAFE_MODE:
            return
        self.mode = SystemMode.SAFE_MODE
        self.copy_enabled = False
        await self._notify(f"‚ö†Ô∏è SAFE MODE: {msg}. New entries paused, protection stays active.")

    async def trigger_emergency_stop(self, reason: str):
        if self.mode is SystemMode.EMERGENCY_STOP:
            return
        self.mode = SystemMode.EMERGENCY_STOP
        self.copy_enabled = False
        await self._notify(f"üõë EMERGENCY STOP: {reason}")

    def can_open_positions(self) -> bool:
        return self.mode is SystemMode.RUNNING and self.copy_enabled

    async def _notify(self, text: str):
        try:
            logger.warning(text)
            if self.notifier:
                await self.notifier(text)
        except Exception:
            pass

    def async_retry(retries=None, base=None, factor=None, max_delay=None, retriable=(asyncio.TimeoutError, OSError)):
        # –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config.SAFE_MODE
        from config import SAFE_MODE as _SM
        retries = _SM["api_retry_limit"] if retries is None else retries
        base = _SM["api_backoff_base"] if base is None else base
        factor = _SM["api_backoff_factor"] if factor is None else factor
        max_delay = _SM["api_backoff_max"] if max_delay is None else max_delay

        def decorator(func):
            @functools.wraps(func)
            async def wrapper(*a, **kw):
                delay = base
                last = None
                for attempt in range(retries):
                    try:
                        return await func(*a, **kw)
                    except retriable as e:
                        last = e
                        if attempt == retries - 1:
                            logger.error("%s failed after %d attempts: %s", func.__name__, retries, e)
                            raise
                        jitter = random.random() * 0.2 * delay
                        sleep_sec = min(delay + jitter, max_delay)
                        logger.warning("%s attempt %d/%d failed: %s. Retry in %.2fs",
                                       func.__name__, attempt+1, retries, e, sleep_sec)
                        await asyncio.sleep(sleep_sec)
                        delay = min(delay * factor, max_delay)
                raise last
            return wrapper
        return decorator

# ================================
# 1.4 PRODUCTION LOGGING SYSTEM
# ================================

class ProductionLogger:
    """
    üìù ENTERPRISE-GRADE –°–ò–°–¢–ï–ú–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
    
    –§—É–Ω–∫—Ü–∏–∏:
    - Structured JSON logging –¥–ª—è machine parsing
    - Log rotation —Å compression
    - Centralized logging ready
    - Performance metrics integration
    - Real-time error alerting
    """
    
    def __init__(self, 
                 app_name: str = "bybit_trading_system",
                 log_level: str = "INFO",
                 enable_rotation: bool = True,
                 enable_json: bool = True,
                 enable_metrics: bool = True):
        
        self.app_name = app_name
        self.enable_json = enable_json
        self.enable_metrics = enable_metrics
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.log_dir = "logs"
        self.metrics_dir = "metrics" 
        os.makedirs(self.log_dir, exist_ok=True)
        os.makedirs(self.metrics_dir, exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π logger
        self.logger = logging.getLogger(app_name)
        self.logger.setLevel(getattr(logging, log_level.upper()))
        
        # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
        self.logger.handlers.clear()
        
        # –î–æ–±–∞–≤–ª—è–µ–º handlers
        self._setup_console_handler()
        if enable_rotation:
            self._setup_file_handlers()
        
        # Metrics tracking
        if enable_metrics:
            self.metrics = LogMetrics()
        
        # Error alerting
        self.error_alerter = ErrorAlerter()
        
        logger.info(f"Production logging initialized for {app_name}")
    
    def _setup_console_handler(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞"""
        console_handler = logging.StreamHandler(sys.stdout)
        
        if self.enable_json:
            formatter = JSONFormatter()
        else:
            formatter = logging.Formatter(
                '%(asctime)s [%(levelname)8s] %(name)s: %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
        
        console_handler.setFormatter(formatter)
        console_handler.setLevel(logging.INFO)
        self.logger.addHandler(console_handler)
    
    def _setup_file_handlers(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∞–π–ª–æ–≤—ã—Ö handlers —Å rotation"""
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥ —Å rotation
        main_handler = logging.handlers.RotatingFileHandler(
            filename=f"{self.log_dir}/{self.app_name}.log",
            maxBytes=50*1024*1024,  # 50MB
            backupCount=10,
            encoding='utf-8'
        )
        
        # –õ–æ–≥ –æ—à–∏–±–æ–∫
        error_handler = logging.handlers.RotatingFileHandler(
            filename=f"{self.log_dir}/{self.app_name}_errors.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        
        # Performance metrics –ª–æ–≥
        perf_handler = logging.handlers.TimedRotatingFileHandler(
            filename=f"{self.log_dir}/{self.app_name}_performance.log",
            when='H',  # Hourly rotation
            interval=1,
            backupCount=24*7,  # –ù–µ–¥–µ–ª—è –¥–∞–Ω–Ω—ã—Ö
            encoding='utf-8'
        )
        
        # JSON —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä—ã –¥–ª—è structured logging
        if self.enable_json:
            json_formatter = JSONFormatter()
            main_handler.setFormatter(json_formatter)
            error_handler.setFormatter(json_formatter)
            perf_handler.setFormatter(json_formatter)
        else:
            standard_formatter = logging.Formatter(
                '%(asctime)s [%(levelname)8s] %(name)s:%(lineno)d - %(message)s'
            )
            main_handler.setFormatter(standard_formatter)
            error_handler.setFormatter(standard_formatter)
            perf_handler.setFormatter(standard_formatter)
        
        # –î–æ–±–∞–≤–ª—è–µ–º handlers
        self.logger.addHandler(main_handler)
        self.logger.addHandler(error_handler)
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–π logger –¥–ª—è performance
        self.perf_logger = logging.getLogger(f"{self.app_name}.performance")
        self.perf_logger.addHandler(perf_handler)
        self.perf_logger.setLevel(logging.INFO)
    
    def log_performance(self, 
                       operation: str,
                       duration: float,
                       success: bool,
                       metadata: Dict[str, Any] = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ performance –º–µ—Ç—Ä–∏–∫"""
        if not self.enable_metrics:
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        self.metrics.record_operation(operation, duration, success)
        
        # Structured log entry
        log_entry = {
            'event_type': 'performance',
            'operation': operation,
            'duration_ms': round(duration * 1000, 2),
            'success': success,
            'timestamp': datetime.utcnow().isoformat(),
            'metadata': metadata or {}
        }
        
        if hasattr(self, 'perf_logger'):
            self.perf_logger.info(json.dumps(log_entry))
    
    def log_error(self, 
                  error: Exception,
                  context: Dict[str, Any] = None,
                  send_alert: bool = True):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ —Å alerting"""
        
        error_info = {
            'event_type': 'error',
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback.format_exc(),
            'context': context or {},
            'timestamp': datetime.utcnow().isoformat(),
            'severity': self.error_alerter._classify_error_severity(error)
        }
        
        # –õ–æ–≥–∏—Ä—É–µ–º
        self.logger.error(json.dumps(error_info) if self.enable_json else error_info['error_message'])
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º alert –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫
        if send_alert and error_info['severity'] in ['high', 'critical']:
            asyncio.create_task(self.error_alerter.send_alert(error_info))

class JSONFormatter(logging.Formatter):
    """JSON —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è structured logging"""
    
    def format(self, record):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º exception info –µ—Å–ª–∏ –µ—Å—Ç—å
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        # –î–æ–±–∞–≤–ª—è–µ–º extra fields –µ—Å–ª–∏ –µ—Å—Ç—å
        for key, value in record.__dict__.items():
            if key not in ['name', 'msg', 'args', 'levelname', 'levelno', 'pathname', 
                          'filename', 'module', 'lineno', 'funcName', 'created', 
                          'msecs', 'relativeCreated', 'thread', 'threadName', 
                          'processName', 'process', 'getMessage', 'exc_info', 'exc_text']:
                log_entry[key] = value
        
        return json.dumps(log_entry, ensure_ascii=False)

class LogMetrics:
    """–°–±–æ—Ä –∏ –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.operation_stats = defaultdict(lambda: {
            'count': 0,
            'success_count': 0,
            'total_duration': 0,
            'max_duration': 0,
            'min_duration': float('inf')
        })
        
        self.error_counts = defaultdict(int)
        self.performance_history = deque(maxlen=1000)
    
    def record_operation(self, operation: str, duration: float, success: bool):
        """–ó–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        stats = self.operation_stats[operation]
        stats['count'] += 1
        stats['total_duration'] += duration
        
        if success:
            stats['success_count'] += 1
        
        stats['max_duration'] = max(stats['max_duration'], duration)
        stats['min_duration'] = min(stats['min_duration'], duration)
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤
        self.performance_history.append({
            'operation': operation,
            'duration': duration,
            'success': success,
            'timestamp': time.time()
        })
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–¥–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        summary = {}
        
        for operation, stats in self.operation_stats.items():
            if stats['count'] > 0:
                avg_duration = stats['total_duration'] / stats['count']
                success_rate = stats['success_count'] / stats['count']
                
                summary[operation] = {
                    'total_calls': stats['count'],
                    'success_rate': round(success_rate * 100, 2),
                    'avg_duration_ms': round(avg_duration * 1000, 2),
                    'max_duration_ms': round(stats['max_duration'] * 1000, 2),
                    'min_duration_ms': round(stats['min_duration'] * 1000, 2)
                }
        
        return summary

class ErrorAlerter:
    """–°–∏—Å—Ç–µ–º–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ alerts –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫"""
    
    def __init__(self):
        self.alert_cooldown = 300  # 5 –º–∏–Ω—É—Ç –º–µ–∂–¥—É –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∞–ª–µ—Ä—Ç–∞–º–∏
        self.recent_alerts = {}
    
    async def send_alert(self, error_info: Dict[str, Any]):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ alert"""
        try:
            # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤
            alert_key = f"{error_info['error_type']}:{error_info.get('operation', 'unknown')}"
            now = time.time()
            
            if alert_key in self.recent_alerts:
                if now - self.recent_alerts[alert_key] < self.alert_cooldown:
                    return  # –°–ª–∏—à–∫–æ–º —Ä–∞–Ω–æ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–ª–µ—Ä—Ç–∞
            
            self.recent_alerts[alert_key] = now
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            alert_message = self._format_alert_message(error_info)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
            await self._send_telegram_alert(alert_message)
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –∫–∞–Ω–∞–ª—ã (email, Slack, etc.)
            
        except Exception as e:
            # –ê–ª–µ—Ä—Ç—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –ª–æ–º–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –ª–æ–≥–∏–∫—É
            logging.getLogger('error_alerter').error(f"Failed to send alert: {e}")
    
    def _format_alert_message(self, error_info: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∞–ª–µ—Ä—Ç–∞"""
        severity_emoji = {
            'critical': 'üö®',
            'high': '‚ö†Ô∏è',
            'medium': 'üî∂',
            'low': '‚ÑπÔ∏è'
        }
        
        emoji = severity_emoji.get(error_info['severity'], '‚ùó')
        
        message = f"""{emoji} **TRADING SYSTEM ALERT** {emoji}

**Severity:** {error_info['severity'].upper()}
**Error:** {error_info['error_type']}
**Message:** {error_info['error_message']}
**Time:** {error_info['timestamp']}

**Context:** {json.dumps(error_info.get('context', {}), indent=2)}
"""
        
        return message
    
    def _classify_error_severity(self, error: Exception) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏"""
        try:
            error_type = type(error).__name__
            error_message = str(error).lower()
        
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ - —Ç—Ä–µ–±—É—é—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è
            critical_errors = [
                'ConnectionError', 'TimeoutError', 'AuthenticationError',
                'ConnectionResetError', 'ConnectionRefusedError', 'OSError'
            ]
        
            # –í—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏ - –≤–ª–∏—è—é—Ç –Ω–∞ —Ç–æ—Ä–≥–æ–≤–ª—é
            high_errors = [
                'RateLimitError', 'APIError', 'ValidationError', 'HTTPError',
                'InvalidSignatureError', 'InsufficientBalanceError'
            ]
        
            # –°—Ä–µ–¥–Ω–∏–µ –æ—à–∏–±–∫–∏ - —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è –Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã
            medium_errors = [
                'ValueError', 'KeyError', 'TypeError', 'AttributeError',
                'JSONDecodeError', 'ParseError'
            ]
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ç–∏–ø—É –æ—à–∏–±–∫–∏
            if error_type in critical_errors:
                return 'critical'
            elif error_type in high_errors:
                return 'high'
            elif error_type in medium_errors:
                return 'medium'
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è
            critical_keywords = [
                'connection refused', 'connection reset', 'network unreachable',
                'authentication failed', 'invalid api key', 'signature verification failed',
                'server error', 'internal server error', 'service unavailable'
            ]
        
            high_keywords = [
                'rate limit', 'too many requests', 'quota exceeded',
                'insufficient balance', 'position not found', 'order failed',
                'market closed', 'trading suspended'
            ]
        
            medium_keywords = [
                'invalid parameter', 'missing field', 'validation error',
                'parse error', 'format error', 'data error'
            ]
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            for keyword in critical_keywords:
                if keyword in error_message:
                    return 'critical'
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            for keyword in high_keywords:
                if keyword in error_message:
                    return 'high'
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            for keyword in medium_keywords:
                if keyword in error_message:
                    return 'medium'
        
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if 'network' in error_message or 'connection' in error_message:
                return 'high'
            elif 'websocket' in error_message or 'socket' in error_message:
                return 'high'
            elif 'bybit' in error_message or 'api' in error_message:
                return 'medium'
        
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            return 'low'
        
        except Exception as classification_error:
            # –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
            logger.debug(f"Error classification failed: {classification_error}")
            return 'medium'

    async def _send_telegram_alert(self, message: str):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é send_telegram_alert
        # –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –µ—Å—Ç—å –≤ —Å–∏—Å—Ç–µ–º–µ
        try:
            # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å circular import
            from enhanced_trading_system_final_fixed import send_telegram_alert
            await send_telegram_alert(message)
        except Exception as e:
            logger.debug(f"Telegram alert failed: {e}")

# ================================
# –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
# ================================

try:
    # –°–æ–∑–¥–∞–µ–º Production Logger
    prod_logger = ProductionLogger(
        app_name="bybit_trading_system",
        log_level="INFO",
        enable_rotation=True,
        enable_json=False,  # –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        enable_metrics=True
    )
    
    # –°–æ–∑–¥–∞–µ–º –∞–ª–∏–∞—Å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    logger = prod_logger.logger
    
    logger.info("‚úÖ Production logging system initialized successfully")
    
except Exception as init_error:
    # Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—é
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
    )
    logger = logging.getLogger(__name__)
    
    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è prod_logger
    class DummyProdLogger:
        def __init__(self, fallback_logger):
            self.logger = fallback_logger
            self.metrics = None
        def log_performance(self, *args, **kwargs): pass
        def log_error(self, error, context=None, send_alert=False):
            self.logger.error(f"Error: {error}")
    
    prod_logger = DummyProdLogger(logger)
    logger.warning(f"Fallback logging due to: {init_error}")


class CircuitState(Enum):
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Circuit tripped, failing fast
    HALF_OPEN = "half_open"  # Testing if service recovered

@dataclass
class CircuitBreakerConfig:
    failure_threshold: int = 5          # Failures before opening
    recovery_timeout: int = 60          # Seconds before trying again
    expected_exception: Exception = Exception
    half_open_max_calls: int = 3        # Max calls in half-open state

class EnterpriseBybitConnector:
    """
    üè≠ ENTERPRISE-GRADE CONNECTION MANAGER
    
    Solves API performance issues with optimized connection pooling
    and intelligent request distribution for Bybit API.
    
    Based on Bybit specifications:
    - 600 requests per 5 seconds (institutional limit)
    - 500 connections per 5 minutes maximum
    - AWS Singapore hosting optimization
    """
    
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        self.connector: Optional[aiohttp.TCPConnector] = None
        self._setup_enterprise_connector()
        
        # Performance tracking
        self.connection_stats = {
            'total_requests': 0,
            'reused_connections': 0,
            'new_connections': 0,
            'avg_response_time': 0.0,
            'connection_pool_hits': 0,
            'connection_pool_misses': 0,
            'active_connections': 0,
            'max_connections_used': 0
        }
        
        # Connection health monitoring
        self.health_metrics = {
            'successful_requests': 0,
            'failed_requests': 0,
            'timeout_errors': 0,
            'connection_errors': 0,
            'last_health_check': time.time()
        }
        
        logger.info("EnterpriseBybitConnector initialized with optimized settings")
    
    def _setup_enterprise_connector(self):
        """Setup production-grade TCP connector based on Bybit specifications"""
    
        try:
            # FIXED: Remove unsupported parameters for aiohttp TCPConnector
            self.connector = aiohttp.TCPConnector(
                limit=200,                    # Total connections
                limit_per_host=50,           # Per-host limit  
                ttl_dns_cache=300,           # DNS cache TTL (5 minutes)
                use_dns_cache=True,          # Enable DNS caching
                keepalive_timeout=30,        # Keep connections alive for 30s
                enable_cleanup_closed=True,  # Clean up closed connections
                force_close=False,           # Reuse connections (critical)
                #ssl=True                     # Enable SSL for HTTPS
            )
        
            logger.info("Enterprise TCP connector configured successfully for Bybit API")
        
        except Exception as e:
            logger.error(f"Failed to create enterprise TCP connector: {e}")
            # CRITICAL FIX: Set connector to None to trigger fallback
            self.connector = None

    async def create_session(self) -> aiohttp.ClientSession:
        """
        Create enterprise-grade session with optimized settings
    
        Returns:
            aiohttp.ClientSession: Optimized session for Bybit API
        """
    
        # CRITICAL FIX: Check if connector exists
        if self.connector is None:
            logger.warning("Enterprise connector is None, creating basic session")
            # Create basic session without connector
            timeout = aiohttp.ClientTimeout(
                total=30.0,
                connect=10.0,
                sock_read=20.0
            )
        
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                headers={'User-Agent': 'Bybit-Trading-Bot-Basic/1.0'}
            )
        
            self.connection_stats['new_connections'] += 1
            self.connection_stats['connection_pool_misses'] += 1
        
            logger.warning("Created basic session without enterprise connector")
            return self.session
    
        if self.session and not self.session.closed:
            # Session reuse - update stats
            self.connection_stats['reused_connections'] += 1
            self.connection_stats['connection_pool_hits'] += 1
            return self.session
    
        # Create new session - update stats
        self.connection_stats['new_connections'] += 1
        self.connection_stats['connection_pool_misses'] += 1
    
        # CRITICAL FIX: Optimized timeout configuration for Bybit API
        timeout = aiohttp.ClientTimeout(
            total=60,           # Total request timeout (increased for stability)
            connect=10,         # Connection establishment timeout  
            sock_connect=5,     # Socket connection timeout
            sock_read=30        # Socket read timeout
        )
    
        try:
            # Create session with enterprise connector
            self.session = aiohttp.ClientSession(
                connector=self.connector,
                timeout=timeout,
            
                # Performance optimizations
                headers={
                    'User-Agent': 'Bybit-Enterprise-Trading-Bot/2.0',
                    'Accept': 'application/json',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive'
                },
            
                # Error handling
                raise_for_status=False,
                trust_env=True,
            )
        
            # CRITICAL FIX: Safe access to connector stats
            if self.connector and hasattr(self.connector, '_conns'):
                try:
                    active_connections = len(self.connector._conns)
                    self.connection_stats['active_connections'] = active_connections
                    self.connection_stats['max_connections_used'] = max(
                        self.connection_stats['max_connections_used'], 
                        active_connections
                    )
                except Exception as e:
                    logger.debug(f"Could not get connection stats: {e}")
        
            logger.info(f"Enterprise session created successfully")
            return self.session
        
        except Exception as e:
            logger.error(f"Failed to create enterprise session: {e}")
        
            # Fallback to basic session
            timeout = aiohttp.ClientTimeout(
                total=30.0,
                connect=10.0,
                sock_read=20.0
            )
        
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                headers={'User-Agent': 'Bybit-Trading-Bot-Fallback/1.0'}
            )
        
            logger.warning("Created fallback session due to enterprise session failure")
            return self.session
    
    async def close(self):
        """Graceful cleanup of connections with proper resource management"""
        try:
            # Close session first
            if self.session and not self.session.closed:
                await self.session.close()
                logger.debug("Enterprise session closed")
            
            # Close connector
            if self.connector:
                await self.connector.close()
                logger.debug("Enterprise connector closed")
            
            # Give time for connections to close properly (important for cleanup)
            await asyncio.sleep(0.1)
            
            # Reset references
            self.session = None
            self.connector = None
            
            logger.info("Enterprise connector cleanup completed")
            
        except Exception as e:
            logger.error(f"Error during enterprise connector cleanup: {e}")
            # Don't raise - cleanup should be fault-tolerant
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status of the connector"""
        
        total_requests = (self.health_metrics['successful_requests'] + 
                         self.health_metrics['failed_requests'])
        
        success_rate = 0.0
        if total_requests > 0:
            success_rate = (self.health_metrics['successful_requests'] / total_requests) * 100
        
        connection_efficiency = 0.0
        if self.connection_stats['total_requests'] > 0:
            connection_efficiency = (self.connection_stats['reused_connections'] / 
                                   self.connection_stats['total_requests']) * 100
        
        return {
            'status': 'healthy' if success_rate > 90 else 'degraded' if success_rate > 50 else 'unhealthy',
            'success_rate_pct': success_rate,
            'connection_efficiency_pct': connection_efficiency,
            'active_connections': self.connection_stats['active_connections'],
            'max_connections_used': self.connection_stats['max_connections_used'],
            'total_requests': total_requests,
            'avg_response_time': self.connection_stats['avg_response_time'],
            'last_health_check': self.health_metrics['last_health_check']
        }
    
    def update_health_metrics(self, success: bool, response_time: float, error_type: str = None):
        """Update health metrics after each request"""
        
        if success:
            self.health_metrics['successful_requests'] += 1
        else:
            self.health_metrics['failed_requests'] += 1
            
            # Categorize error types
            if error_type:
                if 'timeout' in error_type.lower():
                    self.health_metrics['timeout_errors'] += 1
                elif 'connection' in error_type.lower():
                    self.health_metrics['connection_errors'] += 1
        
        # Update average response time (exponential moving average)
        alpha = 0.1
        if self.connection_stats['avg_response_time'] == 0:
            self.connection_stats['avg_response_time'] = response_time
        else:
            self.connection_stats['avg_response_time'] = (
                alpha * response_time + 
                (1 - alpha) * self.connection_stats['avg_response_time']
            )
        
        self.health_metrics['last_health_check'] = time.time()


class NetworkResilienceManager:
    """
    üõ°Ô∏è NETWORK RESILIENCE MANAGER
    
    CRITICAL FIX: Implements circuit breaker pattern with intelligent retry logic
    for handling Bybit API connectivity issues. Solves Network Timeout failures.
    
    Features:
    - Circuit breaker pattern (Closed/Open/Half-Open states)
    - Adaptive timeout calculation based on network health
    - Exponential backoff with jitter
    - Network health tracking and monitoring
    - Intelligent failure categorization
    """
    
    def __init__(self, config: CircuitBreakerConfig = CircuitBreakerConfig()):
        self.config = config
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.last_failure_time = 0
        self.half_open_calls = 0
        
        # Network health tracking
        self.network_health = {
            'consecutive_successes': 0,
            'consecutive_failures': 0,
            'avg_response_time': 0.0,
            'total_requests': 0,
            'success_rate': 100.0,
            'last_success_time': time.time(),
            'last_failure_time': 0
        }
        
        # Failure analysis
        self.failure_analysis = {
            'timeout_errors': 0,
            'connection_errors': 0,
            'http_errors': 0,
            'api_errors': 0,
            'unknown_errors': 0
        }
        
        # Performance metrics
        self.performance_metrics = {
            'fastest_response': float('inf'),
            'slowest_response': 0.0,
            'response_times': deque(maxlen=100),  # Last 100 response times
            'hourly_success_rate': 100.0,
            'circuit_breaker_activations': 0
        }
        
        logger.info("Network Resilience Manager initialized with circuit breaker pattern")
    
    async def call_with_circuit_breaker(self, func: Callable, *args, **kwargs) -> Any:
        """
        Execute function with circuit breaker protection
    
        Args:
            func: Function to execute with protection
            *args: Function arguments
            **kwargs: Function keyword arguments
        
        Returns:
            Any: Result of function execution
        
        Raises:
            Exception: If circuit is open or function fails after retries
        """
    
        # Check circuit state
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time < self.config.recovery_timeout:
                self.performance_metrics['circuit_breaker_activations'] += 1
                raise Exception(f"Circuit breaker OPEN - failing fast. Recovery in {self.config.recovery_timeout - (time.time() - self.last_failure_time):.1f}s")
            else:
                # Transition to half-open for testing
                self.state = CircuitState.HALF_OPEN
                self.half_open_calls = 0
                logger.info("Circuit breaker transitioning to HALF_OPEN for testing")
    
        # Execute with timeout and retry logic
        start_time = time.time()
        last_exception = None
    
        for retry_attempt in range(3):  # Max 3 attempts
            try:
                # CRITICAL FIX: Implement graduated timeouts based on network health
                timeout = self._calculate_adaptive_timeout()
            
                # FIXED: Remove retry_attempt from kwargs - not all functions support it
                result = await asyncio.wait_for(func(*args, **kwargs), timeout=timeout)
            
                # Record success
                response_time = time.time() - start_time
                self._record_success(response_time)
            
                return result
            
            except asyncio.TimeoutError as e:
                last_exception = e
                self._record_failure(e, 'timeout')
            
                if retry_attempt < 2:  # Don't wait after last attempt
                    await self._exponential_backoff(retry_attempt)
                
            # FIXED: Replace ClientTimeoutError with ServerTimeoutError
            except aiohttp.ServerTimeoutError as e:
                last_exception = e
                self._record_failure(e, 'server_timeout')
            
                if retry_attempt < 2:
                    await self._exponential_backoff(retry_attempt)
                
            except aiohttp.ClientConnectionError as e:
                last_exception = e
                self._record_failure(e, 'connection')
            
                if retry_attempt < 2:
                    await self._exponential_backoff(retry_attempt)
                
            except aiohttp.ClientResponseError as e:
                last_exception = e
                self._record_failure(e, 'http_response')
            
                # Don't retry on client errors (4xx)
                if hasattr(e, 'status') and 400 <= e.status < 500:
                    break
                
                if retry_attempt < 2:
                    await self._exponential_backoff(retry_attempt)
                
            # FIXED: Catch all aiohttp errors with general ClientError
            except aiohttp.ClientError as e:
                last_exception = e
                self._record_failure(e, 'client_error')
            
                if retry_attempt < 2:
                    await self._exponential_backoff(retry_attempt)
                
            except Exception as e:
                last_exception = e
                self._record_failure(e, 'unknown')
            
                if retry_attempt < 2:
                    await self._exponential_backoff(retry_attempt)
    
        # All retries failed
        total_time = time.time() - start_time
        logger.error(f"All retry attempts failed after {total_time:.2f}s")
        raise last_exception
    
    def _calculate_adaptive_timeout(self) -> float:
        """Calculate adaptive timeout based on network health and performance"""
        base_timeout = 10.0
        
        # Adjust based on average response time
        if self.network_health['avg_response_time'] > 5.0:
            # Slow network detected - increase timeout
            multiplier = min(self.network_health['avg_response_time'] / 5.0, 3.0)
            adaptive_timeout = base_timeout * multiplier
        elif self.network_health['consecutive_failures'] > 2:
            # Multiple failures - reduce timeout for faster failure detection
            adaptive_timeout = max(base_timeout * 0.5, 5.0)
        elif self.network_health['success_rate'] < 50.0:
            # Poor success rate - reduce timeout
            adaptive_timeout = max(base_timeout * 0.7, 5.0)
        else:
            adaptive_timeout = base_timeout
        
        # Ensure reasonable bounds
        return max(min(adaptive_timeout, 30.0), 5.0)
    
    def _record_success(self, response_time: float):
        """Record successful network operation with comprehensive metrics"""
        
        # Reset failure tracking
        self.failure_count = 0
        self.network_health['consecutive_successes'] += 1
        self.network_health['consecutive_failures'] = 0
        self.network_health['last_success_time'] = time.time()
        self.network_health['total_requests'] += 1
        
        # Update response time metrics
        self.performance_metrics['response_times'].append(response_time)
        self.performance_metrics['fastest_response'] = min(
            self.performance_metrics['fastest_response'], response_time
        )
        self.performance_metrics['slowest_response'] = max(
            self.performance_metrics['slowest_response'], response_time
        )
        
        # Update average response time (exponential moving average)
        alpha = 0.1
        if self.network_health['avg_response_time'] == 0:
            self.network_health['avg_response_time'] = response_time
        else:
            self.network_health['avg_response_time'] = (
                alpha * response_time + 
                (1 - alpha) * self.network_health['avg_response_time']
            )
        
        # Calculate success rate
        total_requests = self.network_health['total_requests']
        total_failures = sum(self.failure_analysis.values())
        if total_requests > 0:
            self.network_health['success_rate'] = ((total_requests - total_failures) / total_requests) * 100
        
        # State management for circuit breaker
        if self.state == CircuitState.HALF_OPEN:
            self.half_open_calls += 1
            if self.half_open_calls >= self.config.half_open_max_calls:
                self.state = CircuitState.CLOSED
                logger.info("Circuit breaker CLOSED - service recovered")
        
        # Log performance milestones
        if self.network_health['consecutive_successes'] % 100 == 0:
            logger.info(f"Network health: {self.network_health['consecutive_successes']} consecutive successes, "
                       f"avg response time: {self.network_health['avg_response_time']:.3f}s")
    
    def _record_failure(self, exception: Exception, error_type: str):
        """Record failed network operation with detailed analysis"""
        
        self.failure_count += 1
        self.last_failure_time = time.time()
        self.network_health['consecutive_failures'] += 1
        self.network_health['consecutive_successes'] = 0
        self.network_health['last_failure_time'] = time.time()
        self.network_health['total_requests'] += 1
        
        # Categorize failure type
        if error_type in self.failure_analysis:
            self.failure_analysis[error_type] += 1
        else:
            self.failure_analysis['unknown_errors'] += 1
        
        # Calculate success rate
        total_requests = self.network_health['total_requests']
        total_failures = sum(self.failure_analysis.values())
        if total_requests > 0:
            self.network_health['success_rate'] = ((total_requests - total_failures) / total_requests) * 100
        
        # Circuit breaker state management
        if self.failure_count >= self.config.failure_threshold:
            if self.state != CircuitState.OPEN:
                self.state = CircuitState.OPEN
                self.performance_metrics['circuit_breaker_activations'] += 1
                logger.warning(f"Circuit breaker OPEN - {self.failure_count} failures detected. Error type: {error_type}")
        
        # Log failure patterns
        if self.network_health['consecutive_failures'] % 5 == 0:
            logger.warning(f"Network degradation: {self.network_health['consecutive_failures']} consecutive failures, "
                          f"success rate: {self.network_health['success_rate']:.1f}%")
    
    async def _exponential_backoff(self, attempt: int):
        """Implement exponential backoff with jitter and adaptive delays"""
        
        # Base delay increases exponentially
        base_delay = 1.0 * (2 ** attempt)  # 1s, 2s, 4s, 8s...
        max_delay = 30.0
        
        # Adaptive delay based on network health
        if self.network_health['success_rate'] < 30.0:
            # Very poor network - longer delays
            base_delay *= 2.0
        elif self.network_health['success_rate'] > 80.0:
            # Network mostly good - shorter delays
            base_delay *= 0.5
        
        delay = min(base_delay, max_delay)
        
        # Add jitter (¬±25%) to prevent thundering herd
        jitter_range = delay * 0.25
        jitter = (hash(time.time()) % 100) / 100 * 2 - 1  # -1 to 1
        delay += jitter * jitter_range
        
        # Ensure minimum delay
        delay = max(delay, 0.5)
        
        logger.debug(f"Exponential backoff: waiting {delay:.2f}s (attempt {attempt + 1})")
        await asyncio.sleep(delay)
    
    def get_resilience_report(self) -> Dict[str, Any]:
        """Get comprehensive resilience and performance report"""
        
        # Calculate percentiles for response times
        response_times = list(self.performance_metrics['response_times'])
        percentiles = {}
        if response_times:
            percentiles = {
                'p50': np.percentile(response_times, 50),
                'p95': np.percentile(response_times, 95),
                'p99': np.percentile(response_times, 99)
            }
        
        return {
            'circuit_breaker': {
                'state': self.state.value,
                'failure_count': self.failure_count,
                'activations': self.performance_metrics['circuit_breaker_activations']
            },
            'network_health': self.network_health,
            'failure_analysis': self.failure_analysis,
            'performance': {
                'fastest_response': self.performance_metrics['fastest_response'] if self.performance_metrics['fastest_response'] != float('inf') else 0,
                'slowest_response': self.performance_metrics['slowest_response'],
                'percentiles': percentiles,
                'total_samples': len(response_times)
            }
        }
    
    def reset_circuit_breaker(self):
        """Manually reset circuit breaker (for administrative purposes)"""
        
        previous_state = self.state
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.half_open_calls = 0
        
        logger.info(f"Circuit breaker manually reset from {previous_state.value} to CLOSED")

# ================================
# –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –£–¢–ò–õ–ò–¢–´
# ================================

class ConnectionMonitorPro:
    """
    üì° PRODUCTION-GRADE –ú–û–ù–ò–¢–û–†–ò–ù–ì –°–û–ï–î–ò–ù–ï–ù–ò–ô
    
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ –≤—Å–µ—Ö —Å–µ—Ç–µ–≤—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç
    """
    
    def __init__(self):
        self.connections = {}  # {id: ConnectionState}
        self.health_checkers = {}
        self.recovery_strategies = {}
        self.monitoring_active = False
        
        # Circuit breaker pattern
        self.circuit_breakers = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_connections': 0,
            'active_connections': 0,
            'failed_connections': 0,
            'recovery_attempts': 0,
            'successful_recoveries': 0
        }
    
    async def register_connection(self, 
                                connection_id: str,
                                connection_obj: Any,
                                health_check_func: callable,
                                recovery_func: callable,
                                check_interval: float = 30.0):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        
        self.connections[connection_id] = {
            'object': weakref.ref(connection_obj),
            'health_check': health_check_func,
            'recovery_func': recovery_func,
            'last_check': 0,
            'check_interval': check_interval,
            'consecutive_failures': 0,
            'status': 'unknown'
        }
        
        # –°–æ–∑–¥–∞–µ–º circuit breaker
        self.circuit_breakers[connection_id] = CircuitBreaker(
            failure_threshold=3,
            recovery_timeout=60,
            expected_exception=Exception
        )
        
        logger.info(f"Connection {connection_id} registered for monitoring")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω
        if not self.monitoring_active:
            asyncio.create_task(self._monitoring_loop())
    
    async def _monitoring_loop(self):
        """‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        self.monitoring_active = True
        logger.info("Connection monitoring started")
    
        # ‚úÖ –ù–û–í–û–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
        last_metrics_report = 0
        metrics_interval = 300  # 5 –º–∏–Ω—É—Ç
    
        while self.monitoring_active:
            try:
                current_time = time.time()
            
                # –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                await self._check_all_connections()
            
                # ‚úÖ –ù–û–í–û–ï: –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –º–µ—Ç—Ä–∏–∫ (–∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç)
                if current_time - last_metrics_report > metrics_interval:
                    try:
                        await self._report_system_metrics()
                        last_metrics_report = current_time
                    except Exception as metrics_error:
                        logger.error(f"Metrics reporting error: {metrics_error}")
                        # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –º–µ—Ç—Ä–∏–∫ —Å Production Logger
                        if 'prod_logger' in globals():
                            prod_logger.log_error(metrics_error, {
                                'operation': 'system_metrics_reporting',
                                'context': 'monitoring_loop',
                                'component': 'connection_monitor'
                            }, send_alert=False)  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞
            
                await asyncio.sleep(10)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥
            
            except Exception as e:
                logger.error(f"Connection monitoring error: {e}")
            
                # ‚úÖ –ù–û–í–û–ï: Production Logger –¥–ª—è –æ—à–∏–±–æ–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                if 'prod_logger' in globals():
                    try:
                        prod_logger.log_error(e, {
                            'operation': 'connection_monitoring',
                            'context': 'monitoring_loop_error',
                            'component': 'connection_monitor',
                            'monitoring_active': self.monitoring_active
                        }, send_alert=True)  # –ö—Ä–∏—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º alert
                    except:
                        pass  # –ù–µ –ª–æ–º–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ª–æ–≥–∏–∫—É
            
                await asyncio.sleep(30)
    
    async def _check_all_connections(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        now = time.time()
        
        for conn_id, conn_info in list(self.connections.items()):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —ç—Ç–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                if now - conn_info['last_check'] > conn_info['check_interval']:
                    await self._check_single_connection(conn_id, conn_info)
                    conn_info['last_check'] = now
                    
            except Exception as e:
                logger.error(f"Error checking connection {conn_id}: {e}")
    
    async def _check_single_connection(self, conn_id: str, conn_info: Dict):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        try:
            connection_obj = conn_info['object']()
            if connection_obj is None:
                # –û–±—ä–µ–∫—Ç –±—ã–ª —É–¥–∞–ª–µ–Ω —Å–±–æ—Ä—â–∏–∫–æ–º –º—É—Å–æ—Ä–∞
                del self.connections[conn_id]
                return
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º circuit breaker
            circuit_breaker = self.circuit_breakers[conn_id]
            
            if circuit_breaker.state == 'open':
                # Circuit –æ—Ç–∫—Ä—ã—Ç, –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º
                conn_info['status'] = 'circuit_open'
                return
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º health check
            health_status = await conn_info['health_check'](connection_obj)
            
            if health_status:
                # –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–¥–æ—Ä–æ–≤–æ–µ
                conn_info['status'] = 'healthy'
                conn_info['consecutive_failures'] = 0
                circuit_breaker.record_success()
                
            else:
                # –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ–∑–¥–æ—Ä–æ–≤–æ–µ
                conn_info['status'] = 'unhealthy'
                conn_info['consecutive_failures'] += 1
                circuit_breaker.record_failure()
                
                # –ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                if conn_info['consecutive_failures'] >= 2:
                    await self._attempt_recovery(conn_id, conn_info)
                    
        except Exception as e:
            logger.warning(f"Health check failed for {conn_id}: {e}")
            conn_info['status'] = 'error'
            self.circuit_breakers[conn_id].record_failure()

    async def _report_system_metrics(self):
        """‚úÖ –ù–û–í–´–ô –ú–ï–¢–û–î: –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # ‚úÖ Performance metrics (–µ—Å–ª–∏ Production Logger –¥–æ—Å—Ç—É–ø–µ–Ω)
            perf_summary = {}
            if 'prod_logger' in globals() and hasattr(prod_logger, 'metrics'):
                try:
                    perf_summary = prod_logger.metrics.get_performance_summary()
                except:
                    perf_summary = {'status': 'metrics_unavailable'}
        
            # ‚úÖ System metrics
            try:
                import psutil
                process = psutil.Process()
                system_metrics = {
                    'memory_mb': round(process.memory_info().rss / 1024 / 1024, 2),
                    'cpu_percent': process.cpu_percent(),
                    'uptime_hours': round((time.time() - self.start_time) / 3600, 2)
                }
            except ImportError:
                system_metrics = {
                    'memory_mb': 'psutil_not_available',
                    'cpu_percent': 'psutil_not_available',
                    'uptime_hours': round((time.time() - self.start_time) / 3600, 2)
                }
            except Exception as e:
                system_metrics = {'error': str(e)}
        
            # ‚úÖ Connection Monitor stats (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            connection_metrics = {}
            if hasattr(self, 'connection_monitor') and self.connection_monitor:
                try:
                    connection_metrics = {
                        'total_connections': len(self.connection_monitor.connections),
                        'active_connections': sum(1 for conn in self.connection_monitor.connections.values() 
                                                if conn.get('status') == 'healthy'),
                        'monitoring_stats': self.connection_monitor.stats
                    }
                except:
                    connection_metrics = {'status': 'connection_monitor_unavailable'}
        
            # ‚úÖ Rate limiter stats
            rate_limiter_stats = {}
            try:
                if hasattr(self, 'source_client') and hasattr(self.source_client, 'rate_limiter'):
                    if hasattr(self.source_client.rate_limiter, 'stats'):
                        rate_limiter_stats['source'] = self.source_client.rate_limiter.stats
                    
                if hasattr(self, 'main_client') and hasattr(self.main_client, 'rate_limiter'):
                    if hasattr(self.main_client.rate_limiter, 'stats'):
                        rate_limiter_stats['main'] = self.main_client.rate_limiter.stats
            except:
                rate_limiter_stats = {'status': 'rate_limiter_unavailable'}
        
            # ‚úÖ WebSocket stats
            websocket_stats = {}
            try:
                if hasattr(self, 'websocket_manager') and self.websocket_manager:
                    websocket_stats = self.websocket_manager.get_stats()
            except:
                websocket_stats = {'status': 'websocket_unavailable'}
        
            # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
            metrics_report = {
                'timestamp': datetime.utcnow().isoformat(),
                'system': system_metrics,
                'connections': connection_metrics,
                'rate_limiters': rate_limiter_stats,
                'websocket': websocket_stats,
                'performance': perf_summary
            }
        
            # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            logger.info("üìä SYSTEM METRICS REPORT:")
            logger.info(f"System: Memory={system_metrics.get('memory_mb', 'N/A')}MB, "
                       f"CPU={system_metrics.get('cpu_percent', 'N/A')}%, "
                       f"Uptime={system_metrics.get('uptime_hours', 'N/A')}h")
        
            if connection_metrics:
                logger.info(f"Connections: {connection_metrics.get('active_connections', 'N/A')}/"
                           f"{connection_metrics.get('total_connections', 'N/A')} active")
        
            if websocket_stats:
                ws_status = websocket_stats.get('status', 'unknown')
                ws_messages = websocket_stats.get('messages_received', 0)
                logger.info(f"WebSocket: Status={ws_status}, Messages={ws_messages}")
        
            # ‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π JSON –æ—Ç—á–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            logger.debug(f"DETAILED METRICS: {json.dumps(metrics_report, indent=2)}")
        
            # ‚úÖ Production Logger metrics (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if 'prod_logger' in globals():
                try:
                    prod_logger.log_performance('system_metrics_report', 0.1, True, {
                        'metrics_summary': {
                            'memory_mb': system_metrics.get('memory_mb'),
                            'active_connections': connection_metrics.get('active_connections'),
                            'websocket_status': websocket_stats.get('status')
                        }
                    })
                except:
                    pass
        
        except Exception as e:
            logger.error(f"System metrics reporting error: {e}")

class CircuitBreaker:
    """Circuit Breaker pattern –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –∫–∞—Å–∫–∞–¥–Ω—ã—Ö —Å–±–æ–µ–≤"""
    
    def __init__(self, failure_threshold: int = 5, recovery_timeout: float = 60.0, expected_exception: type = Exception):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.expected_exception = expected_exception
        
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'closed'  # closed, open, half_open
    
    def record_success(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å —É—Å–ø–µ—à–Ω—É—é –æ–ø–µ—Ä–∞—Ü–∏—é"""
        self.failure_count = 0
        self.state = 'closed'
    
    def record_failure(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å –Ω–µ—É–¥–∞—á–Ω—É—é –æ–ø–µ—Ä–∞—Ü–∏—é"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.state = 'open'
    
    def can_proceed(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–∂–Ω–æ –ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é"""
        if self.state == 'closed':
            return True
        elif self.state == 'open':
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = 'half_open'
                return True
            return False
        elif self.state == 'half_open':
            return True
        
        return False


class SignalType(Enum):
    POSITION_OPEN = "position_open"
    POSITION_CLOSE = "position_close" 
    POSITION_MODIFY = "position_modify"
    ORDER_FILL = "order_fill"
    ORDER_CANCEL = "order_cancel"

class ConnectionStatus(Enum):
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    AUTHENTICATED = "authenticated"
    ERROR = "error"

class HealthStatus(Enum):
    OK = "ok"
    WARNING = "warning" 
    CRITICAL = "critical"

@dataclass
class TradingSignal:
    signal_type: SignalType
    symbol: str
    side: str
    size: float
    price: float
    timestamp: float
    metadata: Dict[str, Any]
    priority: int = 1  # 1=low, 2=normal, 3=high

@dataclass 
class HealthCheck:
    component: str
    status: HealthStatus
    message: str
    details: Dict[str, Any] = None

def utc_now_iso():
    return datetime.now(timezone.utc).isoformat()

def safe_float(value, default=0.0):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ float"""
    try:
        if value is None or value == "":
            return default
        return float(value)
    except (ValueError, TypeError):
        return default

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è enterprise —Å–µ—Å—Å–∏—è –¥–ª—è Telegram alerts
_telegram_enterprise_session: Optional[aiohttp.ClientSession] = None

async def get_telegram_enterprise_session() -> aiohttp.ClientSession:
    """
    CRITICAL FIX: Get or create optimized session for Telegram alerts
    –ó–∞–º–µ–Ω—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –Ω–∞ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é enterprise —Å–µ—Å—Å–∏—é
    """
    global _telegram_enterprise_session
    
    if _telegram_enterprise_session is None or _telegram_enterprise_session.closed:
        # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–µ—Å—Å–∏—é –¥–ª—è Telegram
        connector = aiohttp.TCPConnector(
            limit=10,                    # –ù–µ–±–æ–ª—å—à–æ–π pool –¥–ª—è Telegram
            limit_per_host=5,           # –õ–∏–º–∏—Ç –¥–ª—è api.telegram.org
            ttl_dns_cache=300,          # DNS cache 5 –º–∏–Ω—É—Ç
            use_dns_cache=True,         # Enable DNS caching
            keepalive_timeout=30,       # Keep connections alive
            enable_cleanup_closed=True, # Clean up closed connections
        )
        
        timeout = aiohttp.ClientTimeout(
            total=15,        # –£–≤–µ–ª–∏—á–µ–Ω timeout –¥–ª—è Telegram
            connect=5,       # Connection timeout
            sock_read=10     # Read timeout
        )
        
        _telegram_enterprise_session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'Bybit-Trading-Bot/1.0'}  # Identify our bot
        )
        
        logger.debug("Telegram enterprise session created")
    
    return _telegram_enterprise_session

async def cleanup_telegram_session():
    """Cleanup —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Telegram —Å–µ—Å—Å–∏–∏"""
    global _telegram_enterprise_session
    
    if _telegram_enterprise_session and not _telegram_enterprise_session.closed:
        await _telegram_enterprise_session.close()
        _telegram_enterprise_session = None
        logger.debug("Telegram enterprise session closed")

async def send_telegram_alert(message: str) -> bool:
    """
    CRITICAL FIX: –û—Ç–ø—Ä–∞–≤–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–ª–µ—Ä—Ç–æ–≤ –≤ Telegram —Å enterprise connection management
    –ó–ê–ú–ï–ù–Ø–ï–¢ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—É—é —Å–µ—Å—Å–∏—é
    """
    try:
        if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
            logger.debug("Telegram credentials not configured")
            return False
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
        if len(message) > 4000:
            message = message[:3900] + "\n\n[–°–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ]"
        
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        data = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": f"üö® SYSTEM ALERT: {message}",
            "parse_mode": "HTML",
            "disable_web_page_preview": True  # –£–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞
        }
        
        # CRITICAL FIX: –ò—Å–ø–æ–ª—å–∑—É–µ–º enterprise —Å–µ—Å—Å–∏—é –≤–º–µ—Å—Ç–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π
        session = await get_telegram_enterprise_session()
        
        start_time = time.time()
        
        async with session.post(url, json=data) as response:  # json –≤–º–µ—Å—Ç–æ data –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            response_time = time.time() - start_time
            success = response.status == 200
            
            if success:
                logger.debug(f"Telegram alert sent successfully in {response_time:.3f}s")
            else:
                response_text = await response.text()
                logger.warning(f"Telegram alert failed: HTTP {response.status}, {response_text}")
            
            return success
                
    except asyncio.TimeoutError:
        logger.error("Telegram alert timeout - network issue")
        return False
    except aiohttp.ClientError as e:
        logger.error(f"Telegram alert network error: {e}")
        return False
    except Exception as e:
        logger.error(f"Telegram alert unexpected error: {e}")
        return False

# –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –î–æ–±–∞–≤–∏—Ç—å –≤ cleanup —Ñ—É–Ω–∫—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã
async def cleanup_all_enterprise_sessions():
    """
    CRITICAL: Cleanup –≤—Å–µ—Ö enterprise —Å–µ—Å—Å–∏–π –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã
    –î–û–ë–ê–í–ò–¢–¨ –í–´–ó–û–í –≠–¢–û–ô –§–£–ù–ö–¶–ò–ò –≤ cleanup –º–µ—Ç–æ–¥—ã FinalTradingMonitor
    """
    try:
        await cleanup_telegram_session()
        logger.info("All enterprise sessions cleaned up")
    except Exception as e:
        logger.error(f"Error cleaning up enterprise sessions: {e}")

# ================================
# ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï WEBSOCKET –§–£–ù–ö–¶–ò–ò (–∏–∑ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
# ================================

def get_websockets_version():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ websockets –±–∏–±–ª–∏–æ—Ç–µ–∫–∏"""
    try:
        import websockets
        return websockets.__version__
    except:
        return "unknown"

def is_websocket_open(ws) -> bool:
    """
    ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è WebSocket –¥–ª—è websockets 15.0.1
    
    –ù–ê –û–°–ù–û–í–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:
    - ws.closed –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢ –≤ ClientConnection
    - ws.state.name = "OPEN" - –†–ê–ë–û–¢–ê–ï–¢
    - ws.close_code = None - –†–ê–ë–û–¢–ê–ï–¢
    """
    if not ws:
        return False
        
    try:
        # ‚úÖ –ú–ï–¢–û–î 1: websockets 15.0.1 —Å state.name (–ü–†–ò–û–†–ò–¢–ï–¢)
        # –¢–µ—Å—Ç –ø–æ–∫–∞–∑–∞–ª: ws.state.name = "OPEN" (str)
        if hasattr(ws, 'state') and hasattr(ws.state, 'name'):
            state_name = ws.state.name.upper()
            is_open = 'OPEN' in state_name
            logger.debug(f"WebSocket state check: {ws.state.name} -> {is_open}")
            return is_open
        
        # ‚úÖ –ú–ï–¢–û–î 2: fallback —á–µ—Ä–µ–∑ close_code
        # –¢–µ—Å—Ç –ø–æ–∫–∞–∑–∞–ª: ws.close_code = None (–¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö)
        if hasattr(ws, 'close_code'):
            is_open = ws.close_code is None
            logger.debug(f"WebSocket close_code check: {ws.close_code} -> {is_open}")
            return is_open
        
        # ‚úÖ –ú–ï–¢–û–î 3: –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–æ–¥–æ–≤ (–≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        # –¢–µ—Å—Ç –ø–æ–∫–∞–∑–∞–ª: hasattr(ws, "send") = True, hasattr(ws, "recv") = True
        has_methods = hasattr(ws, 'send') and hasattr(ws, 'recv')
        logger.debug(f"WebSocket methods check: send={hasattr(ws, 'send')}, recv={hasattr(ws, 'recv')} -> {has_methods}")
        return has_methods
        
    except Exception as e:
        logger.debug(f"WebSocket state check error: {e}")
        return False

async def close_websocket_safely(ws):
    """
    ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ WebSocket –¥–ª—è websockets 15.0.1
    
    –ù–ê –û–°–ù–û–í–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:
    - await ws.close() —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ (0.036s)
    - –í—Å–µ 5 –º–µ—Ç–æ–¥–æ–≤ –∑–∞–∫—Ä—ã—Ç–∏—è —Ä–∞–±–æ—Ç–∞—é—Ç –±–µ–∑ –æ—à–∏–±–æ–∫
    - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º
    """
    if not ws:
        return
        
    try:
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º (–Ω–æ–≤—ã–π –º–µ—Ç–æ–¥)
        if is_websocket_open(ws):
            # –¢–µ—Å—Ç –ø–æ–∫–∞–∑–∞–ª: await ws.close() —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞ 0.036s
            await asyncio.wait_for(ws.close(), timeout=5.0)
            logger.debug("WebSocket closed successfully")
        else:
            logger.debug("WebSocket was already closed")
            
    except asyncio.TimeoutError:
        logger.warning("WebSocket close timeout")
    except Exception as e:
        # –¢–µ—Å—Ç –ø–æ–∫–∞–∑–∞–ª: –Ω–µ—Ç –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ª–æ–≥–∏—Ä—É–µ–º
        logger.debug(f"Error closing WebSocket: {e}")
        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∑–∞–∫—Ä—ã—Ç–∏—è - –≥–ª–∞–≤–Ω–æ–µ –Ω–µ —É–ø–∞—Å—Ç—å

async def diagnose_websocket_issue(ws, name="WebSocket"):
    """
    ‚úÖ –ù–û–í–ê–Ø –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø—Ä–æ–±–ª–µ–º —Å WebSocket
    
    –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
    await diagnose_websocket_issue(self.ws, "MyWebSocket")
    """
    print(f"\nüîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê WEBSOCKET: {name}")
    print(f"   –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞: {type(ws).__name__}")
    print(f"   websockets –≤–µ—Ä—Å–∏—è: {get_websockets_version()}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
    checks = [
        ("ws.closed", lambda: getattr(ws, 'closed', 'NOT_FOUND')),
        ("ws.state", lambda: getattr(ws, 'state', 'NOT_FOUND')),
        ("ws.state.name", lambda: getattr(getattr(ws, 'state', None), 'name', 'NOT_FOUND') if hasattr(ws, 'state') else 'NO_STATE'),
        ("ws.close_code", lambda: getattr(ws, 'close_code', 'NOT_FOUND')),
    ]
    
    for check_name, check_func in checks:
        try:
            result = check_func()
            status = "‚úÖ" if result != 'NOT_FOUND' else "‚ùå"
            print(f"   {status} {check_name}: {result}")
        except Exception as e:
            print(f"   ‚ùå {check_name}: ERROR - {e}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞—à—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    is_open = is_websocket_open(ws)
    print(f"   üîß is_websocket_open(): {is_open}")
    
    return {
        'type': type(ws).__name__,
        'version': get_websockets_version(),
        'is_open': is_open
    }

# ================================
# –ü–†–û–î–í–ò–ù–£–¢–ê–Ø –°–ò–°–¢–ï–ú–ê API (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô - –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û)
# ================================


class AdvancedRateLimiterPro:
    """
    üöÄ PRODUCTION-GRADE RATE LIMITING –°–ò–°–¢–ï–ú–ê
    
    –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö Bybit API –ª–∏–º–∏—Ç–æ–≤:
    - REST API: 600 –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ 5 —Å–µ–∫—É–Ω–¥ = 120/–º–∏–Ω
    - WebSocket: 10 –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π/—Å–µ–∫
    - –ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ª–∏–º–∏—Ç—ã —Å –∞–≤–≥—É—Å—Ç–∞ 2025
    """
    
    def __init__(self, 
                 requests_per_minute: int = 120,
                 requests_per_second: int = 10,
                 burst_allowance: int = 20,
                 adaptive_mode: bool = True):
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ª–∏–º–∏—Ç—ã
        self.rpm_limit = requests_per_minute
        self.rps_limit = requests_per_second
        self.burst_allowance = burst_allowance
        self.adaptive_mode = adaptive_mode
        
        # Sliding window tracking
        self.requests_per_minute = deque()
        self.requests_per_second = deque()
        self.requests_per_5sec = deque()  # Bybit —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –ª–∏–º–∏—Ç
        
        # Advanced features
        self.priority_queue = {
            'critical': deque(),  # –≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            'high': deque(),     # –¢–æ—Ä–≥–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            'normal': deque(),   # –û–±—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            'low': deque()       # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞/–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        }
        
        # Adaptive throttling
        self.current_latency = 0
        self.error_rate = 0
        self.adaptive_factor = 1.0
        
        # Rate limit headers tracking (X-Bapi-Limit)
        self.server_limits = {}
        self.limit_reset_times = {}
        
        # Monitoring
        self.stats = {
            'total_requests': 0,
            'throttled_requests': 0,
            'burst_used': 0,
            'adaptive_adjustments': 0,
            'priority_bypasses': 0
        }
        
        self.lock = asyncio.Lock()
        logger.info(f"Advanced Rate Limiter initialized: {self.rpm_limit}/min, {self.rps_limit}/sec")
    
    async def acquire(self, priority: str = 'normal', endpoint: str = None) -> Dict[str, Any]:
        """
        üéØ –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ï –ü–û–õ–£–ß–ï–ù–ò–ï –†–ê–ó–†–ï–®–ï–ù–ò–Ø –ù–ê –ó–ê–ü–†–û–°
        
        Args:
            priority: 'critical', 'high', 'normal', 'low'
            endpoint: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π endpoint –¥–ª—è per-endpoint –ª–∏–º–∏—Ç–æ–≤
        """
        async with self.lock:
            now = time.time()
            
            # –û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π (sliding window)
            self._cleanup_old_requests(now)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ server-side –ª–∏–º–∏—Ç–æ–≤ –∏–∑ headers
            if endpoint and endpoint in self.server_limits:
                if not self._check_server_limits(endpoint, now):
                    return await self._wait_for_server_limit_reset(endpoint)
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ª–∏–º–∏—Ç–æ–≤
            if self.adaptive_mode:
                self._adjust_adaptive_limits()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            if priority in ['critical', 'high']:
                bypass_reason = self._check_priority_bypass(priority, now)
                if bypass_reason:
                    return await self._execute_priority_request(now, bypass_reason)
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ rate limiting
            wait_times = self._calculate_wait_times(now)
            
            if any(wait_times.values()):
                max_wait = max(wait_times.values())
                logger.warning(f"Rate limit hit, waiting {max_wait:.2f}s")
                await self._intelligent_wait(max_wait, priority)
            
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
            return self._register_request(now, priority, endpoint)
    
    def _check_priority_bypass(self, priority: str, now: float) -> Optional[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ bypass –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤—Å–µ–≥–¥–∞ –ø—Ä–æ—Ö–æ–¥—è—Ç
            if priority == 'critical':
                self.stats['priority_bypasses'] += 1
                return 'critical_bypass'
        
            # High priority –ø—Ä–æ—Ö–æ–¥–∏—Ç –µ—Å–ª–∏ —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞
            if priority == 'high':
                current_rps = len(self.requests_per_second)
                if current_rps < (self.rps_limit * 0.8):  # –ú–µ–Ω–µ–µ 80% –ª–∏–º–∏—Ç–∞
                    self.stats['priority_bypasses'] += 1
                    return 'high_priority_bypass'
        
            return None
        
        except Exception as e:
            logger.debug(f"Priority bypass check error: {e}")
            return None

    async def _execute_priority_request(self, now: float, bypass_reason: str) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å bypass"""
        try:
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
            self.requests_per_minute.append(now)
            self.requests_per_second.append(now)
            self.requests_per_5sec.append(now)
            self.stats['total_requests'] += 1
        
            return {
                'timestamp': now,
                'priority': 'bypassed',
                'bypass_reason': bypass_reason,
                'adaptive_factor': self.adaptive_factor,
                'requests_in_window': {
                    'rpm': len(self.requests_per_minute),
                    'rps': len(self.requests_per_second),
                    '5sec': len(self.requests_per_5sec)
                }
            }
        
        except Exception as e:
            logger.error(f"Priority request execution error: {e}")
            return self._register_request(now, 'high', None)

    def _check_server_limits(self, endpoint: str, now: float) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ server-side –ª–∏–º–∏—Ç–æ–≤ –∏–∑ headers"""
        try:
            if endpoint not in self.server_limits:
                return True
        
            server_limit = self.server_limits[endpoint]
            reset_time = self.limit_reset_times.get(endpoint, 0)
        
            # –ï—Å–ª–∏ –≤—Ä–µ–º—è —Å–±—Ä–æ—Å–∞ –ø—Ä–æ—à–ª–æ, –ª–∏–º–∏—Ç –æ–±–Ω–æ–≤–∏–ª—Å—è
            if now > reset_time:
                return True
        
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø—Ä–æ—Å—ã
            # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞, –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
            return True
        
        except Exception as e:
            logger.debug(f"Server limits check error: {e}")
            return True

    async def _wait_for_server_limit_reset(self, endpoint: str) -> Dict[str, Any]:
        """–û–∂–∏–¥–∞–Ω–∏–µ —Å–±—Ä–æ—Å–∞ server-side –ª–∏–º–∏—Ç–∞"""
        try:
            reset_time = self.limit_reset_times.get(endpoint, 0)
            current_time = time.time()
        
            if reset_time > current_time:
                wait_time = reset_time - current_time
                logger.info(f"Waiting for server limit reset: {wait_time:.1f}s")
                await asyncio.sleep(min(wait_time, 60))  # –ú–∞–∫—Å–∏–º—É–º –º–∏–Ω—É—Ç–∞
        
            return self._register_request(time.time(), 'normal', endpoint)
        
        except Exception as e:
            logger.error(f"Server limit wait error: {e}")
            return self._register_request(time.time(), 'normal', endpoint)

    def _cleanup_old_requests(self, now: float):
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ sliding windows"""
        # 1 –º–∏–Ω—É—Ç–∞ window
        while self.requests_per_minute and now - self.requests_per_minute[0] > 60:
            self.requests_per_minute.popleft()
        
        # 1 —Å–µ–∫—É–Ω–¥–∞ window  
        while self.requests_per_second and now - self.requests_per_second[0] > 1:
            self.requests_per_second.popleft()
            
        # 5 —Å–µ–∫—É–Ω–¥ window (Bybit —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π)
        while self.requests_per_5sec and now - self.requests_per_5sec[0] > 5:
            self.requests_per_5sec.popleft()
    
    def _calculate_wait_times(self, now: float) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏–º–∏—Ç–∞"""
        wait_times = {}
        
        # RPM check
        adjusted_rpm = int(self.rpm_limit * self.adaptive_factor)
        if len(self.requests_per_minute) >= adjusted_rpm:
            wait_times['rpm'] = 60 - (now - self.requests_per_minute[0])
        
        # RPS check
        adjusted_rps = int(self.rps_limit * self.adaptive_factor)
        if len(self.requests_per_second) >= adjusted_rps:
            wait_times['rps'] = 1 - (now - self.requests_per_second[0])
            
        # Bybit 5-sec window (600 requests per 5 seconds)
        if len(self.requests_per_5sec) >= 600:
            wait_times['5sec'] = 5 - (now - self.requests_per_5sec[0])
        
        return wait_times
    
    def _adjust_adaptive_limits(self):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç—ã –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if self.current_latency < 100 and self.error_rate < 0.01:
            self.adaptive_factor = min(1.2, self.adaptive_factor + 0.05)
            
        # –£–º–µ–Ω—å—à–∞–µ–º –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
        elif self.current_latency > 500 or self.error_rate > 0.05:
            self.adaptive_factor = max(0.5, self.adaptive_factor - 0.1)
            self.stats['adaptive_adjustments'] += 1
    
    async def _intelligent_wait(self, wait_time: float, priority: str):
        """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        self.stats['throttled_requests'] += 1
        
        # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∂–¥—É—Ç –º–µ–Ω—å—à–µ
        if priority == 'critical':
            wait_time *= 0.5
        elif priority == 'high':
            wait_time *= 0.7
        elif priority == 'low':
            wait_time *= 1.5
            
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π jitter –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è thundering herd
        jitter = wait_time * 0.1 * (hash(asyncio.current_task()) % 100) / 100
        await asyncio.sleep(wait_time + jitter)
    
    def _register_request(self, now: float, priority: str, endpoint: str) -> Dict[str, Any]:
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        self.requests_per_minute.append(now)
        self.requests_per_second.append(now)
        self.requests_per_5sec.append(now)
        self.stats['total_requests'] += 1
        
        return {
            'timestamp': now,
            'priority': priority,
            'endpoint': endpoint,
            'adaptive_factor': self.adaptive_factor,
            'requests_in_window': {
                'rpm': len(self.requests_per_minute),
                'rps': len(self.requests_per_second),
                '5sec': len(self.requests_per_5sec)
            }
        }
    
    def update_from_response_headers(self, headers: Dict[str, str], endpoint: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ response headers –æ—Ç Bybit"""
        try:
            # X-Bapi-Limit: —Ç–µ–∫—É—â–∏–π –ª–∏–º–∏—Ç –¥–ª—è endpoint
            if 'X-Bapi-Limit' in headers:
                self.server_limits[endpoint] = int(headers['X-Bapi-Limit'])
            
            # X-Bapi-Limit-Status: –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø—Ä–æ—Å—ã
            if 'X-Bapi-Limit-Status' in headers:
                remaining = int(headers['X-Bapi-Limit-Status'])
                if remaining < 5:  # –ë–ª–∏–∑–∫–æ –∫ –ª–∏–º–∏—Ç—É
                    logger.warning(f"Endpoint {endpoint} limit almost reached: {remaining} remaining")
            
            # X-Bapi-Limit-Reset-Timestamp: –≤—Ä–µ–º—è —Å–±—Ä–æ—Å–∞ –ª–∏–º–∏—Ç–∞
            if 'X-Bapi-Limit-Reset-Timestamp' in headers:
                reset_time = int(headers['X-Bapi-Limit-Reset-Timestamp']) / 1000
                self.limit_reset_times[endpoint] = reset_time
                
        except (ValueError, KeyError) as e:
            logger.debug(f"Error parsing rate limit headers: {e}")


class AWSTimeSyncPro:
    """
    üåè –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –í–†–ï–ú–ï–ù–ò –° –°–ï–†–í–ï–†–ê–ú–ò BYBIT

    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è Bybit: –∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π timestamp –¥–æ–ª–∂–µ–Ω –ø–æ–ø–∞–¥–∞—Ç—å –≤ –æ–∫–Ω–æ ¬±5s
    –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ö—Ä–∞–Ω–∏—Ç –±–∞–∑–æ–≤—É—é —Ç–æ—á–∫—É —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤–º–µ—Å—Ç–µ —Å monotonic(),
    —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —Å–∫–∞—á–∫–∏ –∏–∑-–∑–∞ NTP/—Å–Ω–∞/—Ä–µ—Å–∏–Ω–∫–æ–≤ VM.
    """

    def __init__(self):
        # –ü—É–±–ª–∏—á–Ω—ã–µ –ø–æ–ª—è (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –≤ —Ç–≤–æ–µ–π –≤–µ—Ä—Å–∏–∏)
        self.time_offset: float = 0.0      # —Å–º–µ—â–µ–Ω–∏–µ "–∫–ª–∏–µ–Ω—Ç -> —Å–µ—Ä–≤–µ—Ä" –≤ –º—Å (–¥–ª—è –º–µ—Ç—Ä–∏–∫/–ª–æ–≥–æ–≤)
        self.last_sync: float = 0.0        # unix seconds –ø–æ—Å–ª–µ–¥–Ω–µ–π —É—Å–ø–µ—à–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        self.sync_interval: int = 300      # 5 –º–∏–Ω—É—Ç
        self.sync_accuracy: float = 0.0    # —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (¬±–º—Å)

        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        if IS_PROD:
            logger.info("AWSTimeSyncPro: Using PRODUCTION time sources.")
            self.time_sources = [
                "https://api.bybit.com/v5/market/time",
                "https://api.bybit.com/v5/public/time",
            ]
        else:
            logger.info("AWSTimeSyncPro: Using DEMO and PRODUCTION time sources for dev.")
            self.time_sources = [
                "https://api-demo.bybit.com/v5/market/time",
                "https://api-demo.bybit.com/v5/public/time",
                "https://api.bybit.com/v5/market/time", # –í dev –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏ –ø—Ä–æ–¥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                "https://api.bybit.com/v5/public/time",
            ]

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        self.sync_stats = {
            "successful_syncs": 0,
            "failed_syncs": 0,
            "average_accuracy": 0.0,
            "max_drift": 0.0,
            "last_sync_source": None,
        }

        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.drift_samples = deque(maxlen=10)
        self.rtt_samples = deque(maxlen=10)

        # üîß –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è "–æ–ø–æ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏" (–º–æ–Ω–æ–ª–∏—Ç–Ω–∞—è –±–∞–∑–∞)
        self._server_ms0: Optional[int] = None  # —Å–µ—Ä–≤–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –≤ –º–æ–º–µ–Ω—Ç —Å–∏–Ω–∫–∞ (–º—Å)
        self._mono0: Optional[float] = None     # time.monotonic() –≤ –º–æ–º–µ–Ω—Ç —Å–∏–Ω–∫–∞ (—Å–µ–∫)

    # ------------------------- –ü–£–ë–õ–ò–ß–ù–´–ô –ò–ù–¢–ï–†–§–ï–ô–° (–∫–∞–∫ —É —Ç–µ–±—è) -------------------------

    async def sync_server_time(self, api_url: str) -> bool:
        """
        üéØ –í–´–°–û–ö–û–¢–û–ß–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –í–†–ï–ú–ï–ù–ò (–∞–ª–≥–æ—Ä–∏—Ç–º NTP —Å –≤—ã–±–æ—Ä–æ–º –ª—É—á—à–µ–≥–æ –∑–∞–º–µ—Ä–∞)
        public: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä–æ–µ –∏–º—è –∏ —Å–∏–≥–Ω–∞—Ç—É—Ä—É
        """
        best_accuracy = float("inf")
        best_offset = 0.0
        best_source = None
        successful_sources = 0
        old_offset = self.time_offset

        for source_url in self.time_sources:
            try:
                measurements = []
                # –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–º–µ—Ä–æ–≤ —Å –∫–æ—Ä–æ—Ç–∫–æ–π –ø–∞—É–∑–æ–π
                for _ in range(3):
                    result = await self._single_time_measurement(source_url)
                    if result:
                        measurements.append(result)
                        await asyncio.sleep(0.1)

                if measurements:
                    # –ª—É—á—à–∏–π –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É RTT
                    best_measurement = min(measurements, key=lambda x: x["rtt"])
                    if best_measurement["accuracy"] < best_accuracy:
                        best_accuracy = best_measurement["accuracy"]
                        best_offset = best_measurement["offset"]
                        best_source = source_url
                        successful_sources += 1

            except Exception as e:
                logger.warning(f"Time sync failed for {source_url}: {e}")
                self.sync_stats["failed_syncs"] += 1

        if successful_sources == 0:
            logger.error("All time sync sources failed")
            return False

        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Å–º–µ—â–µ–Ω–∏—è –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥—Ä–µ–π—Ñ–∞
        calibrated_offset = self._apply_drift_calibration(best_offset)

        # –§–∏–∫—Å–∏—Ä—É–µ–º –±–∞–∑—É: —Å–µ—Ä–≤–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–π —è–∫–æ—Ä—å
        client_epoch_ms_now = int(time.time() * 1000)
        self._server_ms0 = int(client_epoch_ms_now + calibrated_offset)
        self._mono0 = time.monotonic()

        # –û–±–Ω–æ–≤–ª—è–µ–º ¬´—Å—Ç–∞—Ä—ã–µ¬ª –ø—É–±–ª–∏—á–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏ –º–µ—Ç—Ä–∏–∫
        self.time_offset = float(calibrated_offset)
        if old_offset != self.time_offset:
            logger.info(f"TIME_OFFSET_UPDATE old={old_offset:.1f} new={self.time_offset:.1f}")
        self.sync_accuracy = float(best_accuracy)
        self.last_sync = time.time()
        self.sync_stats["successful_syncs"] += 1
        self.sync_stats["average_accuracy"] = (
            self.sync_stats["average_accuracy"] * 0.9 + best_accuracy * 0.1
        )
        self.sync_stats["last_sync_source"] = best_source

        logger.info(
            "Time sync successful: offset=%.1fms, accuracy=¬±%.1fms (source=%s)",
            self.time_offset,
            self.sync_accuracy,
            best_source,
        )
        return True

    async def ensure_time_sync(self, api_url: str) -> bool:
        """
        –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –±–∞–∑–∞ –≤—Ä–µ–º–µ–Ω–∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞ (–∫–∞–∫ –≤ —Ç–≤–æ–µ–º –∫–æ–¥–µ).
        """
        need_sync = (
            self._server_ms0 is None
            or self._mono0 is None
            or (time.time() - self.last_sync) > self.sync_interval
        )
        if need_sync:
            return await self.sync_server_time(api_url)
        return True

    def get_server_time(self) -> int:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (ms) —Å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–µ–π –¥—Ä–µ–π—Ñ–∞.
        –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å.
        """
        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –º–æ–Ω–æ—Ç–æ–Ω–Ω–∞—è –±–∞–∑–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ —Ä–µ—Å–∏–Ω–∫–∞–º/—Å–Ω—É)
        if self._server_ms0 is not None and self._mono0 is not None:
            elapsed_ms = (time.monotonic() - self._mono0) * 1000.0
            return int(self._server_ms0 + elapsed_ms)

        # Fallback: —Å—Ç–∞—Ä—ã–π –ø—É—Ç—å (epoch + time_offset), –ø—Ä–∏–≥–æ–¥–µ–Ω –¥–æ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ sync()
        current_local_time = time.time() * 1000.0
        time_since_sync = max(0.0, time.time() - self.last_sync)
        estimated_drift = time_since_sync * 0.0003  # ~0.3–º—Å/—á ‚Äî –∫–∞–∫ –±—ã–ª–æ —É —Ç–µ–±—è
        compensated_time = current_local_time + self.time_offset - estimated_drift
        return int(compensated_time)

    def get_server_timestamp(self) -> int:
        """
        ‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ ‚Äî –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–æ–π —Ç—ã –≤—ã–∑—ã–≤–∞–µ—à—å –≤ –∫–æ–¥–µ:
            await self.time_sync.ensure_time_sync(self.api_url)
            timestamp = str(self.time_sync.get_server_timestamp())
        """
        return self.get_server_time()

    # ------------------------------- –í–ù–£–¢–†–ï–ù–ù–ò–ï –ú–ï–¢–û–î–´ -------------------------------

    async def _single_time_measurement(self, url: str) -> Optional[Dict[str, Union[float, str]]]:
        """
        –û–¥–∏–Ω –∑–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏: —Ä–∞—Å—á—ë—Ç offset –ø–æ NTP-–ø–æ–¥–æ–±–Ω–æ–π —Å—Ö–µ–º–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏:
          offset, accuracy, rtt, server_time, source
        """
        try:
            # t1/t4 –∏–∑–º–µ—Ä—è–µ–º –≤ epoch-–º—Å, –∫–∞–∫ —É —Ç–µ–±—è (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ–∫–æ–Ω Bybit)
            t1 = time.time() * 1000.0
            timeout = aiohttp.ClientTimeout(total=5)

            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as response:
                    t4 = time.time() * 1000.0

                    if response.status != 200:
                        return None

                    data = await response.json(content_type=None)

                    # retCode=0 –¥–ª—è market/public time ‚Äî –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
                    if (isinstance(data, dict) and data.get("retCode", 0) == 0
                            and isinstance(data.get("result"), dict)):

                        # –î–æ—Å—Ç–∞—ë–º —Å–µ—Ä–≤–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –≤ –º—Å –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–ª–µ–π
                        result = data["result"]
                        server_time = self._extract_server_time_ms(result)
                        if server_time is None:
                            return None

                        # RTT/2 ‚Äî –ø–æ–ª–æ–≤–∏–Ω–∞ –ø—É—Ç–∏
                        rtt = float(t4 - t1)
                        network_delay = rtt / 2.0

                        # –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ t2‚âàt3=server_time, –±–µ—Ä—ë–º –∫–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–ª—É—á–µ–Ω–∏—è
                        adjusted_server_time = server_time + network_delay

                        # –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–∫–∞ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
                        client_time_mid = (t1 + t4) / 2.0

                        # Offset –∏ —Ç–æ—á–Ω–æ—Å—Ç—å
                        offset = float(adjusted_server_time - client_time_mid)
                        accuracy = network_delay  # –ø–æ–ª–æ–≤–∏–Ω–∞ RTT

                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        self.rtt_samples.append(rtt)

                        return {
                            "offset": float(offset),
                            "accuracy": float(accuracy),
                            "rtt": float(rtt),
                            "server_time": float(server_time),
                            "source": url,
                        }

        except Exception as e:
            logger.debug(f"Time measurement failed for {url}: {e}")
            return None

    @staticmethod
    def _extract_server_time_ms(result: Dict) -> Optional[int]:
        """
        –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ Bybit.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è:
          - timeNano (–Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã)
          - timeMicro / timeMillis / timeMilli (–º–∏–∫—Ä–æ/–º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã)
          - timeSecond (—Å–µ–∫—É–Ω–¥—ã) ‚Äî —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ 1000
        """
        try:
            if "timeNano" in result:
                # –ø–µ—Ä–µ–≤–æ–¥ –≤ –º—Å —Å –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º –≤–Ω–∏–∑
                return int(int(result["timeNano"]) / 1_000_000)
            if "timeMicro" in result:
                return int(int(result["timeMicro"]) / 1_000)
            if "timeMillis" in result:
                return int(result["timeMillis"])
            if "timeMilli" in result:
                return int(result["timeMilli"])
            if "timeSecond" in result:
                return int(result["timeSecond"]) * 1000
        except Exception:
            return None
        return None

    def _apply_drift_calibration(self, raw_offset: float) -> float:
        """
        –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –¥—Ä–µ–π—Ñ–∞ —á–∞—Å–æ–≤. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É–±–ª–∏—á–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ.
        """
        if self.time_offset != 0.0:
            drift = raw_offset - self.time_offset
            self.drift_samples.append(drift)

        if len(self.drift_samples) >= 5:
            avg_drift = sum(self.drift_samples) / len(self.drift_samples)
            corrected_offset = raw_offset - (avg_drift * 0.1)
            return float(corrected_offset)

        return float(raw_offset)


class EnhancedBybitClient:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Bybit API —Å –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    
    def __init__(self, api_key: str, api_secret: str, api_url: str, name: str = "client", copy_state=None):
        self.api_key = api_key
        self.api_secret = api_secret
        self.api_url = api_url
        self.name = name
        self.copy_state = copy_state
        
        # –°–∏—Å—Ç–µ–º—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        self.rate_limiter = AdvancedRateLimiterPro(
            requests_per_minute=120,
            requests_per_second=10,
            adaptive_mode=True
        )
        self.time_sync = AWSTimeSyncPro()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        self.request_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'avg_response_time': 0,
            'last_error': None
        }
        
        # Retry –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.max_retries = 3
        self.retry_delays = [1, 2, 5]
        
        # CRITICAL FIX: Enterprise connection management
        self.enterprise_connector = EnterpriseBybitConnector()
        self.resilience_manager = NetworkResilienceManager()
        
        # Connection cleanup registration
        import atexit
        atexit.register(self._cleanup_on_exit)
        
        logger.info(f"{self.name} - Enhanced client initialized with enterprise connection management")

    async def get_wallet_balance(self, account_type: str = "UNIFIED"):
        """
        –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ /v5/account/wallet-balance (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON Bybit –∫–∞–∫ –µ—Å—Ç—å).
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—â–∏–π –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —Å—Ç–µ–∫ _make_request_with_retry ‚Üí _make_single_request.
        """
        logger.info(f"[{self.name}] Fetching wallet balance for account_type='{account_type}', source=REST")
        params = {"accountType": account_type}
        return await self._make_request_with_retry("GET", "account/wallet-balance", params)

    def _cleanup_on_exit(self):
        """Cleanup on process exit"""
        try:
            if hasattr(self, 'enterprise_connector') and self.enterprise_connector:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(self.cleanup_connections())
                loop.close()
        except Exception as e:
            logger.error(f"Exit cleanup error: {e}")
        
    def _generate_signature(self, timestamp: str, recv_window: str, query_string: str = "", body: str = "") -> str:
        """V5: HMAC-SHA256(timestamp + api_key + recv_window + query/body) ‚Üí hex"""
        if not isinstance(recv_window, str):
            recv_window = str(recv_window)
        signature_payload = f"{timestamp}{self.api_key}{recv_window}{query_string}{body}"
        signature = hmac.new(
            self.api_secret.encode("utf-8"),
            signature_payload.encode("utf-8"),
            hashlib.sha256
        ).hexdigest()
        logger.debug(f"{self.name} - Signature payload length: {len(signature_payload)}")
        return signature

    
    async def _make_request_with_retry(self, method: str, endpoint: str, params: dict = None, data: dict = None) -> Optional[dict]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å retry –ª–æ–≥–∏–∫–æ–π –∏ exponential backoff.

        –í–ê–ñ–ù–û: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–±–Ω–æ–≤–ª—è–µ—Ç _make_single_request.
        –ó–¥–µ—Å—å –Ω–µ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º successful_requests, —á—Ç–æ–±—ã –Ω–µ —É–¥–≤–∞–∏–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏.
        """
        for attempt in range(self.max_retries + 1):
            try:
                # –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ total/success/fail –≤–µ–¥—ë—Ç _make_single_request
                return await self._make_single_request(method, endpoint, params, data)
            except Exception as e:
                if "API error 10002" in str(e):
                    req_timestamp = int(data.get('timestamp', 0)) if data else 0
                    req_delta = (time.time() * 1000) - req_timestamp if req_timestamp else -1
                    logger.warning(
                        f"API_10002_RESYNC req_delta={req_delta:.0f}ms offset_before={self.time_sync.time_offset:.1f}"
                    )
                    await self.time_sync.sync_server_time(self.api_url)
                else:
                    logger.warning(f"{self.name} - Request attempt {attempt + 1} failed: {e}")

                if attempt < self.max_retries:
                    delay = self.retry_delays[min(attempt, len(self.retry_delays) - 1)]
                    logger.info(f"{self.name} - Retrying in {delay}s...")
                    await asyncio.sleep(delay)
                else:
                    logger.error(f"{self.name} - All retry attempts failed for {endpoint}")
                    self.request_stats['failed_requests'] += 1
                    self.request_stats['last_error'] = str(e)
                    return None


    async def get_symbol_filters(self, symbol: str, category: str = "linear") -> dict:
        """
        –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å v5/market/instruments-info: —à–∞–≥ –ª–æ—Ç–∞ –∏ —Ç–∏–∫–∞ —Ü–µ–Ω—ã.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: {'min_qty','qty_step','tick_size','min_notional'}
        """
        try:
            if not hasattr(self, "instrument_cache"):
                self.instrument_cache = {}

            cache = self.instrument_cache.get(symbol)
            if cache and (time.time() - cache['ts'] < 3600):
                return cache['filters']

            params = {"category": category, "symbol": symbol}
            res = await self._make_request_with_retry("GET", "market/instruments-info", params)

            filters = {'min_qty': 0.0, 'qty_step': 0.001, 'tick_size': 0.01, 'min_notional': 0.0}
            item = (res or {}).get("result", {}).get("list", [])
            if item:
                item = item[0]
                lot   = item.get("lotSizeFilter", {})
                price = item.get("priceFilter", {})
                filters['min_qty']      = safe_float(lot.get("minOrderQty", 0.0))
                filters['qty_step']     = safe_float(lot.get("qtyStep", 0.001))
                filters['tick_size']    = safe_float(price.get("tickSize", 0.01))
                filters['min_notional'] = safe_float(lot.get("minNotionalValue", lot.get("minOrderValue", 0.0)))

            self.instrument_cache[symbol] = {'ts': time.time(), 'filters': filters}
            return filters

        except Exception as e:
            logger.warning(f"get_symbol_filters failed for {symbol}: {e}")
            return {'min_qty': 0.0, 'qty_step': 0.001, 'tick_size': 0.01, 'min_notional': 0.0}

    async def invalidate_caches(self):
        """Clears all internal caches to force re-fetching of data."""
        logger.info(f"[{self.name}] Invalidating all internal caches...")
        if hasattr(self, "instrument_cache"):
            self.instrument_cache.clear()
            logger.info(f"[{self.name}] Cleared instrument_cache (symbol filters).")
        # Add any other caches here in the future
        await asyncio.sleep(0) # Yield control to allow other tasks to run

    async def _make_single_request(self, method: str, endpoint: str, params: dict = None, data: dict = None, allow_ret_codes: list = None) -> Optional[dict]:
        """
        CRITICAL FIX: Unified single request with enterprise connection management and detailed diagnostics.
        –ó–ê–ú–ï–ù–Ø–ï–¢ –û–ë–ê –°–¢–ê–†–´–• –ü–û–î–•–û–î–ê –Ω–∞ –æ–¥–∏–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π.
        """
        start_time = time.time()
        result = None
        response_data = None
        url = f"{self.api_url}/v5/{endpoint}" # –û–ø—Ä–µ–¥–µ–ª—è–µ–º url –≤ –Ω–∞—á–∞–ª–µ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
        safe_headers_for_log = {}
        body = ""

        try:
            # Rate limiting
            await self.rate_limiter.acquire()

            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏
            await self.time_sync.ensure_time_sync(self.api_url)

            # CRITICAL FIX: Use enterprise session instead of temporary sessions
            session = await self.get_or_create_enterprise_session()

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
            await self.time_sync.ensure_time_sync(self.api_url)
            if abs(self.time_sync.time_offset) > 400:
                logger.warning(f"Time offset {self.time_sync.time_offset}ms > 400ms, forcing resync.")
                await self.time_sync.sync_server_time(self.api_url)

            timestamp = str(self.time_sync.get_server_time())
            recv_window = str(BYBIT_RECV_WINDOW)

            query_string = ""

            if endpoint.startswith("v5/"):
                endpoint = endpoint[3:]

            if method == "GET" and params:
                sorted_params = dict(sorted(params.items()))
                query_string = urlencode(sorted_params)
                url += f"?{query_string}"
            elif method == "POST" and data:
                sorted_data = dict(sorted(data.items()))
                body = json.dumps(sorted_data, separators=(',', ':'))

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥–ø–∏—Å–∏
            signature = self._generate_signature(timestamp, recv_window, query_string, body)

            headers = {
                "X-BAPI-API-KEY": self.api_key,
                "X-BAPI-TIMESTAMP": timestamp,
                "X-BAPI-RECV-WINDOW": recv_window,
                "X-BAPI-SIGN": signature,
                "Content-Type": "application/json"
            }

            # --- DIAGNOSTICS: –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –ü–ï–†–ï–î –æ—Ç–ø—Ä–∞–≤–∫–æ–π ---
            safe_headers_for_log = headers.copy()
            safe_headers_for_log["X-BAPI-API-KEY"] = f"***{self.api_key[-4:]}"
            safe_headers_for_log["X-BAPI-SIGN"] = "***"
            logger.debug(f"[{self.name}] API REQ -> {method} {url}")
            logger.debug(f"[{self.name}] API REQ HEADERS: {safe_headers_for_log}")
            if body:
                logger.debug(f"[{self.name}] API REQ BODY: {body}")

            # CRITICAL FIX: Execute request with proper session reuse
            self.request_stats['total_requests'] += 1
            response = None
            if method == "GET":
                async with session.get(url, headers=headers) as resp:
                    response = resp
                    response_data = await response.json()
            else:
                async with session.post(url, headers=headers, data=body) as resp:
                    response = resp
                    response_data = await response.json()

            # --- DIAGNOSTICS: –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –ü–û–°–õ–ï –ø–æ–ª—É—á–µ–Ω–∏—è ---
            ret_code = response_data.get('retCode')
            ret_msg = response_data.get('retMsg')
            result_list = (response_data.get('result') or {}).get('list', [])
            items_count = len(result_list) if isinstance(result_list, list) else 0

            log_preview = ""
            if items_count > 0:
                log_preview = f", preview: {json.dumps(result_list[:2])}"

            logger.debug(
                f"[{self.name}] API RSP <- {method} {url} | retCode: {ret_code}, retMsg: '{ret_msg}', items: {items_count}{log_preview}"
            )


            # CRITICAL FIX: Process response headers for rate limiting
            if hasattr(self.rate_limiter, 'update_from_response_headers') and response.headers:
                try:
                    self.rate_limiter.update_from_response_headers(
                        dict(response.headers), endpoint)
                except Exception as e:
                    logger.debug(f"{self.name} - Error processing response headers: {e}")

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
            response_time = time.time() - start_time
            self._update_response_time_stats(response_time)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            if response.status == 200:
                if ret_code == 0 or (allow_ret_codes and ret_code in allow_ret_codes):
                    logger.debug(f"{self.name} - Request successful: {endpoint} (retCode: {ret_code})")
                    result = response_data
                    self.request_stats['successful_requests'] += 1
                    if self.copy_state and self.name == "MAIN": self.copy_state.main_rest_ok = True
                    return result
                else:
                    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
                    if ret_code == 10003:  # Invalid signature
                        logger.critical(f"{self.name} - Invalid signature error!")
                        if self.copy_state and self.name == "MAIN": self.copy_state.main_rest_ok = False
                        raise Exception(f"Signature error: {ret_msg}")
                    elif ret_code == 10002: # Request expired
                            logger.warning(f"{self.name} - Timestamp error (10002): {ret_msg}")
                            raise Exception(f"API error 10002: {ret_msg}")
                    elif ret_code == 10006:  # Rate limit exceeded
                        logger.warning(f"{self.name} - Rate limit exceeded")
                        if self.copy_state and self.name == "MAIN": self.copy_state.main_rest_ok = False
                        raise Exception(f"Rate limit: {ret_msg}")
                    else:
                        if self.copy_state and self.name == "MAIN": self.copy_state.main_rest_ok = False
                        raise Exception(f"API error {ret_code}: {ret_msg}")
            else:
                if self.copy_state and self.name == "MAIN": self.copy_state.main_rest_ok = False
                raise Exception(f"HTTP {response.status}: {response_data}")

        except Exception as e:
            if self.copy_state and self.name == "MAIN": self.copy_state.main_rest_ok = False
            self.request_stats['failed_requests'] += 1
            self.request_stats['last_error'] = str(e)
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            logger.error(f"[{self.name}] API Request failed for {endpoint}: {e}")
            logger.debug(f"[{self.name}] Failed request details: URL={url}, Headers={safe_headers_for_log}, Body={body}")
            if response_data:
                logger.error(f"[{self.name}] Failed response data: {response_data}")
            raise

        return result

    async def get_or_create_enterprise_session(self) -> aiohttp.ClientSession:
        """
        CRITICAL FIX: Get or create optimized session with connection pooling
        –ó–ê–ú–ï–ù–Ø–ï–¢ —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É –Ω–∞ enterprise-grade —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏—è–º–∏
        """
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ enterprise connector
        if not hasattr(self, 'enterprise_connector'):
            # –°–æ–∑–¥–∞–µ–º enterprise connector –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            self.enterprise_connector = EnterpriseBybitConnector()
    
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º optimized session
        return await self.enterprise_connector.create_session()

    async def cleanup_connections(self):
        """
        CRITICAL: Proper cleanup of all connections
        """
        try:
            # Cleanup enterprise connector
            if hasattr(self, 'enterprise_connector'):
                await self.enterprise_connector.close()
        
            # Cleanup old session if exists
            if hasattr(self, 'session') and not self.session.closed:
                await self.session.close()
            
            logger.info(f"{self.name} - All connections cleaned up")
        
        except Exception as e:
            logger.error(f"{self.name} - Error cleaning up connections: {e}")

    async def cleanup(self):
        """
        Alias: –≤–Ω–µ—à–Ω–∏–π ‚Äú—á–∏—Å—Ç—ã–π‚Äù shutdown –∫–ª–∏–µ–Ω—Ç–∞.
        –î–µ–ª–∞–µ—Ç —Ç–æ –∂–µ —Å–∞–º–æ–µ, —á—Ç–æ cleanup_connections().
        """
        try:
            await self.cleanup_connections()
        except Exception as e:
            logger.error(f"{self.name} - Error in cleanup(): {e}")


    def get_connection_stats(self) -> Dict[str, Any]:
        """Get comprehensive connection statistics"""
        stats = {
            'request_stats': self.request_stats,
            'enterprise_connector': None,
            'rate_limiter': None
        }
    
        if hasattr(self, 'enterprise_connector'):
            stats['enterprise_connector'] = self.enterprise_connector.connection_stats
    
        if hasattr(self.rate_limiter, 'get_performance_stats'):
            stats['rate_limiter'] = self.rate_limiter.get_performance_stats()
    
        return stats

    async def _make_request_with_detailed_timing(self, method: str, endpoint: str, params: dict = None, data: dict = None) -> dict:
        """
        üî¨ PERFORMANCE PROFILING: –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    
        CRITICAL FIX: Updated to use EnterpriseBybitConnector instead of temporary sessions
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –¥–æ–±–∞–≤–ª—è–µ—Ç detailed timing –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ performance –ø—Ä–æ–±–ª–µ–º
        """
        timings = {
            'rate_limiting': 0,
            'time_sync': 0, 
            'request_prep': 0,
            'session_acquire': 0,
            'http_request': 0,
            'http_response': 0,
            'total_time': 0
        }

        overall_start = time.time()
        result = None

        try:
            # Rate limiting
            rate_start = time.time()
            await self.rate_limiter.acquire()
            timings['rate_limiting'] = time.time() - rate_start
    
            # Time synchronization
            sync_start = time.time()
            await self.time_sync.ensure_time_sync(self.api_url)  # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
            server_time = self.time_sync.get_server_time()       # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è
            timings['time_sync'] = time.time() - sync_start
    
            # Request preparation
            prep_start = time.time()
            timestamp = str(server_time)
            recv_window = str(BYBIT_RECV_WINDOW)
    
            url = f"{self.api_url}/v5/{endpoint}"
            query_string = ""
            body = ""
    
            # DIAGNOSTIC: Log market/tickers requests with category
            if endpoint == "market/tickers" and params:
                logger.info(f"{self.name} - Requesting market/tickers with category: {params.get('category', 'MISSING')} for symbol: {params.get('symbol', 'N/A')}")
            # Prevent double v5 prefix
            if endpoint.startswith("v5/"):
                endpoint = endpoint[3:]  # Remove v5/ prefix if already present

            if method == "GET" and params:
                sorted_params = dict(sorted(params.items()))
                query_string = urlencode(sorted_params)
                url += f"?{query_string}"
            elif method == "POST" and data:
                body = json.dumps(data)
    
            # Generate signature
            signature = self._generate_signature(timestamp, recv_window, query_string, body)
    
            headers = {
                'X-BAPI-API-KEY': self.api_key,
                'X-BAPI-SIGN': signature,
                'X-BAPI-SIGN-TYPE': '2',
                'X-BAPI-TIMESTAMP': timestamp,
                'X-BAPI-RECV-WINDOW': recv_window,
                'Content-Type': 'application/json'
            }
    
            timings['request_prep'] = time.time() - prep_start
    
            # CRITICAL FIX: Use enterprise session instead of old session management
            session_start = time.time()
            session = await self.get_or_create_enterprise_session()
            timings['session_acquire'] = time.time() - session_start
    
            # HTTP Request with circuit breaker protection
            http_start = time.time()
        
            # CRITICAL FIX: Execute request with resilience manager
            async def _execute_http_request():
                if method == "GET":
                    async with session.get(url, headers=headers) as response:
                        timings['http_request'] = time.time() - http_start
                
                        response_start = time.time()
                        response_text = await response.text()
                        timings['http_response'] = time.time() - response_start
                
                        # CRITICAL FIX: Update rate limiter with response headers
                        if hasattr(self.rate_limiter, 'update_from_response_headers') and response.headers:
                            try:
                                self.rate_limiter.update_from_response_headers(
                                    dict(response.headers), 
                                    endpoint
                                )
                            except Exception as e:
                                logger.debug(f"{self.name} - Error processing response headers: {e}")
                
                        if response.status != 200:
                            raise Exception(f"HTTP {response.status}: {response_text}")
                
                        try:
                            result = json.loads(response_text)
                            return result, response_text
                        except json.JSONDecodeError as e:
                            raise Exception(f"Invalid JSON: {e}")
                
                elif method == "POST":
                    async with session.post(url, headers=headers, data=body) as response:
                        timings['http_request'] = time.time() - http_start
                
                        response_start = time.time()
                        response_text = await response.text()
                        timings['http_response'] = time.time() - response_start
                
                        # CRITICAL FIX: Update rate limiter with response headers
                        if hasattr(self.rate_limiter, 'update_from_response_headers') and response.headers:
                            try:
                                self.rate_limiter.update_from_response_headers(
                                    dict(response.headers), 
                                    endpoint
                                )
                            except Exception as e:
                                logger.debug(f"{self.name} - Error processing response headers: {e}")
                
                        if response.status != 200:
                            raise Exception(f"HTTP {response.status}: {response_text}")
                
                        try:
                            result = json.loads(response_text)
                            return result, response_text
                        except json.JSONDecodeError as e:
                            raise Exception(f"Invalid JSON: {e}")
        
            # CRITICAL FIX: Execute with circuit breaker protection
            result, response_text = await self.resilience_manager.call_with_circuit_breaker(_execute_http_request)
    
            # Check API response
            if result.get('retCode') != 0:
                error_msg = result.get('retMsg', 'Unknown API error')
                raise Exception(f"API error: {error_msg}")
    
            timings['total_time'] = time.time() - overall_start
    
            # –õ–æ–≥–∏—Ä—É–µ–º detailed timings –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –º–µ–¥–ª–µ–Ω–Ω—ã–π
            if timings['total_time'] > 5.0:  # –ú–µ–¥–ª–µ–Ω–Ω–µ–µ 5 —Å–µ–∫—É–Ω–¥
                logger.warning(f"SLOW REQUEST DETECTED: {method} {endpoint}")
                logger.warning(f"Timing breakdown: {timings}")
                logger.warning(f"URL: {url}")
                logger.warning(f"Response size: {len(response_text) if 'response_text' in locals() else 0} bytes")
            
                # CRITICAL FIX: Log enterprise connector stats for slow requests
                if hasattr(self, 'enterprise_connector') and self.enterprise_connector:
                    connector_stats = self.enterprise_connector.connection_stats
                    logger.warning(f"Connection stats: {connector_stats}")
            elif timings['total_time'] > 2.0:  # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ > 2s
                logger.info(f"MODERATE DELAY: {method} {endpoint} took {timings['total_time']:.3f}s")
                logger.debug(f"Timing breakdown: {timings}")
    
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.request_stats['total_requests'] += 1
            self.request_stats['successful_requests'] += 1
    
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞
            total_requests = self.request_stats['total_requests']
            old_avg = self.request_stats.get('avg_response_time', 0)
            self.request_stats['avg_response_time'] = (old_avg * (total_requests - 1) + timings['total_time']) / total_requests
        
            # CRITICAL FIX: Update enterprise connector stats
            if hasattr(self, 'enterprise_connector') and self.enterprise_connector:
                self.enterprise_connector.connection_stats['total_requests'] += 1
                if timings.get('session_acquire', 0) < 0.001:  # Session was reused
                    self.enterprise_connector.connection_stats['reused_connections'] += 1
                else:  # New connection created
                    self.enterprise_connector.connection_stats['new_connections'] += 1
    
            logger.debug(f"‚úÖ {method} {endpoint} completed in {timings['total_time']:.3f}s (Enterprise mode)")
    
            return result.get('result', {})
    
        except Exception as e:
            timings['total_time'] = time.time() - overall_start
    
            self.request_stats['total_requests'] += 1
            self.request_stats['failed_requests'] += 1
            self.request_stats['last_error'] = str(e)
    
            logger.error(f"Request failed: {method} {endpoint}")
            logger.error(f"Error: {e}")
            logger.error(f"Total time before failure: {timings['total_time']:.3f}s")
            logger.error(f"Detailed timings: {timings}")
        
            # CRITICAL FIX: Log circuit breaker state on failure
            if hasattr(self, 'resilience_manager'):
                circuit_state = self.resilience_manager.state
                failure_count = self.resilience_manager.failure_count
                logger.error(f"Circuit breaker state: {circuit_state.value}, failure count: {failure_count}")
    
            raise

    def _update_response_time_stats(self, response_time: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞"""
        if self.request_stats['avg_response_time'] == 0:
            self.request_stats['avg_response_time'] = response_time
        else:
            # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
            self.request_stats['avg_response_time'] = (
                self.request_stats['avg_response_time'] * 0.9 + response_time * 0.1
            )
    
    # –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã API (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô - –†–ê–ë–û–¢–ê–Æ–¢ –ö–û–†–†–ï–ö–¢–ù–û)
    async def get_balance(self) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –±–∞–ª–∞–Ω—Å USDT (V5, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–æ–¥–ø–∏—Å—å –∏ –æ–∫–Ω–æ, –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π query)"""
        try:
            params = {
                "accountType": "UNIFIED",
                "coin": "USDT",
            }

            # 1) –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –≤—Ä–µ–º–µ–Ω–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Ä–≤–µ—Ä–Ω—ã–π –æ—Ñ—Ñ—Å–µ—Ç)
            await self.time_sync.ensure_time_sync(self.api_url)
            timestamp = str(self.time_sync.get_server_timestamp())  # ms

            # 2) –£–≤–µ–ª–∏—á–∞–µ–º –æ–∫–Ω–æ –¥–æ 20s (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ —Å–µ—Ç–µ–≤–æ–º—É –¥–∂–∏—Ç—Ç–µ—Ä—É)
            recv_window = str(BYBIT_RECV_WINDOW)

            # 3) –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π queryString (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∫–ª—é—á–µ–π + URL-encoding)
            #    –í–∞–∂–Ω–æ: –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç string —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ –ø–æ–¥–ø–∏—Å–∏ V5
            from urllib.parse import quote_plus
            query_items = [f"{k}={quote_plus(str(params[k]))}" for k in sorted(params)]
            query_string = "&".join(query_items)

            url = f"{self.api_url}/v5/account/wallet-balance?{query_string}"

            # 4) –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–æ–¥–ø–∏—Å—å (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ‚Üí –±–µ–∑ await)
            signature = self._generate_signature(timestamp, recv_window, query_string, "")

            headers = {
                "X-BAPI-API-KEY": self.api_key,
                "X-BAPI-TIMESTAMP": timestamp,
                "X-BAPI-RECV-WINDOW": recv_window,
                "X-BAPI-SIGN": signature,
                "Content-Type": "application/json",
            }

            self.request_stats['total_requests'] += 1
            session = await self.get_or_create_enterprise_session()

            async with session.get(url, headers=headers) as response:
                response_text = await response.text()

                if hasattr(self.rate_limiter, 'update_from_response_headers') and response.headers:
                    try:
                        self.rate_limiter.update_from_response_headers(
                            dict(response.headers), 
                            "account/wallet-balance"
                        )
                    except Exception as e:
                        logger.debug(f"{self.name} - Error processing response headers: {e}")

                if response.status == 200:
                    try:
                        result = json.loads(response_text)
                        if result and result.get('retCode') == 0:
                            accounts = result.get('result', {}).get('list', [])
                            if accounts:
                                for coin in accounts[0].get('coin', []):
                                    if coin.get('coin') == 'USDT':
                                        balance = safe_float(coin.get('walletBalance', 0))
                                        logger.info(f"{self.name} - Balance: {balance:.2f} USDT")
                                        self.request_stats['successful_requests'] += 1
                                        return balance
                            logger.warning(f"{self.name} - No USDT balance found")
                            self.request_stats['successful_requests'] += 1
                            return 0.0

                        logger.error(f"{self.name} - API retCode != 0: {result}")
                        self.request_stats['failed_requests'] += 1
                        return 0.0

                    except json.JSONDecodeError as e:
                        logger.error(f"{self.name} - Invalid JSON response: {e}")
                        self.request_stats['failed_requests'] += 1
                        return 0.0

                else:
                    logger.error(f"{self.name} - HTTP {response.status}: {response_text}")
                    self.request_stats['failed_requests'] += 1
                    return 0.0

        except Exception as e:
            logger.error(f"{self.name} - Balance error: {e}")
            self.request_stats['failed_requests'] += 1
            return 0.0

    
    async def get_positions(self, category: str = "linear", symbol: str = None, settleCoin: str = "USDT") -> List[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–∫—Ä—ã—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        try:
            params = {
                "category": category,
                "settleCoin": settleCoin,
                "limit": 50
            }
            if symbol:
                params['symbol'] = symbol
            
            result = await self._make_request_with_retry("GET", "position/list", params)
            
            if result and result.get('retCode') == 0:
                positions = result.get('result', {}).get('list', [])
                active_positions = []
                
                for pos in positions:
                    size = safe_float(pos.get('size', 0))
                    if size > 0:
                        active_positions.append(pos)
                
                logger.info(f"{self.name} - Found {len(active_positions)} active positions")
                return active_positions
            
            return []
            
        except Exception as e:
            logger.error(f"{self.name} - Positions error: {e}")
            return []
    
    async def get_recent_trades(self, limit: int = 50) -> List[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        try:
            params = {
                "category": "linear",
                "limit": limit
            }
            
            result = await self._make_request_with_retry("GET", "execution/list", params)
            
            if result and result.get('retCode') == 0:
                trades = result.get('result', {}).get('list', [])
                logger.debug(f"{self.name} - Retrieved {len(trades)} recent trades")
                return trades
            
            return []
            
        except Exception as e:
            logger.error(f"{self.name} - Recent trades error: {e}")
            return []

    async def place_order(self, category: str, symbol: str, side: str, orderType: str, qty: str, reduceOnly: bool = False, **kwargs) -> Optional[dict]:
        """Place an order."""
        try:
            data = {
                "category": category,
                "symbol": symbol,
                "side": side,
                "orderType": orderType,
                "qty": str(qty),
                "reduceOnly": reduceOnly,
            }
            data.update(kwargs)

            logger.info(f"{self.name} - Placing order: {symbol} {side} {qty} {orderType}")
            result = await self._make_request_with_retry("POST", "order/create", data=data)

            if result and result.get('retCode') == 0:
                logger.info(f"{self.name} - Order placed successfully: {result.get('result')}")
                return result.get('result')
            else:
                error_msg = result.get('retMsg', 'Unknown error') if result else 'No response'
                logger.error(f"{self.name} - Failed to place order: {error_msg}")
                return None

        except Exception as e:
            logger.error(f"{self.name} - Order placement error: {e}", exc_info=True)
            return None

    async def set_leverage(self, category: str, symbol: str, leverage: str, on_success_callback: Optional[Callable] = None) -> dict:
        """Sets leverage and calls a callback on success. Returns the raw API response."""
        try:
            data = {
                "category": category,
                "symbol": symbol,
                "buyLeverage": str(leverage),
                "sellLeverage": str(leverage),
            }
            logger.info(f"{self.name} - Setting leverage for {symbol} to {leverage}x")

            result = await self._make_single_request(
                "POST",
                "position/set-leverage",
                data=data,
                allow_ret_codes=[110043]
            )

            ret_code = (result or {}).get("retCode")

            if ret_code == 110043:
                logger.info(f"Leverage for {symbol} is already {leverage}x (retCode: 110043).")
            else:
                logger.info(f"Leverage for {symbol} set to {leverage}x (retCode: {ret_code}).")

            if on_success_callback:
                try:
                    on_success_callback(symbol, int(leverage))
                except Exception as cb_exc:
                    logger.error(f"Error in set_leverage on_success_callback: {cb_exc}", exc_info=True)

            return result

        except Exception as e:
            logger.error(f"{self.name} - Set leverage error for {symbol}: {e}", exc_info=True)
            return {"retCode": -1, "retMsg": str(e), "result": {}}

    async def add_margin(self, symbol: str, margin: str, position_idx: int = 0) -> dict:
        """Adds margin to an isolated margin position."""
        try:
            data = {
                "category": "linear",
                "symbol": symbol,
                "margin": str(margin),
                "positionIdx": position_idx,
            }
            logger.info(f"{self.name} - Adding margin to {symbol}: {margin} USDT")
            result = await self._make_single_request("POST", "position/add-margin", data=data)

            ret_code = (result or {}).get("retCode")
            ret_msg = (result or {}).get("retMsg", "Unknown error")

            if ret_code == 0:
                logger.info(f"Successfully added margin to {symbol}.")
                return {"success": True, "result": result}
            else:
                logger.error(f"Failed to add margin to {symbol}: {ret_msg} (retCode: {ret_code})")
                return {"success": False, "error": ret_msg, "result": result}

        except Exception as e:
            logger.error(f"{self.name} - Add margin error for {symbol}: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    async def close_all_positions_by_market(self) -> Tuple[int, int]:
        """Closes all open linear positions by market order."""
        closed_count = 0
        errors_count = 0
        logger.warning(f"{self.name} - Initiating PANIC CLOSE of all positions.")

        try:
            positions = await self.get_positions()
            if not positions:
                logger.info(f"{self.name} - No open positions to close.")
                return 0, 0

            for pos in positions:
                symbol = pos.get('symbol')
                size = pos.get('size')
                side = pos.get('side')

                if not symbol or not size or not side:
                    logger.warning(f"{self.name} - Skipping invalid position: {pos}")
                    continue

                close_side = "Sell" if side == "Buy" else "Buy"

                try:
                    result = await self.place_order(
                        category='linear',
                        symbol=symbol,
                        side=close_side,
                        orderType='Market',
                        qty=str(size),
                        reduceOnly=True
                    )
                    if result and result.get('orderId'):
                        logger.info(f"{self.name} - Successfully placed closing order for {symbol}. Order ID: {result.get('orderId')}")
                        closed_count += 1
                    else:
                        logger.error(f"{self.name} - Failed to place closing order for {symbol}. Result: {result}")
                        errors_count += 1

                    await asyncio.sleep(0.2)

                except Exception as e:
                    logger.error(f"{self.name} - Error closing position for {symbol}: {e}", exc_info=True)
                    errors_count += 1

        except Exception as e:
            logger.error(f"{self.name} - Critical error during close_all_positions_by_market: {e}", exc_info=True)
            errors_count += len(positions) - closed_count

        logger.warning(f"{self.name} - Panic close summary: Closed={closed_count}, Errors={errors_count}")
        return closed_count, errors_count
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–ª–∏–µ–Ω—Ç–∞ (–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π success_rate 0..100%)"""
        stats = self.request_stats.copy()

        total = int(stats.get('total_requests', 0) or 0)
        ok    = int(stats.get('successful_requests', 0) or 0)

        if total > 0:
            # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–≥—Ä–∞–Ω–∏—á–∏–º ok –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö [0, total]
            if ok < 0:
                ok = 0
            elif ok > total:
                ok = total
            rate = (ok / total) * 100.0
        else:
            # –Ω–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Äî —Å—á–∏—Ç–∞–µ–º —Å–∏—Å—Ç–µ–º—É ¬´—á–∏—Å—Ç–æ–π¬ª
            rate = 100.0

        # –∂—ë—Å—Ç–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è 0..100
        stats['success_rate'] = max(0.0, min(100.0, rate))

        # –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
        avg = stats.get('avg_response_time')
        if avg is None or (isinstance(avg, (int, float)) and avg < 0):
            stats['avg_response_time'] = 0.0

        return stats


# ================================
# ‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê WEBSOCKET (—Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∏–∫—Å–∞–º–∏)
# ================================

class FinalFixedWebSocketManager:
    """
    ‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Å–∏—Å—Ç–µ–º–∞ WebSocket —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∏–∫—Å–∞–º–∏
    
    –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–∞ is_websocket_open() –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
    - ‚úÖ –ó–∞–º–µ–Ω–µ–Ω–∞ close_websocket_safely() –Ω–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
    - ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–≤–æ–π—Å—Ç–≤–æ closed –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏
    - ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    - ‚úÖ –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å websockets 15.0.1
    """
    
    def __init__(self, api_key: str, api_secret: str, name: str = "websocket", copy_state=None, final_monitor=None):
        self.api_key = api_key
        self.api_secret = api_secret
        self.name = name
        self.copy_state = copy_state
        self.final_monitor = final_monitor
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ WebSocket
        self.ws = None
        self.status = ConnectionStatus.DISCONNECTED
        
        # ‚úÖ ping/pong –∞—Ç—Ä–∏–±—É—Ç—ã (–∫–∞–∫ –≤ —Ç–µ—Å—Ç–µ—Ä–µ)
        self.last_ping = 0
        self.last_pong = 0
        self.ping_timeout = WEBSOCKET_PONG_TIMEOUT
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏
        self.active_tasks = set()
        self.should_stop = False
        self._heartbeat_task = None
        
        # –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        self.reconnect_attempt = 0
        self.max_reconnect_attempts = MAX_RECONNECT_ATTEMPTS
        self.reconnect_delays = RECONNECT_DELAYS
        
        # –ü–æ–¥–ø–∏—Å–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        self.subscriptions = {} # –ö–∞—Ä—Ç–∞ —Ç–æ–ø–∏–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–ø–æ–¥–ø–∏—Å–∫–∏ topic -> params
        self.message_handlers = {}
        self.message_buffer = deque(maxlen=1000)
        # –ù–æ–≤–æ–µ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º WebSocket
        # –ö–†–ò–¢–ò–ß–ù–û: –î–æ–±–∞–≤–∏—Ç—å –æ—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ get_stats)
        self.message_queue = asyncio.Queue(maxsize=1000)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è _position_states (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ _handle_position_update)
        self._position_states = {}
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –∏–∑ –ø–∞—Ç—á–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        self._event_cache = OrderedDict()
        self._event_cache_ttl = 300  # 5 –º–∏–Ω—É—Ç TTL
        self._max_cache_size = 10000
        
        # –§–ª–∞–≥ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ø–ª–µ—á–∞
        self.copy_leverage = os.getenv('COPY_LEVERAGE', 'true').lower() == 'true'
        
        # –û—á–µ—Ä–µ–¥—å –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è)
        self._copy_queue = asyncio.Queue(maxsize=1000)
        self._copy_processor_task = None
        
        # –ü–æ—Å–ª–µ–¥–Ω—è—è —Ä–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
        self._last_resync = 0
        self._resync_interval = 60
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'ws_received_total': 0,
            'ws_processed_private': 0,
            'messages_received': 0,
            'messages_processed': 0,
            'connection_drops': 0,
            'last_message_time': 0,
            'uptime_start': time.time(),
            'ping_pong_success': 0,
            'ping_pong_failures': 0,
            'topic_counts': defaultdict(lambda: {'received': 0, 'processed': 0})
        }
        
        # –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        self.processing_active = False
        
        logger.info(f"{self.name} - WebSocket manager initialized (websockets v{get_websockets_version()})")
    
    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —Å–≤–æ–π—Å—Ç–≤–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏ 
    @property
    def closed(self) -> bool:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ç–µ—Å—Ç–∞–º–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é"""
        return not is_websocket_open(self.ws)

    async def connect(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ - —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∏–∫—Å–∞–º–∏"""
        try:
            if self.status == ConnectionStatus.CONNECTING:
                logger.debug(f"{self.name} - Already connecting, skipping")
                return
                
            self.status = ConnectionStatus.CONNECTING
            logger.info(f"{self.name} - Connecting to WebSocket...")
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –±–µ–∑ asyncio.wait_for –æ–±–µ—Ä—Ç–∫–∏
            self.ws = await websockets.connect(
                SOURCE_WS_URL,
                ping_interval=None,      # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –æ—Ç–∫–ª—é—á–∞–µ–º WebSocket –∞–≤—Ç–æ–ø–∏–Ω–≥
                ping_timeout=None,       # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –æ—Ç–∫–ª—é—á–∞–µ–º WebSocket –∞–≤—Ç–æ—Çimeout  
                close_timeout=10,        # –¢–æ–ª—å–∫–æ close timeout
                max_size=1048576,        # 1MB max message size
                max_queue=16             # Max queued messages
            )
            
            self.status = ConnectionStatus.CONNECTED
            logger.info(f"{self.name} - ‚úÖ WebSocket connected (auto ping/pong DISABLED)")
            
            # ‚úÖ –î–ò–ê–ì–ù–û–°–¢–ò–†–£–ï–ú WEBSOCKET –û–ë–™–ï–ö–¢
            await diagnose_websocket_issue(self.ws, f"{self.name}_Connected")
            
            # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
            await self._authenticate_bybit_v5()
            
            # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —Å–æ–±—ã—Ç–∏—è
            await self._subscribe_to_events()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –¢–û–õ–¨–ö–û Bybit heartbeat (–ù–ï websockets ping)
            await self._start_heartbeat()
            
        except Exception as e:
            logger.error(f"{self.name} - Connection error: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            self.status = ConnectionStatus.ERROR
            raise
    
    async def _authenticate_bybit_v5(self):
        """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è Bybit API v5"""
        try:
            expires = int(time.time() * 1000) + 10000
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ–¥–ø–∏—Å—å –¥–ª—è Bybit API v5
            signature_payload = f"GET/realtime{expires}"
            signature = hmac.new(
                self.api_secret.encode("utf-8"),
                signature_payload.encode("utf-8"),
                hashlib.sha256
            ).hexdigest()
            
            auth_message = {
                "op": "auth",
                "args": [self.api_key, expires, signature]
            }
            
            logger.debug(f"{self.name} - Sending auth: {auth_message}")
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
            if not is_websocket_open(self.ws):
                raise Exception("WebSocket not open for authentication")
                
            await self.ws.send(json.dumps(auth_message))
            
            # –ñ–¥–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            try:
                response = await asyncio.wait_for(self.ws.recv(), timeout=10)
                auth_response = json.loads(response)
                
                logger.debug(f"{self.name} - Auth response: {auth_response}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ–π –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è Bybit v5
                is_authenticated = (
                    auth_response.get('success') is True or
                    auth_response.get('retCode') == 0 or
                    'success' in str(auth_response).lower()
                )
                
                if is_authenticated:
                    self.status = ConnectionStatus.AUTHENTICATED
                    if self.copy_state: self.copy_state.source_ws_ok = True
                    masked_key = f"{self.api_key[:6]}...{self.api_key[-4:]}" if self.api_key else "N/A"
                    logger.info(f"{self.name} - ‚úÖ WebSocket authenticated successfully for key {masked_key} (account_id={DONOR_ACCOUNT_ID})")
                else:
                    if self.copy_state: self.copy_state.source_ws_ok = False
                    raise Exception(f"Authentication failed: {auth_response}")
                    
            except asyncio.TimeoutError:
                if self.copy_state: self.copy_state.source_ws_ok = False
                raise Exception("Authentication timeout after 10 seconds")
                
        except Exception as e:
            if self.copy_state: self.copy_state.source_ws_ok = False
            logger.error(f"{self.name} - Authentication error: {e}")
            await send_telegram_alert(f"WebSocket authentication failed for {self.name}: {e}")
            raise
    
    async def _subscribe_to_events(self):
        """–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è —Å Performance Logging"""
    
        start_time = time.time()
        operation_name = "websocket_subscribe_to_events"
        success = False

        topics_to_subscribe = {
            "position": "position",
            "wallet": "wallet",
            "execution": "execution",
            "order": "order"
        }
    
        try:
            args = list(topics_to_subscribe.values())
            subscribe_message = {"op": "subscribe", "args": args}
        
            if not is_websocket_open(self.ws):
                raise Exception("WebSocket not open for subscription")
        
            await self.ws.send(json.dumps(subscribe_message))
            self.subscriptions.update(topics_to_subscribe)
        
            logger.info(f"{self.name} - Subscribed to: {args}")
            success = True
        
        except Exception as e:
            logger.error(f"{self.name} - Subscription error: {e}")
            if 'prod_logger' in globals():
                prod_logger.log_error(e, {'component': 'websocket_subscribe_to_events', 'websocket_name': self.name, 'subscriptions': args}, send_alert=True)
            raise
        
        finally:
            duration = time.time() - start_time
            if 'prod_logger' in globals():
                try:
                    prod_logger.log_performance(operation_name, duration, success, {
                        'websocket_name': self.name,
                        'subscriptions_count': len(topics_to_subscribe),
                        'subscriptions': list(topics_to_subscribe.keys()),
                        'subscribe_time_ms': round(duration * 1000, 2)
                    })
                except Exception as perf_log_error:
                    logger.debug(f"WebSocket subscribe performance logging error: {perf_log_error}")

    async def resubscribe_all(self):
        """–ü–µ—Ä–µ–ø–æ–¥–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –≤—Å–µ —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–æ–ø–∏–∫–∏."""
        if not self.subscriptions:
            logger.info(f"[{self.name}] No topics to resubscribe to.")
            return 0

        topics_to_resubscribe = list(self.subscriptions.values())
        subscribe_message = {"op": "subscribe", "args": topics_to_resubscribe}

        try:
            if not is_websocket_open(self.ws):
                raise ConnectionError("Cannot resubscribe, WebSocket is not open.")

            await self.ws.send(json.dumps(subscribe_message))

            num_resubscribed = len(topics_to_resubscribe)
            logger.info(f"HOT_RELOAD_WS_RESUBSCRIBED: Successfully sent resubscription request for {num_resubscribed} topics: {topics_to_resubscribe}")
            logger.info(f"WS_RESUBSCRIBED: topics={topics_to_resubscribe} count={num_resubscribed}")
            return num_resubscribed

        except Exception as e:
            logger.error(f"[{self.name}] HOT_RELOAD_WS_RESUBSCRIBE_FAILED: Failed to resubscribe to topics. Error: {e}", exc_info=True)
            raise
    
    async def _start_heartbeat(self):
        """–ó–∞–ø—É—Å–∫ heartbeat –º–µ—Ö–∞–Ω–∏–∑–º–∞"""
        try:
            if self._heartbeat_task and not self._heartbeat_task.done():
                self._heartbeat_task.cancel()
                
            self._heartbeat_task = asyncio.create_task(self._heartbeat_loop())
            self.active_tasks.add(self._heartbeat_task)
            logger.info(f"{self.name} - Bybit custom heartbeat started")
        except Exception as e:
            logger.error(f"{self.name} - Error starting heartbeat: {e}")
    
    async def _heartbeat_loop(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô heartbeat —Ü–∏–∫–ª —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∏–∫—Å–∞–º–∏"""
        try:
            while not self.should_stop and is_websocket_open(self.ws):
                await asyncio.sleep(WEBSOCKET_PING_INTERVAL)
                
                if is_websocket_open(self.ws) and not self.should_stop:
                    await self._send_bybit_ping()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º timeout pong
                    await asyncio.sleep(2)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ pong
                    if self.last_ping > 0 and self.last_pong < self.last_ping:
                        pong_delay = time.time() - self.last_ping
                        if pong_delay > self.ping_timeout:
                            logger.warning(f"{self.name} - Bybit pong timeout: {pong_delay:.1f}s")
                            self.stats['ping_pong_failures'] += 1
                            # –ù–µ —Ä–∞–∑—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—Ä–∞–∑—É, –¥–∞–µ–º –µ—â–µ –æ–¥–∏–Ω —à–∞–Ω—Å
                            if self.stats['ping_pong_failures'] > 3:
                                logger.error(f"{self.name} - Too many Bybit ping/pong failures")
                                break
                    
        except asyncio.CancelledError:
            logger.debug(f"{self.name} - Heartbeat cancelled")
        except Exception as e:
            logger.error(f"{self.name} - Heartbeat error: {e}")
        finally:
            if self._heartbeat_task in self.active_tasks:
                self.active_tasks.discard(self._heartbeat_task)
    
    async def _send_bybit_ping(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ç–ø—Ä–∞–≤–∫–∞ Bybit custom ping"""
        try:
            if is_websocket_open(self.ws):
                # Bybit —Ç—Ä–µ–±—É–µ—Ç –∏–º–µ–Ω–Ω–æ —Ç–∞–∫–æ–π —Ñ–æ—Ä–º–∞—Ç
                ping_message = {
                    "op": "ping",
                    "req_id": str(int(time.time() * 1000))
                }
            
                await self.ws.send(json.dumps(ping_message))
                self.last_ping = time.time()
                logger.debug(f"{self.name} - ‚úÖ Bybit custom ping sent: {ping_message}")
            
            else:
                logger.debug(f"{self.name} - Cannot send Bybit ping, WebSocket not open")
            
        except Exception as e:
            logger.error(f"{self.name} - Bybit ping error: {e}")
    
    # ‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ç–µ—Å—Ç–∞–º–∏
    async def _send_ping(self):
        """–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ç–µ—Å—Ç–∞–º–∏"""
        await self._send_bybit_ping()
    
    async def test_ping_pong(self, timeout=30.0):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Ç–µ—Å—Ç Bybit custom ping/pong"""
        try:
            if not is_websocket_open(self.ws):
                return False, "WebSocket not open"
        
            # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—Ä–µ–º—è –¥–æ ping
            ping_time = time.time()
        
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Bybit custom ping
            await self._send_bybit_ping()
        
            # –ñ–¥–µ–º pong —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º timeout
            start_wait = time.time()
            while time.time() - start_wait < timeout:
                if self.last_pong > ping_time:
                    delay = self.last_pong - ping_time  
                    return True, f"‚úÖ Bybit pong received in {delay:.3f}s"
                await asyncio.sleep(0.2)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 200ms
        
            return False, f"‚ùå Bybit pong timeout after {timeout}s"
        
        except Exception as e:
            return False, f"‚ùå Bybit ping/pong test error: {e}"

    async def _recv_loop(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π WebSocket.
        """
        logger.info(f"{self.name} - Starting WebSocket recv loop...")
        while not self.should_stop and is_websocket_open(self.ws):
            try:
                message = await asyncio.wait_for(self.ws.recv(), timeout=WEBSOCKET_TIMEOUT)
                
                # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç —Å—á–µ—Ç—á–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
                self.stats['ws_received_total'] = self.stats.get('ws_received_total', 0) + 1
                self.stats['messages_received'] = self.stats.get('messages_received', 0) + 1
                self.stats['last_message_time'] = time.time()
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—ã—Ä–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                logger.debug("RAW_WS_MSG %s", message[:800])

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
                await self._process_message(message)
                
            except asyncio.TimeoutError:
                # –¢–∞–π–º-–∞—É—Ç - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ should_stop
                continue
            except websockets.exceptions.ConnectionClosed as e:
                logger.warning(f"{self.name} - WebSocket connection closed in recv loop: {e}")
                self.stats['connection_drops'] = self.stats.get('connection_drops', 0) + 1
                if not self.should_stop:
                    asyncio.create_task(self._handle_disconnect(f"ConnectionClosed: {e.code}"))
                break
            except Exception as e:
                logger.error(f"{self.name} - Error in recv loop: {e}", exc_info=True)
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–æ—Å–ª–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –æ—à–∏–±–∫–∏
                await asyncio.sleep(1)
        
        logger.info(f"{self.name} - WebSocket recv loop stopped.")

    async def _process_message_queue(self):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        try:
            logger.info(f"{self.name} - Starting message queue processor")
            
            while not self.should_stop:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                    message = await asyncio.wait_for(
                        self.message_queue.get(),
                        timeout=1.0
                    )
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                    await self._process_message(message)
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                    self.stats['messages_processed'] = self.stats.get('messages_processed', 0) + 1
                    
                except asyncio.TimeoutError:
                    continue  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥–∏
                    
                except Exception as e:
                    logger.error(f"{self.name} - Queue processing error: {e}")
                    self.stats['processing_errors'] = self.stats.get('processing_errors', 0) + 1
                    
        except asyncio.CancelledError:
            logger.debug(f"{self.name} - Message processor cancelled")
            
        except Exception as e:
            logger.error(f"{self.name} - Fatal processor error: {e}")
            
        finally:
            # –û—á–∏—â–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è
            while not self.message_queue.empty():
                try:
                    self.message_queue.get_nowait()
                except:
                    break
            
            logger.info(f"{self.name} - Message queue processor stopped")

    async def _process_message(self, message: str):
        """
        ‚úÖ –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –æ–±–æ–∏—Ö –≤–µ—Ä—Å–∏–π + –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        start_time = time.time()
        operation_name = "websocket_handle_message"
        success = False

        try:
            # –õ–æ–≥–∏—Ä—É–µ–º –í–ï–°–¨ –≤—Ö–æ–¥—è—â–∏–π —Ç—Ä–∞—Ñ–∏–∫ –¥–ª—è –ø–æ–ª–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            logger.info(f"[{self.name}] RAW WS MSG: {message}")
            self.stats['raw_message_count'] = self.stats.get('raw_message_count', 0) + 1

            data = json.loads(message)

            # –ë—É—Ñ–µ—Ä–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            self.message_buffer.append({'timestamp': time.time(), 'data': data})

            # –ö—Ä–∏—Ç–∏—á–Ω–æ: –æ–±—Ä–∞–±–æ—Ç–∫–∞ Bybit pong
            if self._handle_bybit_pong_message(data):
                success = True
                return  # —ç—Ç–æ pong

            # === –ì–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ===
            if 'topic' in data:
                topic = data['topic']
                if topic in ["position", "wallet", "execution", "order"]:
                    self.stats['ws_processed_private'] = self.stats.get('ws_processed_private', 0) + 1

                self.stats['topic_counts'][topic]['received'] += 1
                logger.info(f"[{self.name}] Received message for topic: '{topic}'")

                # –°—Ç—Ä–æ–≥–∏–π —Ä–æ—É—Ç–µ—Ä: –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–ø–∏–∫–∏ (snapshot, query, periodic)
                if '.' in topic:
                    logger.debug(f"[{self.name}] Ignoring service topic with '.' in name: '{topic}'")
                    return

                handler_called = False
                if topic == "position":
                    logger.info(f"[{self.name}] Routing to position handler.")
                    await self._handle_position_update(data)
                    handler_called = True
                elif topic == "execution":
                    logger.info(f"[{self.name}] Routing to execution handler.")
                    await self._handle_execution_update(data)
                    handler_called = True
                elif topic == "order":
                    logger.info(f"[{self.name}] Routing to order handler.")
                    await self._handle_order_update(data)
                    handler_called = True
                elif topic == "wallet":
                    logger.info(f"[{self.name}] Routing to wallet handler.")
                    await self._handle_wallet_update(data)
                    handler_called = True
                else:
                    logger.debug(f"[{self.name}] Unknown or unhandled topic: '{topic}'")

                # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ —Ç–æ–ª—å–∫–æ –¥–ª—è —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–æ–ø–∏–∫–æ–≤
                if handler_called:
                    self.stats['messages_processed'] = self.stats.get('messages_processed', 0) + 1
                    self.stats['topic_counts'][topic]['processed'] += 1

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            elif data.get('op') == 'subscribe':
                if data.get('success'):
                    logger.info(f"{self.name} - ‚úÖ Subscription confirmed: {data}")
                else:
                    logger.error(f"{self.name} - ‚ùå Subscription failed: {data}")

            elif data.get('op') == 'auth':
                if data.get('success'):
                    logger.info(f"{self.name} - ‚úÖ Authentication confirmed")
                else:
                    logger.error(f"{self.name} - ‚ùå Authentication failed: {data}")

            success = True

        except json.JSONDecodeError as e:
            logger.error(f"{self.name} - JSON decode error: {e}")
            logger.debug(f"Raw message: {message[:200]}...")

            if hasattr(self, 'sys_logger'):
                self.sys_logger.log_error("WebSocket", f"JSON decode error: {str(e)}", {
                    "message_preview": message[:100],
                    "websocket_name": self.name
                })

            if 'prod_logger' in globals():
                prod_logger.log_error(e, {
                    'component': 'websocket_message_processing',
                    'message_preview': message[:100],
                    'websocket_name': self.name
                }, send_alert=False)

        except Exception as e:
            logger.error(f"{self.name} - Message processing error: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")

            if hasattr(self, 'sys_logger'):
                self.sys_logger.log_error("WebSocket", str(e), {
                    "message_type": data.get('topic', 'unknown') if 'data' in locals() else 'parse_failed',
                    "websocket_name": self.name
                })

            if 'prod_logger' in globals():
                prod_logger.log_error(e, {
                    'component': 'websocket_message_processing',
                    'websocket_name': self.name,
                    'message_type': data.get('topic', 'unknown') if 'data' in locals() else 'unknown'
                }, send_alert=True)

        finally:
            duration = time.time() - start_time
            if duration > 0.1:
                logger.warning(f"{self.name} - Slow message processing: {duration:.3f}s")

            if 'prod_logger' in globals():
                try:
                    prod_logger.log_performance(
                        operation_name, duration, success,
                        {
                            'websocket_name': self.name,
                            'message_size': len(message) if message else 0,
                            'processing_time_ms': round(duration * 1000, 2)
                        }
                    )
                except Exception as perf_log_error:
                    logger.debug(f"WebSocket performance logging error: {perf_log_error}")


    # ===============================
    # 2. –î–û–ë–ê–í–ò–¢–¨ –ù–û–í–´–ô –ú–ï–¢–û–î send_message() 
    # ===============================

    async def send_message(self, message: dict) -> bool:
        """
        ‚úÖ –ù–û–í–´–ô –ú–ï–¢–û–î: –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ WebSocket —Å Performance Logging
    
        Args:
            message: –°–ª–æ–≤–∞—Ä—å —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
    
        Returns:
            bool: True –µ—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ
        """
    
        # ‚úÖ Performance tracking - –Ω–∞—á–∞–ª–æ (—É–∂–µ –µ—Å—Ç—å)
        start_time = time.time()
        operation_name = "websocket_send_message"
        success = False
    
        try:
            if not self.ws or not is_websocket_open(self.ws):
                logger.warning(f"{self.name} - Cannot send message: WebSocket not connected")
                return False
        
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON
            json_message = json.dumps(message)
        
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            await self.ws.send(json_message)
        
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats['messages_sent'] = self.stats.get('messages_sent', 0) + 1
            logger.debug(f"{self.name} - Message sent: {message}")
        
            success = True
            return True
        
        except websockets.exceptions.ConnectionClosed as e:
            logger.error(f"{self.name} - Connection closed while sending: {e}")
        
            # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –ë–î
            sys_logger.log_error("WebSocket", f"Connection closed during send: {str(e)}", {
                "websocket_name": self.name,
                "message_type": message.get('op', 'unknown')
            })
        
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É —Å prod_logger
            if 'prod_logger' in globals():
                prod_logger.log_error(e, {
                    'component': 'websocket_send',
                    'websocket_name': self.name,
                    'message_type': message.get('op', 'unknown')
                }, send_alert=True)
            return False
        
        except Exception as e:
            logger.error(f"{self.name} - Send message error: {e}")
        
            # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º –æ–±—â—É—é –æ—à–∏–±–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –ë–î
            sys_logger.log_error("WebSocket", f"Send error: {str(e)}", {
                "websocket_name": self.name,
                "message_size": len(json_message) if 'json_message' in locals() else 0
            })
        
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É —Å prod_logger
            if 'prod_logger' in globals():
                prod_logger.log_error(e, {
                    'component': 'websocket_send',
                    'websocket_name': self.name,
                    'message_size': len(json_message) if 'json_message' in locals() else 0
                }, send_alert=True)
            return False
        
        finally:
            # ‚úÖ Performance logging (—É–∂–µ –µ—Å—Ç—å, –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º)
            duration = time.time() - start_time
        
            if 'prod_logger' in globals():
                try:
                    prod_logger.log_performance(operation_name, duration, success, {
                        'websocket_name': self.name,
                        'message_type': message.get('op', 'unknown'),
                        'message_size': len(json.dumps(message)) if message else 0,
                        'send_time_ms': round(duration * 1000, 2)
                    })
                except Exception as perf_log_error:
                    logger.debug(f"WebSocket send performance logging error: {perf_log_error}")

    
    def _handle_bybit_pong_message(self, data: dict) -> bool:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ Bybit pong - —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ —Ç–µ—Å—Ç–µ—Ä–µ"""
        try:
            # –¢–æ—á–Ω–æ —Ç–∞–∫–∞—è –∂–µ –ª–æ–≥–∏–∫–∞ –∫–∞–∫ –≤ —Ç–µ—Å—Ç–µ—Ä–µ
            is_bybit_pong = (
                (data.get('op') == 'ping' and data.get('ret_msg') == 'pong') or
                (data.get('op') == 'pong') or 
                (data.get('success') is True and data.get('ret_msg') == 'pong') or
                (data.get('retCode') == 0 and data.get('op') == 'pong')
            )
            
            if is_bybit_pong:
                self.last_pong = time.time()
                self.stats['ping_pong_success'] += 1
                self.stats['ping_pong_failures'] = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á
                
                if self.last_ping > 0:
                    ping_delay = self.last_pong - self.last_ping
                    logger.debug(f"{self.name} - ‚úÖ Bybit pong received: delay={ping_delay:.3f}s")
                
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"{self.name} - Error handling Bybit pong: {e}")
            return False

    async def _escalate_shutdown_after_timeout(self, timeout_seconds: int):
        """
        Schedules a graceful shutdown if the connection is not restored within the timeout.
        This is designed to be called from a non-blocking task.
        """
        try:
            logger.warning(f"WS_ESCALATE_SCHEDULED: Escalation to restart scheduled in {timeout_seconds}s.")
            await asyncio.sleep(timeout_seconds)

            # Check status again after waiting
            if not is_websocket_open(self.ws):
                logger.error(f"WS_ESCALATE_TRIGGER: WebSocket still disconnected after {timeout_seconds}s. Triggering monitor restart.")
                self.stats['ws_escalations_total'] = self.stats.get('ws_escalations_total', 0) + 1

                # Safely call monitor restart methods if the monitor reference exists
                if hasattr(self, 'final_monitor') and self.final_monitor:
                    if hasattr(self.final_monitor, "request_graceful_restart"):
                        await self.final_monitor.request_graceful_restart(reason="ws_escalation_timeout")
                    elif hasattr(self.final_monitor, "_request_full_restart"):
                        await self.final_monitor._request_full_restart("ws_escalation_timeout")
                    else:
                        logger.warning("No restart hook available on monitor; escalation logged only.")
                else:
                    logger.warning("final_monitor reference not found; escalation logged only.")
            else:
                logger.info("WS_ESCALATE_ABORTED: WebSocket reconnected before escalation timeout.")

        except asyncio.CancelledError:
            logger.info("WS_ESCALATE_ABORTED: Shutdown escalation task was cancelled.")
        except Exception as e:
            logger.error(f"Error in _escalate_shutdown_after_timeout: {e}", exc_info=True)
    
    # ============================================================
    #  WS: –õ–Å–ì–ö–ò–ô –•–≠–ù–î–õ–ï–† –ü–û–ó–ò–¶–ò–ô + –§–û–ù–û–í–´–ô –í–û–†–ö–ï–† –ó–ê–ü–ò–°–ò –í –ë–î
    #  –û—á–µ—Ä–µ–¥—å/–≤–æ—Ä–∫–µ—Ä—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –∏ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è –≤ _run_integrated_monitoring_loop
    #  (—Å–º. —Ä–∞–Ω–µ–µ –ø—Ä–∏—Å–ª–∞–Ω–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä). –ó–¥–µ—Å—å ‚Äî —Ç–æ–ª—å–∫–æ fast-path.
    # ============================================================

    # self._positions_db_queue: asyncio.Queue[tuple[int, dict]]
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–µ; –∑–¥–µ—Å—å –ª–∏—à—å –∏—Å–ø–æ–ª—å–∑—É–µ–º.


    async def _handle_position_update(self, data: dict):
        """
        Simple dispatcher for 'position' topic.
        It extracts position items and calls registered handlers.
        """
        try:
            items = []
            payload = data.get("data", data.get("result", []))
            if isinstance(payload, list):
                items = payload
            elif isinstance(payload, dict):
                # Bybit can send a single position object instead of a list
                items = payload.get("list", [payload])

            # The key for handlers should be 'position' to match the topic.
            handlers = self.message_handlers.get('position', [])

            if handlers:
                for position_item in items:
                    for handler in handlers:
                        try:
                            await handler(position_item)
                        except Exception as e:
                            logger.error(f"Position handler error for item {position_item.get('symbol')}: {e}", exc_info=True)
            else:
                logger.debug(f"[{self.name}] No handler for position topic.")

        except Exception as e:
            logger.error("%s - Position update handling error: %s", getattr(self, 'name', 'WS'), e, exc_info=True)


    async def _generate_copy_signal(self, position_data: dict, event_type: str, prev_qty: float = 0):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∞–∫–∫–∞—É–Ω—Ç
        –ù–û–í–´–ô –º–µ—Ç–æ–¥ - –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        """
        try:
            # –ò—â–µ–º —Å–∏—Å—Ç–µ–º—É –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            copy_system = None
        
            # –í–∞—Ä–∏–∞–Ω—Ç 1: –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            if 'copy_system' in globals():
                copy_system = globals()['copy_system']
        
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –ê—Ç—Ä–∏–±—É—Ç –∫–ª–∞—Å—Å–∞
            if not copy_system and hasattr(self, 'copy_system'):
                copy_system = self.copy_system
        
            # –í–∞—Ä–∏–∞–Ω—Ç 3: –ß–µ—Ä–µ–∑ orchestrator
            if not copy_system:
                orchestrator = globals().get('orchestrator')
                if orchestrator:
                    copy_system = getattr(orchestrator, 'copy_system', None)
        
            if not copy_system:
                logger.debug("No copy system available, skipping signal generation")
                return
        
            # –ü–æ–ª—É—á–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            copy_queue = getattr(copy_system, 'copy_queue', None)
            if not copy_queue:
                logger.debug("No copy queue available")
                return
        
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª–∞
            symbol = position_data.get('symbol', '').upper()
            side = position_data.get('side', 'Buy')
            current_qty = float(position_data.get('size', position_data.get('qty', 0)))

            # –°–æ–∑–¥–∞–µ–º —Å–∏–≥–Ω–∞–ª
            signal = {
                'type': event_type,
                'timestamp': time.time(),
                'source': 'donor',
                'symbol': symbol,
                'side': side,
                'current_qty': current_qty,
                'prev_qty': prev_qty,
                'position_idx': int(position_data.get('positionIdx', position_data.get('position_idx', 0))),
                'leverage': int(position_data.get('leverage', 1)),
                'data': position_data
            }
        
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            priority = 1  # –û–±—ã—á–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            if event_type in ['CLOSED', 'OPENED']:
                priority = 0  # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è/–∑–∞–∫—Ä—ã—Ç–∏—è
        
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
            await copy_queue.put((priority, time.time(), signal))
        
            logger.info(f"üì§ Copy signal sent: {event_type} for {symbol} {side} "
                       f"qty={current_qty} (was {prev_qty})")
        
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.debug(f"COPY_PLAN: {event_type} {symbol} {side} {prev_qty}‚Üí{current_qty}")
        
        except Exception as e:
            logger.error(f"Failed to generate copy signal: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")

    async def _positions_db_worker(self, worker_id: int = 1):
        """
        –§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä –∑–∞–ø–∏—Å–∏ –ø–æ–∑–∏—Ü–∏–π –≤ –ë–î.
        –ß–∏—Ç–∞–µ—Ç –∏–∑ self._positions_db_queue –∏ –≤—ã–∑—ã–≤–∞–µ—Ç positions_writer.upsert_position().
        –ò–º—è –º–µ—Ç–æ–¥–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç–µ–º, –∫–∞–∫ –µ–≥–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä (_run_integrated_monitoring_loop).
        """
        try:
            try:
                from app.positions_db_writer import positions_writer
            except ImportError:
                from positions_db_writer import positions_writer

            q: asyncio.Queue = getattr(self, '_positions_db_queue', None)
            if q is None:
                logger.warning("DB worker %s: queue is None ‚Äî exiting", worker_id)
                return

            while not getattr(self, 'should_stop', False):
                try:
                    account_id, pos = await q.get()
                    try:
                        await positions_writer.upsert_position(pos, account_id)
                    except Exception as e:
                        logger.error("DB writer error: %s", e)
                    finally:
                        q.task_done()
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error("DB worker %s error: %s", worker_id, e)
                    # –Ω–µ —Å–ø–∏–º –¥–æ–ª–≥–æ, —á—Ç–æ–±—ã –Ω–µ –≤–ª–∏—è—Ç—å –Ω–∞ –∑–∞–¥–µ—Ä–∂–∫–∏ WS
                    await asyncio.sleep(0)

        finally:
            logger.info("DB worker %s stopped", worker_id)


    async def _handle_wallet_update(self, data: dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –∫–æ—à–µ–ª—å–∫–∞"""
        try:
            wallets = data.get('data', [])
            for wallet in wallets:
                coin = wallet.get('coin')
                balance = safe_float(wallet.get('walletBalance', 0))

                logger.info(f"{self.name} - Wallet update: {coin} balance={balance}")

                if 'wallet' in self.message_handlers:
                    for handler in self.message_handlers['wallet']:
                        await handler(wallet)

        except Exception as e:
            logger.error(f"{self.name} - Wallet update handling error: {e}")
    
    async def _handle_execution_update(self, data: dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ä–¥–µ—Ä–æ–≤"""
        try:
            executions = data.get('data', [])
            for execution in executions:
                symbol = execution.get('symbol')
                side = execution.get('side')
                exec_qty = safe_float(execution.get('execQty', 0))
                exec_price = safe_float(execution.get('execPrice', 0))
                
                logger.info(f"{self.name} - Execution: {symbol} {side} {exec_qty}@{exec_price}")
                
                if 'execution' in self.message_handlers:
                    for handler in self.message_handlers['execution']:
                        await handler(execution)
                    
        except Exception as e:
            logger.error(f"{self.name} - Execution update handling error: {e}")
    
    async def _handle_order_update(self, data: dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –æ—Ä–¥–µ—Ä–æ–≤"""  
        try:
            orders = data.get('data', [])
            for order in orders:
                symbol = order.get('symbol')
                order_status = order.get('orderStatus')
                order_type = order.get('orderType')
                
                logger.info(f"{self.name} - Order update: {symbol} {order_type} {order_status}")
                
                if 'order' in self.message_handlers:
                    for handler in self.message_handlers['order']:
                        await handler(order)
                    
        except Exception as e:
            logger.error(f"{self.name} - Order update handling error: {e}")
    
    async def _handle_disconnect(self, reason: str):
        """
        –ù–∞–¥—ë–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏—Å–∫–æ–Ω–Ω–µ–∫—Ç–∞ WS:
        - –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞;
        - –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é —ç—Å–∫–∞–ª–∞—Ü–∏—é shutdown (–æ—Ç–º–µ–Ω—è–µ—Ç—Å—è –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏);
        - —É–≤–µ–¥–æ–º–ª—è–µ—Ç NetworkSupervisor (–µ—Å–ª–∏ –µ—Å—Ç—å) –æ —Å—Ç–∞—Ç—É—Å–µ.
        """
    
        logger.warning(f"SOURCE_WS - Handling disconnect ({reason}), starting reconnection loop...")
    
        # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º –¥–∏—Å–∫–æ–Ω–Ω–µ–∫—Ç –≤ –ë–î
        sys_logger.log_event("WARN", "WebSocket", f"WebSocket disconnected: {reason}", {
            "websocket_name": "SOURCE_WS",
            "reason": reason
        })

        # --- reentrancy guard ---
        if not hasattr(self, "_ws_reconnect_lock"):
            self._ws_reconnect_lock = asyncio.Lock()
        if not hasattr(self, "_ws_reconnecting"):
            self._ws_reconnecting = False

        if self._ws_reconnecting:
            logger.info("SOURCE_WS - Reconnect already in progress; skip duplicate handler call")
            return

        # Non-blocking escalation task
        asyncio.create_task(self._escalate_shutdown_after_timeout(180))

        async with self._ws_reconnect_lock:
            if self._ws_reconnecting:
                logger.info("SOURCE_WS - Reconnect already in progress (lock path); skip")
                return
            self._ws_reconnecting = True
        
            # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞
            sys_logger.log_reconnect("WebSocket", "Bybit SOURCE_WS", 1)

            # --- —É–≤–µ–¥–æ–º–∏–º —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä –æ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –ø–æ–¥–∫–ª—é—á—ë–Ω) ---
            try:
                if getattr(self, "network_supervisor", None):
                    await self.network_supervisor.on_connection_failure("websocket", f"disconnect: {reason}")
            except Exception as e:
                logger.debug(f"NetworkSupervisor notify failure skipped: {e}")

            try:
                # --- —Å–∞–º —Ü–∏–∫–ª —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞ —Å backoff (—Ç–≤–æ—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ –º–µ—Ç–æ–¥–∞) ---
                await self._reconnect_ws_loop()
            
                # ‚úÖ –ù–û–í–û–ï: –ï—Å–ª–∏ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç —É—Å–ø–µ—à–µ–Ω, –ª–æ–≥–∏—Ä—É–µ–º
                if hasattr(self, 'ws') and self.ws and is_websocket_open(self.ws):
                    sys_logger.log_event("INFO", "WebSocket", "WebSocket reconnected successfully", {
                        "websocket_name": "SOURCE_WS"
                    })

            except Exception as e:
                # —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç –Ω–µ —É–¥–∞–ª—Å—è ‚Äî —ç—Å–∫–∞–ª–∞—Ü–∏—è –∑–∞–π–º—ë—Ç—Å—è shutdown; –ø—Ä–æ—Å—Ç–æ –∑–∞–ª–æ–≥–∏—Ä—É–µ–º
                logger.error(f"SOURCE_WS - Reconnect loop crashed: {e}")
                logger.error(f"Full traceback: {traceback.format_exc()}")
            
                # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞
                sys_logger.log_error("WebSocket", "Reconnect loop crashed", {
                    "websocket_name": "SOURCE_WS",
                    "error": str(e),
                    "critical": True
                })

            else:
                # --- —É—Å–ø–µ—à–Ω—ã–π —Ä–µ-–∫–æ–Ω–Ω–µ–∫—Ç: –æ—Ç–º–µ–Ω—è–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é —ç—Å–∫–∞–ª–∞—Ü–∏—é –∏ —É–≤–µ–¥–æ–º–ª—è–µ–º —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä ---
                self._cancel_planned_shutdown()
                logger.info("SOURCE_WS - Successfully reconnected, escalation cancelled")

                try:
                    if getattr(self, "network_supervisor", None):
                        await self.network_supervisor.on_connection_success("websocket")
                except Exception as e:
                    logger.debug(f"NetworkSupervisor notify success skipped: {e}")

            finally:
                self._ws_reconnecting = False

    async def _reconnect_ws_loop(self):
        """
        –¶–∏–∫–ª —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞ WebSocket —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ –ë–î
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ _handle_disconnect –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        """
        # ‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º sys_logger
    
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª–∞—Å—Å–∞ –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
        max_attempts = getattr(self, 'max_reconnect_attempts', 10)
        reconnect_delays = getattr(self, 'reconnect_delays', [1, 2, 4, 8, 16, 32, 60, 60, 60, 60])
    
        logger.info(f"SOURCE_WS - Starting reconnect loop (max attempts: {max_attempts})")
    
        for attempt in range(1, max_attempts + 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            if getattr(self, 'should_stop', False):
                logger.info("SOURCE_WS - System stopping, aborting reconnect")
                return False
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ–ø—ã—Ç–∫–∏
            delay_index = min(attempt - 1, len(reconnect_delays) - 1)
            delay = reconnect_delays[delay_index]
        
            logger.info(f"SOURCE_WS - Reconnect attempt {attempt}/{max_attempts} in {delay}s")
        
            # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞ –≤ –ë–î
            sys_logger.log_reconnect("WebSocket", "Bybit SOURCE_WS", attempt)
        
            # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π
            await asyncio.sleep(delay)
        
            # –ï—â–µ —Ä–∞–∑ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è
            if getattr(self, 'should_stop', False):
                logger.info("SOURCE_WS - System stopping after delay, aborting reconnect")
                return False
            
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è
                logger.info(f"SOURCE_WS - Attempting reconnection (attempt {attempt})")
            
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                if hasattr(self, 'ws') and self.ws:
                    try:
                        await self.ws.close()
                    except:
                        pass
                    self.ws = None
            
                # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∑–∞–Ω–æ–≤–æ
                await self.connect()
            
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                if hasattr(self, 'status') and self.status == ConnectionStatus.CONNECTED:
                    logger.info(f"SOURCE_WS - Successfully reconnected on attempt {attempt}")
                
                    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç –≤ –ë–î
                    sys_logger.log_event("INFO", "WebSocket", "WebSocket reconnected successfully", {
                        "websocket_name": "SOURCE_WS",
                        "attempt": attempt,
                        "total_attempts": max_attempts,
                        "delay_used": delay
                    })
                
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∫–∏
                    try:
                        if hasattr(self, '_resubscribe'):
                            await self._resubscribe()
                        elif hasattr(self, 'subscriptions') and self.subscriptions:
                            # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–æ–¥–∞ _resubscribe, –ø—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–ø–∏—Å–∫–∏ –≤—Ä—É—á–Ω—É—é
                            for subscription in self.subscriptions:
                                await self.subscribe(subscription)
                    
                        logger.info("SOURCE_WS - Subscriptions restored")
                    except Exception as sub_error:
                        logger.error(f"SOURCE_WS - Error restoring subscriptions: {sub_error}")
                        # –ù–µ —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–æ–π - —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
                
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á—É –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if hasattr(self, 'listen'):
                        listen_task = asyncio.create_task(self.listen())
                        if hasattr(self, 'active_tasks'):
                            self.active_tasks.add(listen_task)
                
                    return True
                
                # –ï—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –Ω–µ CONNECTED, —Å—á–∏—Ç–∞–µ–º –ø–æ–ø—ã—Ç–∫—É –Ω–µ—É–¥–∞—á–Ω–æ–π
                logger.warning(f"SOURCE_WS - Connection established but status is not CONNECTED")
            
            except asyncio.CancelledError:
                logger.info("SOURCE_WS - Reconnect cancelled")
                raise
            
            except Exception as e:
                logger.error(f"SOURCE_WS - Reconnect attempt {attempt} failed: {e}")
            
                # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –Ω–µ—É–¥–∞—á–Ω—É—é –ø–æ–ø—ã—Ç–∫—É –≤ –ë–î
                sys_logger.log_error("WebSocket", f"Reconnect attempt failed", {
                    "websocket_name": "SOURCE_WS",
                    "attempt": attempt,
                    "error": str(e),
                    "error_type": type(e).__name__
                })
            
                # –ï—Å–ª–∏ —ç—Ç–æ –±—ã–ª–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞, –ª–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
                if attempt == max_attempts:
                    logger.error(f"SOURCE_WS - Final reconnect attempt failed: {e}")
    
        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        logger.error(f"SOURCE_WS - All {max_attempts} reconnect attempts exhausted")
    
        # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É –≤ –ë–î - —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω
        sys_logger.log_error("WebSocket", "All reconnect attempts exhausted", {
            "websocket_name": "SOURCE_WS",
            "max_attempts": max_attempts,
            "critical": True,
            "final_status": "FAILED"
        })
    
        # –£–≤–µ–¥–æ–º–ª—è–µ–º –æ–± –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ —á–µ—Ä–µ–∑ Telegram –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
        try:
            from telegram_utils import send_telegram_alert
            await send_telegram_alert(
                f"üî¥ CRITICAL: WebSocket SOURCE_WS failed to reconnect after {max_attempts} attempts. "
                f"Manual intervention required!"
            )
        except:
            pass  # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º –µ—Å–ª–∏ –∞–ª–µ—Ä—Ç –Ω–µ –æ—Ç–ø—Ä–∞–≤–∏–ª—Å—è
    
        return False

    async def _resubscribe(self):
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏ –ø–æ—Å–ª–µ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞.
        –î–µ–ª–µ–≥–∏—Ä—É–µ—Ç –Ω–∞ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ resubscribe_all.
        """
        logger.info("SOURCE_WS - Restoring subscriptions via resubscribe_all...")
        try:
            await self.resubscribe_all()
            logger.info("SOURCE_WS - Subscriptions restored.")
        except Exception as e:
            logger.error(f"SOURCE_WS - Error restoring subscriptions via resubscribe_all: {e}")
    
    async def _cleanup_tasks(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
        try:
            cleanup_tasks = []
            
            for task in list(self.active_tasks):
                if task and not task.done():
                    task.cancel()
                    cleanup_tasks.append(task)
            
            if cleanup_tasks:
                # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á —Å timeout
                try:
                    await asyncio.wait_for(
                        asyncio.gather(*cleanup_tasks, return_exceptions=True),
                        timeout=5.0
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"{self.name} - Some tasks didn't finish within timeout")
            
            # –û—á–∏—â–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á
            self.active_tasks.clear()
            
            logger.debug(f"{self.name} - Tasks cleaned up successfully")
        
        except Exception as e:
            logger.debug(f"{self.name} - Error cleaning up tasks: {e}")
    
    async def reconnect(self):
        """–ù–∞–¥—ë–∂–Ω–æ–µ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å exponential backoff –∏ –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫."""
        # --- reentrancy guard (–Ω–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–æ–≤) ---
        if not hasattr(self, "_reconnect_lock"):
            self._reconnect_lock = asyncio.Lock()
        if not hasattr(self, "_reconnecting"):
            self._reconnecting = False

        if self._reconnecting:
            logger.info(f"{self.name} - Reconnect already in progress; skipping duplicate call")
            return False

        async with self._reconnect_lock:
            if self._reconnecting:
                logger.info(f"{self.name} - Reconnect already in progress (lock path); skip")
                return False
            self._reconnecting = True

            try:
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫, –µ—Å–ª–∏ –¥–æ —ç—Ç–æ–≥–æ –±—ã–ª —É—Å–ø–µ—à–Ω—ã–π –∫–æ–Ω–Ω–µ–∫—Ç
                self.reconnect_attempt = getattr(self, "reconnect_attempt", 0) or 0

                while self.reconnect_attempt < self.max_reconnect_attempts and not self.should_stop:
                    try:
                        # –í—ã–±–æ—Ä –∑–∞–¥–µ—Ä–∂–∫–∏ –ø–æ —Ç–∞–±–ª–∏—Ü–µ –±—ç–∫–æ—Ñ—Ñ–∞
                        idx = min(self.reconnect_attempt, len(self.reconnect_delays) - 1)
                        delay = self.reconnect_delays[idx]
                        logger.info(f"{self.name} - Reconnecting in {delay}s (attempt {self.reconnect_attempt + 1})")

                        await asyncio.sleep(delay)

                        # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                        if getattr(self, "ws", None):
                            try:
                                await close_websocket_safely(self.ws)
                            except Exception as ce:
                                logger.debug(f"{self.name} - safe close previous ws failed: {ce}")
                            finally:
                                self.ws = None

                        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∑–∞–Ω–æ–≤–æ
                        await self.connect()

                        # –£—Å–ø–µ—Ö
                        logger.info(f"{self.name} - Successfully reconnected")
                        self.reconnect_attempt = 0

                        # --- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å FinalTradingMonitor (–µ—Å–ª–∏ –µ—Å—Ç—å) ---
                        # 1) –û—Ç–º–µ–Ω—è–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é —ç—Å–∫–∞–ª–∞—Ü–∏—é shutdown –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –º–æ–Ω–∏—Ç–æ—Ä–∞
                        fm = getattr(self, "final_monitor", None)
                        if fm and hasattr(fm, "_cancel_planned_shutdown"):
                            try:
                                fm._cancel_planned_shutdown()
                            except Exception as hook_e:
                                logger.debug(f"{self.name} - cancel escalation hook failed: {hook_e}")

                        # 2) –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–ª–±—ç–∫ ¬´—É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç¬ª (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
                        cb = getattr(self, "on_reconnect_success", None)
                        if cb:
                            try:
                                res = cb(self)
                                if asyncio.iscoroutine(res):
                                    await res
                            except Exception as cb_e:
                                logger.debug(f"{self.name} - on_reconnect_success callback failed: {cb_e}")

                        return True

                    except Exception as e:
                        self.reconnect_attempt += 1
                        logger.error(f"{self.name} - Reconnection attempt {self.reconnect_attempt} failed: {e}")

                        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–ª–±—ç–∫ ¬´–æ—à–∏–±–∫–∞ –ø–æ–ø—ã—Ç–∫–∏ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞¬ª (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)
                        cb_fail = getattr(self, "on_reconnect_attempt_failed", None)
                        if cb_fail:
                            try:
                                res = cb_fail(self, self.reconnect_attempt, e)
                                if asyncio.iscoroutine(res):
                                    await res
                            except Exception as cbfe:
                                logger.debug(f"{self.name} - on_reconnect_attempt_failed callback failed: {cbfe}")

                # --- –∏—Å—á–µ—Ä–ø–∞–ª–∏ –ø–æ–ø—ã—Ç–∫–∏ ---
                logger.critical(f"{self.name} - Max reconnection attempts reached")
                try:
                    await send_telegram_alert(
                        f"WebSocket {self.name} failed to reconnect after {self.max_reconnect_attempts} attempts"
                    )
                except Exception:
                    pass

                # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–ª–±—ç–∫ ¬´–ø–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–∞¬ª (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
                cb_final_fail = getattr(self, "on_reconnect_failed", None)
                if cb_final_fail:
                    try:
                        res = cb_final_fail(self)
                        if asyncio.iscoroutine(res):
                            await res
                    except Exception as cbffe:
                        logger.debug(f"{self.name} - on_reconnect_failed callback failed: {cbffe}")

                return False

            finally:
                self._reconnecting = False

    
    def register_handler(self, event_type: str, handler_func):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Å–æ–±—ã—Ç–∏–π"""
        if event_type not in self.message_handlers:
            self.message_handlers[event_type] = []
    
        self.message_handlers[event_type].append(handler_func)
        logger.info(f"{self.name} - Registered handler for {event_type}")
    
    async def close(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∏–∫—Å–∞–º–∏"""
        try:
            self.should_stop = True
            self.processing_active = False
    
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
            await self._cleanup_tasks()
        
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏
            if hasattr(self, '_message_processor_task') and self._message_processor_task:
                self._message_processor_task.cancel()
                try:
                    await asyncio.wait_for(self._message_processor_task, timeout=2.0)
                except (asyncio.CancelledError, asyncio.TimeoutError):
                    pass
        
            # –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π
            if hasattr(self, 'message_queue'):
                while not self.message_queue.empty():
                    try:
                        self.message_queue.get_nowait()
                    except:
                        break
    
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –∑–∞–∫—Ä—ã—Ç–∏—è
            if self.ws:
                await close_websocket_safely(self.ws)
                self.ws = None
    
            self.status = ConnectionStatus.DISCONNECTED
            logger.info(f"{self.name} - WebSocket manager closed successfully")
    
        except Exception as e:
            logger.error(f"{self.name} - Error closing WebSocket: {e}")
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
            self.status = ConnectionStatus.DISCONNECTED
    
    def get_stats(self) -> dict:
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å ping/pong –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        uptime = time.time() - self.stats['uptime_start']
        stats = self.stats.copy()

        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ping/pong —Å –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π
        ping_pong_delay = None
        if self.last_ping > 0 and self.last_pong > self.last_ping:
            ping_pong_delay = self.last_pong - self.last_ping

        stats.update({
            'status': self.status.value,
            'uptime_seconds': uptime,
            'subscriptions': list(self.subscriptions.keys()),
            'buffer_size': len(self.message_buffer),
            'queue_size': self._get_queue_size_safe(),
            'active_tasks': len(self.active_tasks),
            'websocket_open': is_websocket_open(self.ws),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é
            'websockets_version': get_websockets_version(),
            'last_ping': self.last_ping,
            'last_pong': self.last_pong,
            'ping_pong_delay': ping_pong_delay,
            'ping_pong_success_rate': (
                (stats.get('ping_pong_success', 0) / max(1, stats.get('ping_pong_success', 0) + stats.get('ping_pong_failures', 0))) * 100
            ),
            'websocket_auto_ping_disabled': True,  # ‚úÖ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –∞–≤—Ç–æ–ø–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω
            'bybit_custom_ping_enabled': True,     # ‚úÖ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º Bybit ping
            'websocket_fixes_applied': True        # ‚úÖ –ù–û–í–û–ï: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ñ–∏–∫—Å—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã
        })
        return stats

    async def get_diagnostic_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ WebSocket –¥–ª—è Telegram."""
        try:
            stats = self.get_stats()
            is_open = stats.get('websocket_open', False)
            status = stats.get('status', 'UNKNOWN')

            report_lines = [
                f"**WebSocket Diagnostics ({self.name})**",
                f"---------------------------------",
                f"**Status:** `{status}` {'‚úÖ' if is_open else '‚ùå'}",
                f"**Connection Open:** `{is_open}`",
                f"**Websockets Lib Version:** `{stats.get('websockets_version', 'N/A')}`",
                f"**Subscriptions:** `{', '.join(self.subscriptions) if self.subscriptions else 'None'}`",
                f"**Uptime:** `{int(stats.get('uptime_seconds', 0))} seconds`",
                f"**Last Message:** `{time.time() - stats.get('last_message_time', 0):.1f}s ago`" if stats.get('last_message_time') else "`Never`",
                f"**Messages Received:** `{stats.get('messages_received', 0)}`",
                f"**Messages Processed:** `{stats.get('messages_processed', 0)}`",
                f"**Queue Size:** `{stats.get('queue_size', 0)}`",
                f"**Connection Drops:** `{stats.get('connection_drops', 0)}`",
                "",
                "**Ping/Pong (Bybit Custom):**",
                f"  **Last Ping:** `{datetime.fromtimestamp(self.last_ping).strftime('%H:%M:%S') if self.last_ping else 'N/A'}`",
                f"  **Last Pong:** `{datetime.fromtimestamp(self.last_pong).strftime('%H:%M:%S') if self.last_pong else 'N/A'}`",
                f"  **Latency:** `{'%.3f' % stats.get('ping_pong_delay') if stats.get('ping_pong_delay') is not None else 'N/A'}s`",
                f"  **Success Rate:** `{stats.get('ping_pong_success_rate', 0):.1f}%`",
            ]
            return "\n".join(report_lines)
        except Exception as e:
            logger.error(f"Failed to generate WS diagnostic report: {e}")
            return f"Error generating report: {e}"

    def _get_queue_size_safe(self) -> int:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –æ—á–µ—Ä–µ–¥–∏"""
        try:
            if hasattr(self, 'message_queue') and self.message_queue:
                return self.message_queue.qsize()
            return 0
        except (AttributeError, RuntimeError):
            return 0

# ================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –û–ë–†–ê–ë–û–¢–ö–ò –°–ò–ì–ù–ê–õ–û–í (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# ================================

class ProductionSignalProcessor:
    """–ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""
    
    def __init__(self, account_id: int, monitor: 'FinalTradingMonitor' = None):
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π
        self.account_id = account_id
        self.monitor = monitor
        self.known_positions = {}
        self.position_history = deque(maxlen=1000)
        self._last_set_leverage: dict[str, int] = {}
        
        # –û—á–µ—Ä–µ–¥–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è backpressure
        self.signal_queue = asyncio.PriorityQueue(maxsize=PRODUCTION_CONFIG['max_queue_size'])
        self.processed_signals = deque(maxlen=500)
        
        # –°–∏—Å—Ç–µ–º–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
        self.suspicious_patterns = {
            'rapid_fire_orders': {'threshold': 10, 'timeframe': 60},
            'unusual_size': {'threshold': 5.0},
            'weekend_activity': {},
            'correlation_break': {'threshold': 0.3}
        }
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'signals_received': 0,
            'signals_processed': 0,
            'signals_filtered': 0,
            'signals_dropped': 0,
            'suspicious_detected': 0,
            'processing_errors': 0,
            'queue_full_events': 0
        }
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏
        self.processing_active = False
        self._processor_task = None
        self.should_stop = False
        self._active_tasks = 0
        self.workers_idle = asyncio.Event()
        self.workers_idle.set()  # Initially, no workers are active

    async def _ingest_position_to_db(self, position_data: dict):
        """
        –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –ø–æ–∑–∏—Ü–∏–∏ –≤ –ë–î —á–µ—Ä–µ–∑ positions_writer.
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è: qty/size, position_idx/positionIdx, symbol.
        """
        try:
            from positions_db_writer import positions_writer
        except ImportError:
            from app.positions_db_writer import positions_writer
        except Exception as e:
            logger.error("WS ingest: cannot import positions_writer: %s", e)
            return

        account_id = self.account_id

        # –∫–æ–ø–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–µ–π
        pos = dict(position_data) if isinstance(position_data, dict) else {}
        # qty / size
        qty_raw = pos.get("qty", pos.get("size", 0))
        try:
            pos["qty"] = float(qty_raw)
        except Exception:
            pos["qty"] = 0.0

        # position_idx / positionIdx
        try:
            pos["position_idx"] = int(pos.get("position_idx", pos.get("positionIdx", 0)))
        except Exception:
            pos["position_idx"] = 0

        # SYMBOL UPPER
        if "symbol" in pos and isinstance(pos["symbol"], str):
            pos["symbol"] = pos["symbol"].upper()

        # –∑–∞–ø–∏—Å—å –Ω–∞–ø—Ä—è–º—É—é (writer —Å–∞–º —Ä–µ—à–∏—Ç: qty>0 => upsert, qty==0 => close)
        try:
            await positions_writer.update_position({**pos, "account_id": account_id})
        except Exception as e:
            logger.error("WS ingest: writer.update_position error: %s", e)

        # –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –º–æ–∂–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –≤ –æ—á–µ—Ä–µ–¥—å (–µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å)
        q = getattr(self, "_positions_db_queue", None)
        if q is not None:
            try:
                q.put_nowait((account_id, pos))
            except Exception:
                # –º—è–≥–∫–æ–µ –≤—ã—Ç–µ—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–∏
                try:
                    _ = q.get_nowait(); q.task_done()
                except Exception:
                    pass
                try:
                    q.put_nowait((account_id, pos))
                except Exception:
                    pass
        
    async def start_processing(self):
        """–ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        if not self.processing_active:
            if self._processor_task and not self._processor_task.done():
                self._processor_task.cancel()
                
            self._processor_task = asyncio.create_task(self._process_signal_queue())
            self.processing_active = True
            logger.info("Signal processing system started")
    
    async def stop_processing(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        self.should_stop = True
        self.processing_active = False
        
        if self._processor_task and not self._processor_task.done():
            self._processor_task.cancel()
            try:
                await asyncio.wait_for(self._processor_task, timeout=5.0)
            except (asyncio.CancelledError, asyncio.TimeoutError):
                pass
        
        logger.info("Signal processing system stopped")

    async def process_position_update(self, position_data: dict):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç WebSocket (hedge-safe + DB ingest)"""
        try:
            if not isinstance(position_data, dict):
                return

            # ---- –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ö–õ–Æ–ß–ï–í–´–• –ü–û–õ–ï–ô ----
            symbol_raw = position_data.get('symbol')
            if not symbol_raw:
                return
            symbol = str(symbol_raw).upper()

            # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ –ø–æ–ª—è —Ä–∞–∑–º–µ—Ä–∞
            current_size = safe_float(
                position_data.get('size', position_data.get('qty', 0.0))
            ) or 0.0

            # –í–ê–ñ–ù–û: –≤ UTA –ø—Ä–∏ –Ω—É–ª–µ–≤–æ–π –ø–æ–∑–∏—Ü–∏–∏ side = "" (–ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞) ‚Äî —ç—Ç–æ –≤–∞–ª–∏–¥–Ω–æ
            side = (position_data.get('side') or "").strip()

            # –í–ê–ñ–ù–û: hedge mode ‚Äî —É—á–∏—Ç—ã–≤–∞–µ–º positionIdx
            try:
                position_idx = int(position_data.get('position_idx', position_data.get('positionIdx', 0)))
            except Exception:
                position_idx = 0

            # –∫–ª—é—á —Å–æ—Å—Ç–æ—è–Ω–∏—è: SYMBOL#IDX (—á—Ç–æ–±—ã long/short –Ω–µ –º–µ—à–∞–ª–∏ –¥—Ä—É–≥ –¥—Ä—É–≥—É)
            state_key = f"{symbol}#{position_idx}"

            # ---- –°–†–ê–í–ù–ï–ù–ò–ï –° –ü–†–ï–î–´–î–£–©–ò–ú –°–û–°–¢–û–Ø–ù–ò–ï–ú ----
            prev_size = 0.0
            is_known = state_key in self.known_positions
            if is_known:
                prev_position = self.known_positions[state_key]
                prev_size = safe_float(prev_position.get('size', 0.0)) or 0.0

            size_delta = current_size - prev_size

            # ---- –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–ò–ì–ù–ê–õ–û–í ----
            if abs(size_delta) > 0.001:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–∏–º–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ

                # –¶–µ–Ω–∞ –≤—Ö–æ–¥–∞ –ø–æ V5: entryPrice; –∑–∞–ø–∞—Å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã ‚Äî sessionAvgPrice/markPrice
                entry_price = safe_float(
                    position_data.get('entryPrice')
                    or position_data.get('sessionAvgPrice')
                    or position_data.get('markPrice')
                    or 0
                ) or 0.0

                if not is_known and current_size > 0:
                    signal_type = SignalType.POSITION_OPEN
                    eff_size = current_size
                else:
                    if prev_size == 0 and current_size > 0:
                        signal_type = SignalType.POSITION_OPEN
                        eff_size = current_size
                    elif prev_size > 0 and current_size == 0:
                        signal_type = SignalType.POSITION_CLOSE
                        eff_size = prev_size  # –∑–∞–∫—Ä—ã–≤–∞–µ–º –≤–µ—Å—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ–±—ä—ë–º
                    else:
                        signal_type = SignalType.POSITION_MODIFY
                        eff_size = abs(size_delta)

                signal = TradingSignal(
                    signal_type=signal_type,
                    symbol=symbol,
                    side=side,
                    size=eff_size,
                    price=entry_price,
                    timestamp=time.time(),
                    metadata={
                        'prev_size': prev_size,
                        'new_size': current_size,
                        'position_idx': position_idx,
                        'position_data': position_data
                    },
                    priority=3 if signal_type == SignalType.POSITION_CLOSE else 2
                )
                await self.add_signal(signal)

            # ---- –û–ë–ù–û–í–õ–Ø–ï–ú –õ–û–ö–ê–õ–¨–ù–û–ï –°–û–°–¢–û–Ø–ù–ò–ï ----
            self.known_positions[state_key] = {
                'size': current_size,
                'side': side,
                'position_idx': position_idx,
                'last_update': time.time(),
                'data': position_data
            }

            # ---- –ò–°–¢–û–†–ò–Ø ----
            self.position_history.append({
                'symbol': symbol,
                'position_idx': position_idx,
                'size': current_size,
                'timestamp': time.time(),
                'type': 'position_update'
            })

            # ---- –°–¢–ê–¢–ò–°–¢–ò–ö–ê ----
            try:
                self.stats['signals_received'] += 1
            except Exception:
                pass

            # ---- –°–¢–†–ê–•–û–í–û–ß–ù–ê–Ø –ó–ê–ü–ò–°–¨ –í –ë–î (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ) ----
            try:
                # _ingest_position_to_db –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç qty/idx/symbol –∏ –≤—ã–∑–æ–≤–µ—Ç writer
                ingest_data = position_data.copy()
                ingest_data['symbol'] = symbol
                ingest_data['position_idx'] = position_idx
                await self._ingest_position_to_db(ingest_data)
            except Exception as e:
                logger.error("process_position_update -> ingest error: %s", e)

        except Exception as e:
            logger.error(f"Position update processing error: {e}")
            try:
                self.stats['processing_errors'] += 1
            except Exception:
                pass


    
    async def add_signal(self, signal: TradingSignal):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –≤ –æ—á–µ—Ä–µ–¥—å —Å backpressure –∏ —É—á–µ—Ç–æ–º –ø–∞—É–∑—ã."""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –ø–∞—É–∑–µ
            if self.monitor and self.monitor._is_paused:
                if signal.signal_type in [SignalType.POSITION_CLOSE, SignalType.POSITION_MODIFY]:
                    position_idx = signal.metadata.get('position_idx', 0)
                    idempotency_key = f"{signal.symbol}|{position_idx}|{signal.signal_type.value}|{int(signal.timestamp)}"
                    self.monitor._deferred_ops_queue.append((idempotency_key, signal))
                    logger.info(f"Critical op deferred with key {idempotency_key}: {signal.signal_type.value} {signal.symbol}")
                else:
                    self.monitor._deferred_signal_queue.append(signal)
                    logger.info(f"Signal deferred due to system pause: {signal.signal_type.value} {signal.symbol}")
                return

            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–∞
            if not await self.validate_signal(signal):
                logger.warning(f"Signal filtered: {signal.signal_type.value} {signal.symbol}")  
                self.stats['signals_filtered'] += 1
                return
            
            # Backpressure —Å–∏—Å—Ç–µ–º–∞
            try:
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –æ—á–µ—Ä–µ–¥—å: —á–µ–º –≤—ã—à–µ priority, —Ç–µ–º —Ä–∞–Ω—å—à–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞
                self.signal_queue.put_nowait((-signal.priority, time.time(), signal))
                logger.info(f"Signal added to main queue: {signal.signal_type.value} {signal.symbol} {signal.side} {signal.size}")
            except asyncio.QueueFull:
                # –û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ - —É–¥–∞–ª—è–µ–º —Å–∏–≥–Ω–∞–ª —Å –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
                try:
                    removed_signal = self.signal_queue.get_nowait()
                    self.stats['signals_dropped'] += 1
                    logger.warning(f"Dropped low priority signal due to queue overflow")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª
                    self.signal_queue.put_nowait((-signal.priority, time.time(), signal))
                    logger.info(f"Signal added after dropping old: {signal.signal_type.value} {signal.symbol}")
                except asyncio.QueueEmpty:
                    # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –Ω–æ –±—ã–ª–∞ –ø–æ–ª–Ω–∞—è - —Å—Ç—Ä–∞–Ω–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è
                    self.signal_queue.put_nowait((-signal.priority, time.time(), signal))
                
                self.stats['queue_full_events'] += 1
                
        except Exception as e:
            logger.error(f"Signal addition error: {e}")
    
    async def validate_signal(self, signal: TradingSignal) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –ø—Ä–æ—Ç–∏–≤ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if signal.size <= 0 or not signal.symbol:
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            for pattern_name, pattern_config in self.suspicious_patterns.items():
                if await self.check_suspicious_pattern(signal, pattern_name, pattern_config):
                    logger.warning(f"Suspicious pattern detected: {pattern_name} for {signal.symbol}")
                    self.stats['suspicious_detected'] += 1
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"Signal validation error: {e}")
            return False
    
    async def check_suspicious_pattern(self, signal: TradingSignal, pattern_name: str, config: dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        try:
            if pattern_name == 'rapid_fire_orders':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–µ–∫—É–Ω–¥
                threshold = config['threshold']
                timeframe = config['timeframe']
                recent_time = time.time() - timeframe
                
                recent_signals = [
                    s for s in self.processed_signals
                    if s.timestamp > recent_time and s.symbol == signal.symbol
                ]
                
                return len(recent_signals) > threshold
                
            elif pattern_name == 'unusual_size':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                threshold = config['threshold']
                
                # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–º–µ—Ä–æ–≤ –¥–ª—è —Å–∏–º–≤–æ–ª–∞
                historical_sizes = [
                    h['size'] for h in self.position_history
                    if h['symbol'] == signal.symbol and h['size'] > 0
                ]
                
                if len(historical_sizes) >= 5:
                    avg_size = sum(historical_sizes) / len(historical_sizes)
                    return signal.size > avg_size * threshold
                
            elif pattern_name == 'weekend_activity':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ (–¥–ª—è —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã—Ö —Ä—ã–Ω–∫–æ–≤)
                current_time = datetime.now()
                if current_time.weekday() >= 5:  # –°—É–±–±–æ—Ç–∞ –∏–ª–∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
                    # –î–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º, —Ç–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ–º
                    logger.info(f"Weekend activity detected for {signal.symbol}")
                    return False  # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
            
            return False
            
        except Exception as e:
            logger.error(f"Pattern check error for {pattern_name}: {e}")
            return False
    
    def is_trading_hours(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö —á–∞—Å–æ–≤ (–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã —Ç–æ—Ä–≥—É—é—Ç—Å—è 24/7)"""
        return True
    
    async def _process_signal_queue(self):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—á–µ—Ä–µ–¥–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        try:
            while not self.should_stop:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —Å–∏–≥–Ω–∞–ª —Å –Ω–∞–∏–≤—ã—Å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
                    priority, timestamp, signal = await asyncio.wait_for(
                        self.signal_queue.get(), timeout=1.0
                    )
                    
                    self._active_tasks += 1
                    self.workers_idle.clear()
                    
                    try:
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª
                        await self._execute_signal_processing(signal)

                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                        self.processed_signals.append(signal)
                        self.stats['signals_processed'] += 1

                        self.signal_queue.task_done()
                    finally:
                        self._active_tasks -= 1
                        if self._active_tasks == 0 and self.signal_queue.empty():
                            self.workers_idle.set()
                            logger.info("All in-flight signal workers are idle.")
                    
                except asyncio.TimeoutError:
                    if self._active_tasks == 0 and self.signal_queue.empty():
                        if not self.workers_idle.is_set():
                            self.workers_idle.set()
                            logger.info("Signal queue is empty and workers are idle after timeout.")
                    continue  # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º should_stop
                except Exception as e:
                    logger.error(f"Signal queue processing error: {e}")
                    self.stats['processing_errors'] += 1
        except asyncio.CancelledError:
            logger.debug("Signal processor cancelled")
        except Exception as e:
            logger.error(f"Signal processor error: {e}")
    
    async def _execute_signal_processing(self, signal: TradingSignal):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ signals_log"""
        try:
            logger.info(f"Processing signal: {signal.signal_type.value} {signal.symbol} {signal.side} {signal.size}")
        
            # –õ–æ–≥–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª –≤ –ë–î –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            account_id = 1 if signal.metadata.get('source') == 'source_account' else 2
        
            signal_logged = signals_logger.log_signal(
                account_id=account_id,
                symbol=signal.symbol,
                side=signal.side,
                qty=signal.size,
                ext_id=signal.metadata.get('order_id', f"sig_{signal.timestamp}"),
                signal_data={
                    'signal_type': signal.signal_type.value,
                    'price': signal.price,
                    'timestamp': signal.timestamp,
                    'metadata': signal.metadata,
                    'priority': signal.priority
                },
                timestamp=signal.timestamp
            )
        
            if signal_logged:
                logger.debug(f"Signal recorded in signals_log: {signal.symbol}")
            else:
                logger.debug(f"Signal duplicate skipped: {signal.symbol}")
        
            # –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
            # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è
            try:
                from positions_db_writer import positions_writer
                position_data = signal.metadata.get('position_data', {})
                position_idx = position_data.get('position_idx', 0) if position_data else 0
                leverage = await self._get_main_leverage_for_log(signal.symbol, position_idx)

                if signal.signal_type in [SignalType.POSITION_OPEN, SignalType.POSITION_MODIFY]:
                    await positions_writer.log_open(position_data, leverage=leverage)
                elif signal.signal_type == SignalType.POSITION_CLOSE:
                    await positions_writer.log_close(position_data, leverage=leverage)
            except Exception as log_exc:
                logger.error(f"Failed to log position to DB with leverage: {log_exc}", exc_info=True)

            if signal.signal_type == SignalType.POSITION_OPEN:
                await self._handle_position_open_signal(signal)
            elif signal.signal_type == SignalType.POSITION_CLOSE:
                await self._handle_position_close_signal(signal)
            elif signal.signal_type == SignalType.POSITION_MODIFY:
                await self._handle_position_modify_signal(signal)
        
        except Exception as e:
            logger.error(f"Signal execution error: {e}")
            self.stats['processing_errors'] += 1

    def invalidate_caches(self):
        """Clears all internal caches to force re-fetching of data."""
        logger.info("SIGNAL_PROCESSOR: Invalidating internal caches...")
        self.known_positions.clear()
        self._last_set_leverage.clear()
        logger.info("SIGNAL_PROCESSOR: Caches (known_positions, _last_set_leverage) cleared.")
    
    async def _handle_signal_with_stage2_check(self, signal: TradingSignal, signal_type_str: str):
        """Generic handler to check Stage-2 readiness before forwarding a signal."""
        try:
            # Check for Stage-2 readiness and attempt recovery if needed
            if await self.monitor._ensure_stage2_ready():
                if self.monitor._copy_system_callback:
                    try:
                        await self.monitor._copy_system_callback(signal)
                        self.monitor.metrics['signals_forwarded_total'] += 1
                        logger.info(f"‚úÖ {signal_type_str} signal forwarded to copy system: {signal.symbol}")
                        # Minimal logging, TG alert can be done by Stage 2
                    except Exception as e:
                        self.monitor.metrics['signals_failed_total'] += 1
                        logger.error(f"Copy system callback error for {signal_type_str}: {e}", exc_info=True)
                        await send_telegram_alert(f"‚ùå **–û–®–ò–ë–ö–ê –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø '{signal_type_str}'**: {str(e)}")
                else:
                    logger.warning(f"SIG_BUFFERED: symbol={signal.symbol}, reason='no_callback'")
                    try:
                        self.monitor._copy_signal_buffer.put_nowait(signal)
                        self.monitor.metrics['signals_buffered_total'] += 1
                    except asyncio.QueueFull:
                        try:
                            # Drop-oldest policy
                            dropped_signal = self.monitor._copy_signal_buffer.get_nowait()
                            logger.warning(f"SIG_BUFFER_OVERFLOW_DROP_OLDEST: size={self.monitor._copy_signal_buffer.qsize()}, max_size={self.monitor._copy_signal_buffer.maxsize}. Dropped {dropped_signal.symbol}")
                            self.monitor.metrics['signals_dropped_total'] += 1
                            self.monitor._copy_signal_buffer.put_nowait(signal)
                            self.monitor.metrics['signals_buffered_total'] += 1
                        except asyncio.QueueEmpty:
                            pass # Should not happen
            else:
                logger.warning(f"SIG_BUFFERED: symbol={signal.symbol}, reason='stage2_not_ready'")
                try:
                    self.monitor._copy_signal_buffer.put_nowait(signal)
                    self.monitor.metrics['signals_buffered_total'] += 1
                except asyncio.QueueFull:
                    # Drop-oldest policy
                    dropped_signal = self.monitor._copy_signal_buffer.get_nowait()
                    logger.warning(f"SIG_BUFFER_OVERFLOW_DROP_OLDEST: size={self.monitor._copy_signal_buffer.qsize()}, max_size={self.monitor._copy_signal_buffer.maxsize}. Dropped {dropped_signal.symbol}")
                    self.monitor.metrics['signals_dropped_total'] += 1
                    self.monitor._copy_signal_buffer.put_nowait(signal)
                    self.monitor.metrics['signals_buffered_total'] += 1
        except Exception as e:
            logger.exception(f"Error handling {signal_type_str} signal for {signal.symbol}: {e}")
            await send_telegram_alert(f"‚ùå **–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –°–ò–ì–ù–ê–õ–ê '{signal_type_str}'**: {str(e)}")



    async def _handle_position_open_signal(self, signal: TradingSignal):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏"""
        logger.info(f"üü¢ POSITION OPEN DETECTED: {signal.symbol} {signal.side} {signal.size} @ {signal.price}")
        await send_telegram_alert(
            f"üü¢ **–ù–û–í–ê–Ø –ü–û–ó–ò–¶–ò–Ø –û–ë–ù–ê–†–£–ñ–ï–ù–ê**\n"
            f"Symbol: {signal.symbol}\n"
            f"Side: {signal.side}\n"
            f"Size: {signal.size}\n"
            f"Price: ${signal.price:.4f}\n"
            f"Time: {datetime.now().strftime('%H:%M:%S')}"
        )
        await self._handle_signal_with_stage2_check(signal, "OPEN")

    async def _handle_position_close_signal(self, signal: TradingSignal):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –ø–æ–∑–∏—Ü–∏–∏"""
        logger.info(f"üî¥ POSITION CLOSE DETECTED: {signal.symbol} {signal.side} {signal.size} @ {signal.price}")
        await send_telegram_alert(
            f"üî¥ **–ü–û–ó–ò–¶–ò–Ø –ó–ê–ö–†–´–¢–ê**\n"
            f"Symbol: {signal.symbol}\n"
            f"Side: {signal.side}\n"
            f"Size: {signal.size}\n"
            f"Price: ${signal.price:.4f}\n"
            f"Time: {datetime.now().strftime('%H:%M:%S')}"
        )
        await self._handle_signal_with_stage2_check(signal, "CLOSE")

    async def _handle_position_modify_signal(self, signal: TradingSignal):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏"""
        logger.info(f"üü° POSITION MODIFY DETECTED: {signal.symbol} {signal.side} {signal.size} @ {signal.price}")
        await send_telegram_alert(
            f"üü° **–ü–û–ó–ò–¶–ò–Ø –ò–ó–ú–ï–ù–ï–ù–ê**\n"
            f"Symbol: {signal.symbol}\n"
            f"Side: {signal.side}\n"
            f"New Size: {signal.size}\n"
            f"Price: ${signal.price:.4f}\n"
            f"Time: {datetime.now().strftime('%H:%M:%S')}"
        )
        await self._handle_signal_with_stage2_check(signal, "MODIFY")

    def _remember_leverage(self, symbol: str, lev: int) -> None:
        """Stores the last successfully set leverage for a symbol."""
        self._last_set_leverage[symbol] = int(lev)
        logger.info(f"Leverage for {symbol} remembered: {lev}x")

    async def _get_main_leverage_for_log(self, symbol: str, position_idx: int) -> int | None:
        """
        Gets the leverage for a symbol using a two-level cache.
        1. Checks the Main account's position cache (updated by the reconciliation loop).
        2. Falls back to the last-set leverage cache (updated by set_leverage calls).
        """
        lev = None
        # Level 1: Check the main positions cache from the monitor
        if self.monitor and hasattr(self.monitor, 'main_positions_cache'):
            cache_key = f"{symbol}#{position_idx}"
            cached_pos = self.monitor.main_positions_cache.get(cache_key)
            if cached_pos and 'leverage' in cached_pos:
                try:
                    lev = int(float(cached_pos['leverage']))
                    logger.debug(f"Found live leverage for {symbol} from MAIN position cache: {lev}x")
                except (ValueError, TypeError):
                    pass

        # Level 2: Fallback to the last successfully set leverage
        if lev is None:
            lev = self._last_set_leverage.get(symbol)
            if lev is not None:
                logger.debug(f"Found cached leverage for {symbol} from last set: {lev}x")
            else:
                logger.debug(f"No live or cached leverage found for {symbol}, will use None.")

        return lev
    
    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        stats = self.stats.copy()
        stats.update({
            'known_positions': len(self.known_positions),
            'queue_size': self.signal_queue.qsize(),
            'queue_max_size': self.signal_queue.maxsize,
            'history_size': len(self.position_history),
            'processed_history_size': len(self.processed_signals),
            'processing_active': self.processing_active,
            'queue_utilization_percent': (self.signal_queue.qsize() / self.signal_queue.maxsize) * 100
        })
        return stats

# ================================
# ‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ì–õ–ê–í–ù–´–ô –ö–õ–ê–°–°
# ================================

class FinalTradingMonitor:
    """
    ‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏
    
    –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç FinalFixedWebSocketManager (—Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∏–∫—Å–∞–º–∏)
    - ‚úÖ –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å websockets 15.0.1
    - ‚úÖ –í—Å–µ WebSocket –ø—Ä–æ–±–ª–µ–º—ã —Ä–µ—à–µ–Ω—ã
    - ‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã
    """
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        # State object for cross-component status
        self.copy_state = None
        self.stage2_system = None

        self.source_client = EnhancedBybitClient(
            SOURCE_API_KEY, SOURCE_API_SECRET, SOURCE_API_URL, "SOURCE", copy_state=self.copy_state
        )
        
        self.main_client = EnhancedBybitClient(
            MAIN_API_KEY, MAIN_API_SECRET, MAIN_API_URL, "MAIN", copy_state=self.copy_state
        )
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π WebSocket –º–µ–Ω–µ–¥–∂–µ—Ä
        self.websocket_manager = FinalFixedWebSocketManager(
            SOURCE_API_KEY, SOURCE_API_SECRET, "SOURCE_WS", copy_state=self.copy_state, final_monitor=self
        )
        
        self.signal_processor = ProductionSignalProcessor(account_id=DONOR_ACCOUNT_ID, monitor=self)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        self.running = False
        self.start_time = time.time()
        
        # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –°–æ–∑–¥–∞–µ–º Connection Monitor –≤ __init__
        self.connection_monitor = ConnectionMonitorPro()
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏
        self.active_tasks = set()
        self.should_stop = False

        # === NEW: —Ñ–ª–∞–≥–∏ –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º Stage-1 ===
        self._started = False                 # –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ start()
        self._monitoring_started = False      # –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self._main_task = None                # —Ö—ç–Ω–¥–ª –≥–ª–∞–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ Stage-1
        self._monitor_task = None             # —Ö—ç–Ω–¥–ª —Ü–∏–∫–ª–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        self._planned_shutdown_task = None    # –æ—Ç–ª–æ–∂–µ–Ω–Ω–∞—è "—ç—Å–∫–∞–ª–∞—Ü–∏—è" –Ω–∞ shutdown (–æ—Ç–º–µ–Ω—è–µ–º –ø—Ä–∏ —Ä–µ-–∫–æ–Ω–Ω–µ–∫—Ç–µ)
        self._system_active = False           # –≥–ª–∞–≤–Ω—ã–π —Ñ–ª–∞–≥ "–∂–∏—Ç—å" –¥–ª—è _run_main_loop()
        self.main_positions_cache = {}        # NEW: Cache for MAIN account positions
        self.reconcile_enqueued_last_minute = deque(maxlen=60)

        # --- Hot-Reload and Pause Mechanism ---
        self._reload_lock = asyncio.Lock()
        self._reloading = False
        self._is_paused = False
        self._deferred_signal_queue = deque()
        self._deferred_ops_queue = deque()
        self._processed_op_keys = set()
        # === /NEW ===

        # === Stage-2 Callback & Buffering ---
        self._copy_system_callback = None
        self._copy_callback_lock = asyncio.Lock()

        buffer_size = int(os.getenv("COPY_SIGNAL_BUFFER_SIZE", "128"))
        if buffer_size < 32: buffer_size = 32
        self._copy_signal_buffer = asyncio.Queue(maxsize=buffer_size)
        logger.info(f"Signal buffer size = {buffer_size}")

        self._buffer_drainer_task = None
        self._buffer_drainer_event = asyncio.Event()

        self.metrics = defaultdict(int)
        # === /End ---

    @property
    def _deferred_queue(self):
        """Provides backward compatibility for tests or other components
        that might still reference the old queue name.
        """
        return self._deferred_signal_queue

    async def pause_processing(self, timeout: int = 10):
        """Pauses signal processing and waits for all in-flight tasks to complete."""
        logger.info("Pausing system processing...")
        self._is_paused = True

        try:
            if self.signal_processor and hasattr(self.signal_processor, 'workers_idle'):
                logger.info("Waiting for in-flight signals to complete...")
                await asyncio.wait_for(self.signal_processor.workers_idle.wait(), timeout=timeout)
                logger.info("All in-flight tasks completed. System is fully paused.")
        except asyncio.TimeoutError:
            logger.warning(f"In-flight tasks did not complete within the {timeout}s timeout. System paused, but some tasks may still be running.")
        except Exception as e:
            logger.error(f"Error while waiting for workers to become idle: {e}", exc_info=True)

    async def resume_processing(self):
        """Resumes signal processing and processes any deferred signals."""
        logger.info("Resuming system processing...")
        self._is_paused = False  # Unpause first to allow signals to be added to the main queue

        # Process critical deferred operations first with idempotency
        if self._deferred_ops_queue:
            logger.info(f"Processing {len(self._deferred_ops_queue)} deferred critical operations.")
            while self._deferred_ops_queue:
                idempotency_key, op_signal = self._deferred_ops_queue.popleft()
                if idempotency_key in self._processed_op_keys:
                    logger.warning(f"Skipping duplicate deferred operation: {idempotency_key}")
                    continue

                try:
                    if self.signal_processor:
                        await self.signal_processor.add_signal(op_signal)
                    self._processed_op_keys.add(idempotency_key)
                except Exception as e:
                    logger.error(f"Error processing deferred op {op_signal}: {e}", exc_info=True)

        # Process regular deferred signals
        if self._deferred_signal_queue:
            logger.info(f"Processing {len(self._deferred_signal_queue)} deferred signals.")
            while self._deferred_signal_queue:
                signal = self._deferred_signal_queue.popleft()
                try:
                    # Add signal back to the main processing queue
                    if self.signal_processor:
                        await self.signal_processor.add_signal(signal)
                except Exception as e:
                    logger.error(f"Error processing deferred signal {signal}: {e}", exc_info=True)

        logger.info("System processing resumed.")

    async def reload_credentials_and_reconnect(self):
        """
        Atomically hot-reloads API credentials, ensuring the system remains
        in a consistent state throughout the process.
        """
        async with self._reload_lock:
            if self._reloading:
                logger.warning("Hot-reload already in progress. Skipping.")
                return

            self._reloading = True
            start_time = time.time()
            deferred_signals_before = len(self._deferred_queue)
            logger.info(f"HOT_RELOAD_START: Beginning credentials hot-reload process... (deferred signals: {deferred_signals_before})")

            try:
                # 1. Pause system processing
                await self.pause_processing()

                # 2. Disconnect WebSocket
                if self.websocket_manager:
                    logger.info("HOT_RELOAD_WS_DISCONNECT: Closing WebSocket connection...")
                    if hasattr(self.websocket_manager, 'unsubscribe_all'): # Optional: if implemented
                         await self.websocket_manager.unsubscribe_all()
                    await self.websocket_manager.close()

                # 3. Reload and apply new credentials
                from config import get_api_credentials, TARGET_ACCOUNT_ID, DONOR_ACCOUNT_ID

                target_creds = get_api_credentials(TARGET_ACCOUNT_ID)
                if not (target_creds and len(target_creds) == 2):
                    raise ValueError("Failed to load new credentials for TARGET account.")

                self.main_client.api_key, self.main_client.api_secret = target_creds
                logger.info("HOT_RELOAD_CREDS: Main client credentials updated.")

                source_creds = get_api_credentials(DONOR_ACCOUNT_ID)
                if source_creds and len(source_creds) == 2:
                    self.source_client.api_key, self.source_client.api_secret = source_creds
                    if self.websocket_manager:
                        self.websocket_manager.api_key, self.websocket_manager.api_secret = source_creds
                    logger.info("HOT_RELOAD_CREDS: Source client and WebSocket credentials updated.")

                # 4. Invalidate all relevant caches
                logger.info("HOT_RELOAD_CACHE_INVALIDATE: Clearing all cached data...")
                self.main_positions_cache.clear()
                if hasattr(self.main_client, 'invalidate_caches'): await self.main_client.invalidate_caches()
                if hasattr(self.source_client, 'invalidate_caches'): await self.source_client.invalidate_caches()
                if hasattr(self.signal_processor, 'invalidate_caches'): self.signal_processor.invalidate_caches()

                # 5. Reconnect WebSocket with retries
                if self.websocket_manager:
                    reconnect_attempts = 3
                    reconnect_delays = [0.5, 2, 5]
                    for attempt in range(reconnect_attempts):
                        try:
                            logger.info(f"HOT_RELOAD_WS_RECONNECT: Attempt {attempt + 1}/{reconnect_attempts} to reconnect WebSocket...")
                            await self.websocket_manager.connect()
                            if self.websocket_manager.ws and self.websocket_manager.status == 'authenticated':
                                logger.info("HOT_RELOAD_WS_RECONNECTED: WebSocket reconnected and authenticated.")
                                await self.websocket_manager.resubscribe_all()
                                break  # Success, exit loop
                            else:
                                raise ConnectionError("WebSocket connected but not authenticated.")
                        except Exception as e:
                            logger.warning(f"HOT_RELOAD_WS_RECONNECT_ATTEMPT_FAILED: Attempt {attempt + 1} failed: {e}")
                            if attempt < reconnect_attempts - 1:
                                await asyncio.sleep(reconnect_delays[attempt])
                            else:
                                logger.critical("HOT_RELOAD_WS_RECONNECT_FAILED: All WebSocket reconnect attempts failed.")
                                raise ConnectionError("Failed to reconnect and authenticate WebSocket after multiple attempts.")

                # 6. Refresh state from REST API
                logger.info(f"HOT_RELOAD_STATE_REFRESH: Fetching current state from REST API using balance_account_type='{BALANCE_ACCOUNT_TYPE}'.")
                await self.run_reconciliation_cycle(enqueue=False) # Refresh positions without queueing
                new_main_balance = await self._get_balance_safe(self.main_client, "MAIN_RELOAD")

                if new_main_balance is None:
                    raise ValueError("Failed to fetch new balance after reload.")

                # D) Rebind Stage-2 to the fresh client
                if self.stage2_system:
                    logger.info("Rebinding Stage-2 to fresh client after key reload...")
                    self.stage2_system.main_client = self.main_client
                    self.stage2_system.source_client = self.source_client
                    # Re-bind the callback to the fresh instance
                    await self.connect_copy_system(self.stage2_system)
                    logger.info("‚úÖ Stage-2 rebound and callback re-bound after key reload.")


                # 7. Final health check and logging
                duration_ms = (time.time() - start_time) * 1000
                ws_topics_count = len(self.websocket_manager.subscriptions) if self.websocket_manager else 0

                summary_log = (
                    f"HOT_RELOAD_SUMMARY: "
                    f"duration_ms={duration_ms:.0f}, "
                    f"deferred_signals_processed={deferred_signals_before}, "
                    f"ws_topics_re-subscribed={ws_topics_count}"
                )
                logger.info(summary_log)

                await send_telegram_alert(
                    f"‚úÖ –ì–æ—Ä—è—á–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {duration_ms:.0f}ms.\n"
                    f"–ù–æ–≤—ã–π –±–∞–ª–∞–Ω—Å: {new_main_balance:.2f} USDT\n"
                    f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {deferred_signals_before}"
                )

                # 8. Resume processing only on success
                await self.resume_processing()

            except Exception as e:
                logger.critical(f"HOT_RELOAD_FAILED: {e}", exc_info=True)
                await send_telegram_alert(f"‚ùå –ì–æ—Ä—è—á–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}\n–°–∏—Å—Ç–µ–º–∞ –Ω–∞ –ø–∞—É–∑–µ. –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ.")
                # Do NOT resume processing on failure. Leave it paused.

            finally:
                self._reloading = False
                logger.info("HOT_RELOAD_FINISH: Reload process finished.")
        
    def set_copy_state_ref(self, state_obj):
        """Sets the reference to the shared copy_state object."""
        self.copy_state = state_obj
        # Propagate the reference to child components
        if hasattr(self, 'main_client'):
            self.main_client.copy_state = state_obj
        if hasattr(self, 'source_client'):
            self.source_client.copy_state = state_obj
        if hasattr(self, 'websocket_manager'):
            self.websocket_manager.copy_state = state_obj
        logger.info("Shared copy_state reference has been set in FinalTradingMonitor and its children.")

        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ WebSocket —Å–æ–±—ã—Ç–∏–π
        self._register_websocket_handlers()
        
        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–æ–π)
        try:
            signal.signal(signal.SIGINT, self._signal_handler)
            signal.signal(signal.SIGTERM, self._signal_handler)
        except (AttributeError, ValueError):
            # Windows –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Å–∏—Å—Ç–µ–º—ã –º–æ–≥—É—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —ç—Ç–∏ —Å–∏–≥–Ω–∞–ª—ã
            pass

    async def _ensure_stage2_ready(self) -> bool:
        """Ensures Stage-2 is initialized and connected, then re-binds the callback."""
        # Quick check if everything is already fine
        if self.stage2_system and getattr(self.stage2_system, 'copy_connected', False) and self._copy_system_callback:
            return True

        logger.warning("Stage-2 is not connected or callback is missing. Attempting lazy re-initialization and re-binding...")
        try:
            if self.stage2_system is None:
                logger.info("Stage-2 system instance not found, creating a new one.")
                from stage2_copy_system import Stage2CopyTradingSystem
                from config import dry_run

                self.stage2_system = Stage2CopyTradingSystem(base_monitor=self)
                self.set_copy_state_ref(self.stage2_system.copy_state)
                self.stage2_system.demo_mode = dry_run

            # Re-bind clients to ensure they are fresh after any hot-reloads
            self.stage2_system.main_client = self.main_client
            self.stage2_system.source_client = self.source_client

            # Re-initialize the system to ensure all handlers are correctly registered
            await self.stage2_system.initialize()

            # Manually set the flags to connected
            self.stage2_system.copy_connected = True
            self.stage2_system.trade_executor_connected = True

            # CRITICAL: Re-bind the callback using the new reliable method
            await self.connect_copy_system(self.stage2_system)

            if self._copy_system_callback:
                 logger.info("‚úÖ Stage-2 lazy re-initialization and callback binding successful.")
                 return True
            else:
                 logger.error("üî• Stage-2 re-initialized, but callback binding failed.")
                 return False
        except Exception:
            logger.exception("üî• Failed to lazy-initialize Stage-2.")
            if self.stage2_system:
                self.stage2_system.copy_connected = False
                self.stage2_system.trade_executor_connected = False
            return False


    async def _register_connections_for_monitoring(self):
        """‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        try:
            logger.info("Registering connections for monitoring...")
            
            # API –∫–ª–∏–µ–Ω—Ç—ã
            await self.connection_monitor.register_connection(
                'source_api',
                self.source_client,
                self._health_check_api_client,
                self._recover_api_client
            )
            
            await self.connection_monitor.register_connection(
                'main_api', 
                self.main_client,
                self._health_check_api_client,
                self._recover_api_client
            )
            
            # WebSocket
            await self.connection_monitor.register_connection(
                'websocket',
                self.websocket_manager,
                self._health_check_websocket,
                self._recover_websocket
            )
            
            logger.info("‚úÖ All connections registered for monitoring")
            
        except Exception as e:
            logger.error(f"Failed to register connections for monitoring: {e}")
            # –ù–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º—É –∏–∑-–∑–∞ —ç—Ç–æ–π –æ—à–∏–±–∫–∏
    
    async def _health_check_api_client(self, client):
        """Health check –¥–ª—è API –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            await client.time_sync.sync_server_time(client.api_url)
            return True
        except Exception as e:
            logger.debug(f"API client health check failed: {e}")
            return False

    async def _health_check_websocket(self, ws_manager):
        """Health check –¥–ª—è WebSocket"""
        try:
            return ws_manager.status == ConnectionStatus.AUTHENTICATED
        except Exception as e:
            logger.debug(f"WebSocket health check failed: {e}")
            return False

    async def _recover_api_client(self, client):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ API –∫–ª–∏–µ–Ω—Ç–∞"""
        try:
            logger.info(f"Recovering API client: {client.client_name}")
            await client.time_sync.sync_server_time(client.api_url)
            logger.info(f"‚úÖ API client {client.client_name} recovered")
        except Exception as e:
            logger.error(f"Failed to recover API client {client.client_name}: {e}")

    async def _recover_websocket(self, ws_manager):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ WebSocket"""
        try:
            logger.info("Recovering WebSocket connection...")
            await ws_manager.reconnect()
            logger.info("‚úÖ WebSocket connection recovered")
        except Exception as e:
            logger.error(f"Failed to recover WebSocket: {e}")

    async def _get_balance_safe(self, client, label: str) -> Optional[float]:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞: –Ω–µ –≤–∞–ª–∏—Ç —Ü–∏–∫–ª –∏ –Ω–µ –∏–Ω–∏—Ü–∏–∏—Ä—É–µ—Ç –ª–æ–∂–Ω—ã–µ DD –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö —Å–±–æ—è—Ö.
        """
        try:
            bal = await client.get_balance()  # –≤–∞—à —Ä–µ–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ (—Å—É–¥—è –ø–æ –ª–æ–≥—É)
            if bal is not None:
                logger.info("%s - Balance: %.2f USDT", label, bal)
                # –µ—Å–ª–∏ –µ—Å—Ç—å —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä, –ø–æ–º–µ—á–∞–µ–º —É—Å–ø–µ—Ö API
                if hasattr(self, "supervisor") and self.supervisor:
                    try:
                        await self.supervisor.on_api_success()
                    except Exception:
                        pass
            return bal
        except Exception as e:
            logger.error("%s - Balance error: %s", label, e)
            # –µ—Å–ª–∏ –µ—Å—Ç—å —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä, —Å–æ–æ–±—â–∞–µ–º –æ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ API
            if hasattr(self, "supervisor") and self.supervisor:
                try:
                    await self.supervisor.on_api_failure(str(e))
                except Exception:
                    pass
            return None


    @property 
    def ws(self):
        """–î–æ—Å—Ç—É–ø –∫ WebSocket –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏"""
        return self.websocket_manager.ws
        
    def _signal_handler(self, signum, frame):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""
        logger.info(f"Received signal {signum}, initiating graceful shutdown...")
        self.should_stop = True

    def _register_websocket_handlers(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ WebSocket —Å–æ–±—ã—Ç–∏–π"""
        self.websocket_manager.register_handler(
            'position',
            self.signal_processor.process_position_update
        )

    def _normalize_rest_position(self, p: dict) -> Optional[dict]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ REST API —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º."""
        size = safe_float(p.get('size'))
        if not (size > 0):
            return None

        symbol = p.get('symbol')
        if not symbol:
            return None

        try:
            idx = int(p.get('positionIdx', 0))
        except (ValueError, TypeError):
            idx = 0

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–Ω—ã –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É: entryPrice -> sessionAvgPrice -> markPrice -> 0
        price = safe_float(p.get('entryPrice') or p.get('sessionAvgPrice') or p.get('markPrice') or 0)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–æ—Ä–æ–Ω—ã
        side = (p.get('side') or "").strip()

        return {
            'key': f"{symbol}#{idx}",
            'symbol': symbol,
            'size': size,
            'side': side,
            'price': price,
            'leverage': safe_float(p.get('leverage', 1)),
            'position_idx': idx,
        }

    async def run_reconciliation_cycle(self, enqueue: bool = True):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω —Ü–∏–∫–ª —Å–≤–µ—Ä–∫–∏ –ø–æ–∑–∏—Ü–∏–π –º–µ–∂–¥—É –î–û–ù–û–†–û–ú –∏ –û–°–ù–û–í–ù–´–ú –∞–∫–∫–∞—É–Ω—Ç–æ–º.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é.
        """
        logger.info("--- Running REST API Reconciliation Cycle ---")
        try:
            # Ensure time is synchronized before making API calls
            await self.source_client.time_sync.ensure_time_sync(self.source_client.api_url)
            await self.main_client.time_sync.ensure_time_sync(self.main_client.api_url)

            donor_positions_raw = await self.source_client.get_positions()
            main_positions_raw = await self.main_client.get_positions()

            if donor_positions_raw is None or main_positions_raw is None:
                logger.error("RECONCILE: Failed to fetch positions. Aborting cycle.")
                return

            donor_positions = {p['key']: p for p in (self._normalize_rest_position(pos) for pos in donor_positions_raw) if p}
            main_positions = {p['key']: p for p in (self._normalize_rest_position(pos) for pos in main_positions_raw) if p}

            # Update the main positions cache
            self.main_positions_cache = {p['key']: p for p in main_positions.values()}
            logger.info(f"Main positions cache updated with {len(self.main_positions_cache)} positions.")

            enqueued_signals, to_open, to_close, to_modify = 0, 0, 0, 0
            all_keys = set(donor_positions.keys()) | set(main_positions.keys())

            for key in all_keys:
                donor_pos, main_pos = donor_positions.get(key), main_positions.get(key)
                signal_to_add = None
                if donor_pos and not main_pos:
                    to_open += 1
                    signal_to_add = TradingSignal(signal_type=SignalType.POSITION_OPEN, symbol=donor_pos['symbol'], side=donor_pos['side'], size=donor_pos['size'], price=donor_pos['price'], timestamp=time.time(), metadata={'source': 'reconcile', 'position_idx': donor_pos['position_idx'], 'leverage': donor_pos['leverage']}, priority=1)
                elif not donor_pos and main_pos:
                    to_close += 1
                    copy_connected = getattr(self.stage2_system, 'copy_connected', True)

                    if not copy_connected:
                        logger.info(f"RECONCILE: copy_connected=False. Attempting direct REST close for {main_pos['symbol']}.")
                        close_side = "Sell" if main_pos['side'] == "Buy" else "Buy"
                        close_result = await self.main_client.place_order(
                            category='linear',
                            symbol=main_pos['symbol'],
                            side=close_side,
                            orderType='Market',
                            qty=str(main_pos['size']),
                            reduceOnly=True
                        )
                        if close_result and close_result.get('orderId'):
                            exec_price = safe_float(close_result.get('avgPrice', main_pos['price']))
                            synthetic_payload = {
                                "symbol": main_pos['symbol'],
                                "qty": main_pos['size'],
                                "side": main_pos['side'],
                                "close_price": exec_price,
                                "source": "reconcile_forced",
                                "account_id": TARGET_ACCOUNT_ID,
                                "ts": utc_now_iso(),
                            }
                            await positions_writer.log_close(synthetic_payload)
                            logger.info(f"RECONCILE_FORCED_CLOSE_OK symbol={main_pos['symbol']} qty={main_pos['size']} price={exec_price}")
                        else:
                            logger.error(f"RECONCILE_FORCED_CLOSE_FAIL: Failed to close {main_pos['symbol']} via REST.")
                        continue # Skip adding to signal queue

                    signal_to_add = TradingSignal(signal_type=SignalType.POSITION_CLOSE, symbol=main_pos['symbol'], side=main_pos['side'], size=main_pos['size'], price=main_pos['price'], timestamp=time.time(), metadata={'source': 'reconcile', 'position_idx': main_pos['position_idx']}, priority=1)
                elif donor_pos and main_pos and (abs(donor_pos['size'] - main_pos['size']) > 1e-9 or donor_pos['side'] != main_pos['side']):
                    to_modify += 1
                    signal_to_add = TradingSignal(signal_type=SignalType.POSITION_MODIFY, symbol=donor_pos['symbol'], side=donor_pos['side'], size=donor_pos['size'], price=donor_pos['price'], timestamp=time.time(), metadata={'source': 'reconcile', 'position_idx': donor_pos['position_idx'], 'leverage': donor_pos['leverage'], 'prev_size_main': main_pos['size']}, priority=1)

                if signal_to_add and enqueue:
                    logger.info(f"RECONCILE: ENQUEUE {signal_to_add.signal_type.name} {key} size={signal_to_add.size} side={signal_to_add.side}")
                    await self.signal_processor.add_signal(signal_to_add)
                    enqueued_signals += 1
                    self.reconcile_enqueued_last_minute.append(time.time())

            summary_log = f"RECONCILE: fetched donor={len(donor_positions)}, main={len(main_positions)} | to_open={to_open}, to_close={to_close}, to_modify={to_modify}"
            logger.info(summary_log)
            logger.info(f"RECONCILE SUMMARY: enqueued={enqueued_signals}")
            if to_open or to_close or to_modify:
                 await send_telegram_alert(f"‚úÖ Reconciliation Run: {summary_log}. Enqueued {enqueued_signals} signals.")

        except Exception as e:
            logger.error(f"RECONCILE: Critical error during reconciliation cycle: {e}", exc_info=True)
            await send_telegram_alert(f"üî• RECONCILE FAILED: {e}")

        # Auto-healer logic
        try:
            exchange_positions_raw = await self.main_client.get_positions()
            db_positions_raw = positions_writer.get_open_positions(TARGET_ACCOUNT_ID)

            exchange_keys = {f"{p.get('symbol')}#{int(p.get('positionIdx', 0))}" for p in exchange_positions_raw if safe_float(p.get('size')) > 0}
            db_keys = {f"{p.get('symbol')}#{int(p.get('position_idx', 0))}" for p in db_positions_raw}

            to_heal = db_keys - exchange_keys
            if to_heal:
                logger.info(f"AUTO_HEAL: Found {len(to_heal)} positions to hard-close in DB.")
                healed_count = 0
                for key in to_heal:
                    symbol, pos_idx_str = key.split('#')
                    pos_idx = int(pos_idx_str)

                    # Find the corresponding position in the db_positions_raw list
                    stale_pos = next((p for p in db_positions_raw if p.get('symbol') == symbol and int(p.get('position_idx', 0)) == pos_idx), None)
                    if stale_pos:
                        synthetic_payload = {
                            "symbol": stale_pos['symbol'],
                            "qty": stale_pos['qty'],
                            "side": stale_pos['side'],
                            "close_price": stale_pos.get('mark_price') or stale_pos.get('entry_price'),
                            "source": "auto_heal",
                            "account_id": TARGET_ACCOUNT_ID,
                            "ts": utc_now_iso(),
                            "position_idx": pos_idx,
                        }
                        await positions_writer.log_close(synthetic_payload)
                        healed_count += 1
                if healed_count > 0:
                    logger.info(f"AUTO_HEAL_CLOSED n={healed_count}")
        except Exception as e:
            logger.error(f"AUTO_HEAL: Critical error during auto-healing cycle: {e}", exc_info=True)


    async def _periodic_reconciliation_loop(self, interval_sec: int = 60):
        """–ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª, –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–≤–µ—Ä–∫—É –ø–æ–∑–∏—Ü–∏–π."""
        logger.info(f"Starting periodic reconciliation loop with interval {interval_sec}s.")
        while self.running and not self.should_stop:
            try:
                await asyncio.sleep(interval_sec)
                logger.info("Triggering periodic reconciliation...")
                await self.run_reconciliation_cycle()
            except asyncio.CancelledError:
                logger.info("Periodic reconciliation loop cancelled.")
                break
            except Exception as e:
                logger.error(f"Error in periodic reconciliation loop: {e}", exc_info=True)
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∂–¥–µ–º –¥–æ–ª—å—à–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–ø–∞–º–∞
                await asyncio.sleep(interval_sec * 2)

    def _ensure_creds(self):
        from config import get_api_credentials, TARGET_ACCOUNT_ID
        creds = get_api_credentials(TARGET_ACCOUNT_ID)
        if not creds:
            raise RuntimeError("Missing API credentials at runtime (–≤–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–∏ —á–µ—Ä–µ–∑ /keys)")
        self.api_key, self.api_secret = creds

    async def start(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ò –ò–î–ï–ú–ü–û–¢–ï–ù–¢–ù–´–ô –∑–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (Stage-1)"""
        if getattr(self, "_started", False):
            logger.info("FinalTradingMonitor.start() called again ‚Äî ignored (idempotent)")
            return

        self._ensure_creds()
        self._started = True
        self._system_active = True

        try:
            logger.info("üöÄ Starting Final Trading Monitor System...")
            logger.info("‚úÖ WebSocket fixes applied and integrated!")
            self.running = True

            logger.info("Registering connections for monitoring...")
            await self._register_connections_for_monitoring()
            logger.info("‚úÖ All connections registered for monitoring")

            logger.info("Testing API connections...")
            source_balance = await self._get_balance_safe(self.source_client, "SOURCE")
            main_balance   = await self._get_balance_safe(self.main_client,   "MAIN")

            if source_balance is not None:
                logger.info(f"‚úÖ Source account balance: {source_balance:.2f} USDT")
            if main_balance is not None:
                logger.info(f"‚úÖ Main account balance: {main_balance:.2f} USDT")

            # <<< ADDED: –∑–∞–ø—É—Å—Ç–∏–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å —Å–Ω–∞–ø—à–æ—Ç–æ–≤ TARGET-–∫–æ—à–µ–ª—å–∫–∞
            if not getattr(self, "_snapshot_task", None):
                self._snapshot_task = asyncio.create_task(
                    self._wallet_snapshot_loop(interval_sec=60),
                    name="BalanceSnapshots"
                )
                logger.info("üîÑ Balance snapshot task started (interval=60s)")
                # –ü—Ä–æ–≤–µ—Ä–∏–º —á—Ç–æ —Å–Ω–∞–ø—à–æ—Ç—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞—é—Ç
                asyncio.create_task(self._verify_snapshots_working())


            if hasattr(self, "risk_ctx") and self.risk_ctx:
                try:
                    self.risk_ctx.update_equity(main_balance)
                    if hasattr(self.risk_ctx, "is_data_reliable") and not self.risk_ctx.is_data_reliable():
                        state_name = getattr(getattr(self.risk_ctx, "equity_state", None), "name", "UNKNOWN")
                        logger.warning("Risk data not reliable (%s) ‚Äî skip DD alerts", state_name)
                except Exception as _e:
                    logger.debug("Risk context update skipped: %s", _e)

            await self.signal_processor.start_processing()

            # Create the single buffer drainer task
            if self._buffer_drainer_task is None:
                self._buffer_drainer_task = asyncio.create_task(self._run_buffer_drainer(), name="SignalBufferDrainer")
                self.active_tasks.add(self._buffer_drainer_task)

            logger.info("Connecting to WebSocket with integrated fixes...")
            await self.websocket_manager.connect()

            # –ö–†–ò–¢–ò–ß–ù–û: –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ–Ω–µ
            asyncio.create_task(self.websocket_manager._recv_loop(), name="WS_RecvLoop")
            logger.info("WebSocket _recv_loop task started.")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é —Å–≤–µ—Ä–∫—É –ø–æ–∑–∏—Ü–∏–π
            asyncio.create_task(self.run_reconciliation_cycle(), name="InitialReconcile")

            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é —Å–≤–µ—Ä–∫—É –≤ —Ñ–æ–Ω–µ
            asyncio.create_task(self._periodic_reconciliation_loop(), name="PeriodicReconcile")

            await send_telegram_alert("‚úÖ Final Trading Monitor System started with WebSocket fixes!")

            if not getattr(self, "_main_task", None):
                if hasattr(self, "_run_main_loop"):
                    self._main_task = asyncio.create_task(self._run_main_loop(), name="Stage1_Monitor")
                else:
                    self._main_task = asyncio.create_task(self._main_monitoring_loop(), name="Stage1_Monitor")

            return

        except Exception as e:
            self._started = False
            self._system_active = False
            logger.error(f"System startup error: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
            try:
                await send_telegram_alert(f"System startup failed: {e}")
            except Exception:
                pass
            raise

    async def _wallet_snapshot_loop(self, interval_sec: int = 60):
        """
        –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞: –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥ –±–µ—Ä—ë–º –∫–æ—à–µ–ª—ë–∫ TARGET (MAIN),
        –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –°–ù–ê–ü–®–û–¢ –±–∞–∑—ã (wallet –±–µ–∑ UPNL) –≤ balance_snapshots.
        –ö–†–ò–¢–ò–ß–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º account_id=1 (TARGET), –∞ –Ω–µ 2 (DONOR)!
        """
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º writer
        writer = getattr(self, "positions_writer", None)
        if writer is None:
            try:
                from positions_db_writer import positions_writer as writer
                logger.info("Balance snapshots: using positions_writer from positions_db_writer module")
            except ImportError:
                try:
                    from app.positions_db_writer import positions_writer as writer
                    logger.info("Balance snapshots: using positions_writer from app.positions_db_writer")
                except ImportError as e:
                    logger.warning("Balance snapshots disabled: PositionsDBWriter not available (%s)", e)
                    return

        logger.info("‚úÖ Balance snapshot writer initialized successfully")
    
        # –ö–†–ò–¢–ò–ß–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π account_id –¥–ª—è TARGET
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é TARGET_ACCOUNT_ID = 1 (–∏–∑ –≤–∞—à–µ–≥–æ .env)
        import os
        target_account_id = int(os.getenv('TARGET_ACCOUNT_ID', '1'))
    
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ config –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        try:
            from config import TARGET_ACCOUNT_ID
            if TARGET_ACCOUNT_ID:
                target_account_id = int(TARGET_ACCOUNT_ID)
                logger.info(f"Using TARGET_ACCOUNT_ID={target_account_id} from config")
        except (ImportError, ValueError):
            logger.info(f"Using TARGET_ACCOUNT_ID={target_account_id} from env")
    
        # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: —É–±–µ–¥–∏–º—Å—è —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π ID
        if target_account_id != 1:
            logger.warning(f"‚ö†Ô∏è TARGET_ACCOUNT_ID={target_account_id} is not 1! Check your config!")
    
        logger.info(f"üìä Balance snapshots will be saved for account_id={target_account_id} (TARGET)")
    
        snapshots_saved = 0
        last_save_time = 0
    
        while getattr(self, "_system_active", False) and getattr(self, "running", False):
            try:
                current_time = time.time()
            
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—à–µ–ª –ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª
                if current_time - last_save_time < interval_sec:
                    await asyncio.sleep(1)  # –ö–æ—Ä–æ—Ç–∫–∏–π sleep —á—Ç–æ–±—ã –Ω–µ –Ω–∞–≥—Ä—É–∂–∞—Ç—å CPU
                    continue
            
                normalized = await self._fetch_main_wallet_normalized()
                if normalized:
                    # –ö–†–ò–¢–ò–ß–ù–û: –Ø–≤–Ω–æ –ø–µ—Ä–µ–¥–∞—ë–º account_id=1 –¥–ª—è TARGET!
                    # –ù–ï –ø–æ–ª–∞–≥–∞–µ–º—Å—è –Ω–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ª–æ–≥–∏–∫—É writer
                    writer.save_balance_snapshot(
                        account_id=target_account_id,  # –Ø–í–ù–û —É–∫–∞–∑—ã–≤–∞–µ–º TARGET account_id
                        balance_data=normalized
                    )
                
                    snapshots_saved += 1
                    last_save_time = current_time
                
                    wallet_base = float(normalized.get("totalWalletBalance", 0))
                
                    logger.debug(
                        "Snapshot #%d saved: account_id=%d, base=%.2f, free=%.2f, im=%.2f, upnl=%.2f",
                        snapshots_saved,
                        target_account_id,  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫–æ–π account_id –∏—Å–ø–æ–ª—å–∑—É–µ–º
                        wallet_base,
                        float(normalized.get("availableBalance", 0)),
                        float(normalized.get("totalInitialMargin", 0)),
                        float(normalized.get("unrealizedPnl", 0)),
                    )
                
                    # –ö–∞–∂–¥—ã–µ 10 —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    if snapshots_saved % 10 == 0:
                        logger.info(
                            "‚úÖ Balance snapshots: %d saved for account_id=%d (TARGET), wallet_base=%.2f USDT",
                            snapshots_saved,
                            target_account_id,
                            wallet_base
                        )
                
                    # –ü–µ—Ä–≤—ã–π —Å–Ω–∞–ø—à–æ—Ç –ª–æ–≥–∏—Ä—É–µ–º –≤—Å–µ–≥–¥–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                    if snapshots_saved == 1:
                        logger.info(
                            "üéØ FIRST snapshot saved: account_id=%d, wallet=%.2f, interval=%ds",
                            target_account_id,
                            wallet_base,
                            interval_sec
                        )
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º
                        try:
                            await send_telegram_alert(
                                f"‚úÖ –°–Ω–∞–ø—à–æ—Ç—ã –±–∞–ª–∞–Ω—Å–∞ –∑–∞–ø—É—â–µ–Ω—ã!\n"
                                f"Account ID: {target_account_id} (TARGET)\n"
                                f"Wallet Base: {wallet_base:.2f} USDT\n"
                                f"–ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval_sec} —Å–µ–∫"
                            )
                        except Exception:
                            pass
                        
            except Exception as e:
                logger.warning("Wallet snapshot loop error: %s", e)
                await asyncio.sleep(5)  # –ü—Ä–∏ –æ—à–∏–±–∫–µ –∂–¥–µ–º 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                continue

            # –û—Å–Ω–æ–≤–Ω–æ–π sleep –º–µ–∂–¥—É —Å–Ω–∞–ø—à–æ—Ç–∞–º–∏
            await asyncio.sleep(1)
    
        logger.info("Balance snapshot loop stopped (snapshots_saved=%d)", snapshots_saved)

    async def _fetch_main_wallet_normalized(self) -> dict | None:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è save_balance_snapshot():
        {
            "currency": "USDT",
            "totalWalletBalance": <Decimal>,   # –ë–ê–ó–ê –±–µ–∑ UPNL
            "availableBalance":   <Decimal|0>,
            "totalInitialMargin": <Decimal|0>,
            "unrealizedPnl":      <Decimal|0>, # –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏/–ª–æ–≥–∏–∫–∏, –≤ –ë–î –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è
        }
        """
        # –õ–æ–∫–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Decimal
        def _D(x):
            try:
                return Decimal(str(x))
            except Exception:
                return None
    
        raw = None

        # 1) –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–∑–≤–∞—Ç—å —Ç–∏–ø–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–ª–∏–µ–Ω—Ç–∞ –±–µ–∑ –ø–æ–ª–æ–º–∫–∏ —Ç–µ–∫—É—â–µ–π –ª–æ–≥–∏–∫–∏
        for meth in ("get_wallet_balance", "get_balance", "wallet_balance"):
            fn = getattr(self.main_client, meth, None)
            if fn:
                try:
                    # –¥–æ–ø—É—Å–∫–∞–µ–º –∫–∞–∫ sync, —Ç–∞–∫ –∏ async –∫–ª–∏–µ–Ω—Ç–æ–≤
                    raw = await fn() if asyncio.iscoroutinefunction(fn) else fn()
                    logger.debug("Fetched wallet via method: %s", meth)
                    break
                except Exception as e:
                    logger.debug("Main wallet fetch via %s failed: %s", meth, e)

        if not raw:
            logger.warning("Failed to fetch main wallet - all methods failed")
            return None

        # 2) –†–∞–∑–±–∏—Ä–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞ Bybit
        try:
            # v5 unified: {"result": {"list": [{"coin": [{"coin":"USDT", ...}], ...}]}}
            result = (raw.get("result") or {})
            lst = result.get("list") or result.get("balances") or []
            if isinstance(lst, list) and lst:
                # –ª–∏–±–æ –≤–ª–æ–∂–µ–Ω–Ω—ã–π coin[], –ª–∏–±–æ —Å—Ä–∞–∑—É —Å–ø–∏—Å–æ–∫ –ø–æ –≤–∞–ª—é—Ç–∞–º
                coins = None
                if isinstance(lst[0], dict) and "coin" in lst[0]:
                    coins = lst[0].get("coin") or []
                else:
                    coins = lst

                usdt = None
                for c in coins:
                    name = (c.get("coin") or c.get("currency") or "").upper()
                    if name in ("USDT", "USD", "USDC"):
                        usdt = c
                        break

                if usdt:
                    wallet = _D(usdt.get("walletBalance") or usdt.get("totalWalletBalance") or usdt.get("cashBalance"))
                    avail  = _D(usdt.get("availableBalance") or usdt.get("availableToWithdraw"))
                    im     = _D(usdt.get("totalInitialMargin") or usdt.get("usedMargin") or usdt.get("positionMargin"))
                    upnl   = _D(usdt.get("unrealisedPnl") or usdt.get("unrealizedPnl"))

                    # –º–∏–Ω–∏–º—É–º ‚Äî –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–∞–∑–∞
                    if wallet is None:
                        # –∏–Ω–æ–≥–¥–∞ –¥–∞—é—Ç —Ç–æ–ª—å–∫–æ equity ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –±–∞–∑—É –∫–∞–∫ equity - upnl
                        equity = _D(usdt.get("equity") or usdt.get("totalEquity"))
                        if equity is not None and upnl is not None:
                            wallet = equity - upnl

                    if wallet is None:
                        logger.warning("No wallet balance found in parsed response")
                        return None

                    logger.debug("Normalized wallet: base=%s, available=%s, im=%s, upnl=%s",
                                wallet, avail, im, upnl)

                    return {
                        "currency": "USDT",
                        "totalWalletBalance": wallet,
                        "availableBalance":   avail or Decimal("0"),
                        "totalInitialMargin": im or Decimal("0"),
                        "unrealizedPnl":      upnl or Decimal("0"),
                    }
        except Exception as e:
            logger.debug("Wallet normalization failed: %s", e)

        # 3) –§–æ–ª–ª–±—ç–∫ –Ω–∞ –ø–ª–æ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
        try:
            wallet = _D(raw.get("totalWalletBalance") or raw.get("walletBalance"))
            upnl   = _D(raw.get("unrealisedPnl") or raw.get("unrealizedPnl"))
            if wallet is None:
                equity = _D(raw.get("equity") or raw.get("totalEquity"))
                if equity is not None and upnl is not None:
                    wallet = equity - upnl
            if wallet is None:
                return None
            
            logger.debug("Fallback normalization: wallet=%s, upnl=%s", wallet, upnl)
        
            return {
                "currency": "USDT",
                "totalWalletBalance": wallet,
                "availableBalance":   _D(raw.get("availableBalance"))   or Decimal("0"),
                "totalInitialMargin": _D(raw.get("totalInitialMargin")) or Decimal("0"),
                "unrealizedPnl":      upnl or Decimal("0"),
            }
        except Exception:
            return None
        
    async def _verify_snapshots_working(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ —Å–Ω–∞–ø—à–æ—Ç—ã –±–∞–ª–∞–Ω—Å–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è"""
        await asyncio.sleep(70)  # –ñ–¥—ë–º —á—É—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ positions_writer
            from positions_db_writer import positions_writer
        
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞–ª–∞–Ω—Å –∏–∑ –ë–î
            latest_balance = positions_writer.get_latest_balance(1)
        
            if latest_balance is not None:
                logger.info("‚úÖ Balance snapshots WORKING! Latest balance in DB: %.2f USDT", latest_balance)
                await send_telegram_alert(f"‚úÖ Balance snapshots –∞–∫—Ç–∏–≤–Ω—ã! –ë–∞–∑–∞ –≤ –ë–î: {latest_balance:.2f} USDT")
            else:
                logger.warning("‚ö†Ô∏è Balance snapshots might not be working - no data in DB after 70s")
                await send_telegram_alert("‚ö†Ô∏è –°–Ω–∞–ø—à–æ—Ç—ã –±–∞–ª–∞–Ω—Å–∞ –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏")
        except Exception as e:
            logger.error("Failed to verify snapshots: %s", e)


    async def _main_monitoring_loop(self):
        """‚úÖ –ñ–ò–í–û–ô –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª Stage-1 (–Ω–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è —Å–∞–º –ø–æ —Å–µ–±–µ)"""
        try:
            while self._system_active:
                # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ WS (–ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å health-check)
                if self.websocket_manager and not is_websocket_open(self.websocket_manager.ws):
                    logger.warning("WebSocket not connected ‚Äî awaiting reconnect/recovery...")
            
                # 2. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –æ—Ç—á—ë—Ç—ã/—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–≤–æ—é –ª–æ–≥–∏–∫—É –∏–∑ _monitoring_loop)
                current_time = time.time()
                if hasattr(self, "_last_stats_report"):
                    if current_time - self._last_stats_report > PRODUCTION_CONFIG['stats_report_interval']:
                        try:
                            await self._report_system_stats()
                        except Exception as e:
                            logger.error(f"Stats report failed: {e}")
                        self._last_stats_report = current_time
                else:
                    self._last_stats_report = current_time

                # 3. –õ—ë–≥–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Ü–∏–∫–ª–∞
                await asyncio.sleep(1.0)

        except asyncio.CancelledError:
            logger.info("Main monitoring loop cancelled")
        except Exception as e:
            logger.error(f"Main monitoring loop error: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")
        finally:
            # !!! –ù–ï –≤—ã–∑—ã–≤–∞—Ç—å –∑–¥–µ—Å—å self._shutdown(), —ç—Ç–æ –¥–µ–ª–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä !!!
            return

    
    async def _monitoring_loop(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–∏—Å—Ç–µ–º—ã"""
        last_stats_report = 0
        stats_interval = PRODUCTION_CONFIG['stats_report_interval']
        
        try:
            while self.running and not self.should_stop:
                current_time = time.time()
                
                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å
                if current_time - last_stats_report > stats_interval:
                    await self._report_system_stats()
                    last_stats_report = current_time
                
                # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
                if int(current_time) % 600 == 0:  # –ö–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
                    await self._memory_management()
                
                await asyncio.sleep(30)  # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                
        except asyncio.CancelledError:
            logger.debug("Monitoring loop cancelled")
        except Exception as e:
            logger.error(f"Monitoring loop error: {e}")
    
    async def connect_copy_system(self, copy_system):
        """
        Connects Stage-2 and reliably binds the copy callback.
        """
        async with self._copy_callback_lock:
            self.stage2_system = copy_system
            
            candidate = None
            candidate_name = None
            # Prefer a known, documented method on Stage2; fallback to common candidates
            for name in ("enqueue_signal", "handle_incoming_signal", "process_signal", "_enqueue_signal", "process_copy_signal"):
                candidate = getattr(self.stage2_system, name, None)
                if callable(candidate):
                    candidate_name = name
                    break
            
            if candidate:
                # If candidate is a bound sync method, wrap to async thread to avoid blocking
                if not asyncio.iscoroutinefunction(candidate):
                    def _sync_wrapper(signal):
                        return asyncio.to_thread(candidate, signal)
                    self._copy_system_callback = _sync_wrapper
                    logger.warning(f"Callback '{candidate_name}' is synchronous. Wrapped in asyncio.to_thread.")
                else:
                    self._copy_system_callback = candidate

                qualname = getattr(candidate, '__qualname__', str(candidate))
                logger.info(f"COPY_CALLBACK_BOUND: method={qualname}")
                await send_telegram_alert(f"üîó **–°–ò–°–¢–ï–ú–ê –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø –ü–û–î–ö–õ–Æ–ß–ï–ù–ê**\n‚úÖ Callback: {qualname}")

                # If there are pending signals, poke the drainer to start processing
                if not self._copy_signal_buffer.empty():
                    logger.info("Poking buffer drainer to process buffered signals...")
                    self._buffer_drainer_event.set()

                return True
            else:
                self._copy_system_callback = None
                logger.error("‚ùå Could not find a suitable copy system callback method.")
                await send_telegram_alert("‚ùå **–û–®–ò–ë–ö–ê –ò–ù–¢–ï–ì–†–ê–¶–ò–ò**: –ù–µ –Ω–∞–π–¥–µ–Ω –º–µ—Ç–æ–¥ –¥–ª—è callback –≤ Stage-2.")
                return False

    async def _report_system_stats(self):
        """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –æ—Ç—á–µ—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∏–∫—Å–∞—Ö"""
        try:
            # 1. –û–±—ä—è–≤–ª—è–µ–º –∏ –≤—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–æ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            source_stats = self.source_client.get_stats()
            main_stats = self.main_client.get_stats()
            ws_stats = self.websocket_manager.get_stats()
            signal_stats = self.signal_processor.get_stats()
            
            memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            uptime = time.time() - self.start_time
            
            copy_connected = getattr(self.stage2_system, 'copy_connected', False)
            trade_executor_connected = getattr(self.stage2_system, 'trade_executor_connected', False)

            reconcile_now = time.time()
            reconcile_enqueued_minute = len([t for t in self.reconcile_enqueued_last_minute if reconcile_now - t <= 60])

            db_open_positions = len(positions_writer.get_open_positions(TARGET_ACCOUNT_ID))
            exchange_open_positions = len([p for p in await self.main_client.get_positions() if safe_float(p.get('size', 0)) > 0])

            # 2. –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã–≤–æ–¥–∏—Ç—å –ª–æ–≥
            logger.info("=" * 80)
            logger.info("FINAL SYSTEM STATUS REPORT (WITH WEBSOCKET FIXES)")
            logger.info("=" * 80)
            logger.info(f"Uptime: {uptime:.0f}s ({uptime/3600:.1f}h)")
            logger.info(f"Memory usage: {memory_usage:.1f} MB")
            logger.info("")

            logger.info("SYSTEM STATE:")

            # Trailing Stop Status
            trailing_enabled_str = "N/A"
            trailing_mode_str = "N/A"
            if hasattr(self, 'stage2_system') and self.stage2_system and hasattr(self.stage2_system, 'trailing_manager'):
                try:
                    # Use the public method to get a safe snapshot of the config
                    trailing_cfg = self.stage2_system.trailing_manager.get_config_snapshot()
                    trailing_enabled_str = str(trailing_cfg.get('enabled', 'N/A'))
                    trailing_mode_str = str(trailing_cfg.get('mode', 'N/A'))
                except Exception as e:
                    logger.exception("Could not retrieve trailing_manager config for status report: %s", e)
            logger.info(f"  Trailing: enabled={trailing_enabled_str}, mode={trailing_mode_str}")

            logger.info(f"  Copy Connected: {copy_connected}")
            logger.info(f"  Trade Executor Connected: {trade_executor_connected}")
            logger.info(f"  DB Open Positions: {db_open_positions}")
            logger.info(f"  Exchange Open Positions: {exchange_open_positions}")
            logger.info(f"  Reconcile Enqueued (last 1m): {reconcile_enqueued_minute}")
            logger.info("")
            
            logger.info("API CLIENTS:")
            logger.info(f"  Source: {source_stats['success_rate']:.1f}% success, {source_stats['avg_response_time']:.3f}s avg")
            logger.info(f"  Main: {main_stats['success_rate']:.1f}% success, {main_stats['avg_response_time']:.3f}s avg")
            logger.info("")

            logger.info("WEBSOCKET (FINAL FIXED VERSION):")
            logger.info(f"  Status: {ws_stats['status']}")
            logger.info(f"  Open: {ws_stats.get('websocket_open', 'Unknown')}")
            logger.info(f"  Version: websockets {ws_stats.get('websockets_version', 'unknown')}")
            logger.info(f"  Fixes Applied: {ws_stats.get('websocket_fixes_applied', False)} ‚úÖ")
            logger.info(f"  Messages: {ws_stats.get('ws_received_total', 0)} received, {ws_stats.get('ws_processed_private', 0)} processed private")
            logger.info(f"  Ping/Pong: {ws_stats.get('ping_pong_success_rate', 0):.1f}% success rate")
            logger.info(f"  Auto Ping: DISABLED ‚úÖ (Fixed)")
            logger.info(f"  Bybit Ping: ENABLED ‚úÖ (Fixed)")
            logger.info(f"  Connection drops: {ws_stats['connection_drops']}")
            logger.info("")
            
            logger.info("SIGNAL PROCESSING:")
            logger.info(f"  Received: {signal_stats['signals_received']}")
            logger.info(f"  Processed: {signal_stats['signals_processed']}")
            logger.info(f"  Filtered: {signal_stats['signals_filtered']}")
            logger.info(f"  Dropped: {signal_stats['signals_dropped']}")
            logger.info(f"  Queue utilization: {signal_stats.get('queue_utilization_percent', 0):.1f}%")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.exception(f"Stats reporting error: {e}")
    
    async def _memory_management(self):
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é"""
        try:
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            
            if memory_mb > PRODUCTION_CONFIG['max_memory_mb'] * 0.8:  # 80% –æ—Ç –ª–∏–º–∏—Ç–∞
                logger.warning(f"High memory usage: {memory_mb:.1f} MB, running cleanup...")
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞
                gc.collect()
                
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                cutoff_time = time.time() - PRODUCTION_CONFIG['cleanup_interval']
                
                # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã WebSocket (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100)
                while len(self.websocket_manager.message_buffer) > 100:
                    self.websocket_manager.message_buffer.popleft()
                
                # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∑–∏—Ü–∏–π (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 500)
                while len(self.signal_processor.position_history) > 500:
                    self.signal_processor.position_history.popleft()
                
                # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏
                new_memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
                saved_mb = memory_mb - new_memory_mb
                
                logger.info(f"Memory cleanup completed: {new_memory_mb:.1f} MB (saved {saved_mb:.1f} MB)")
                
        except Exception as e:
            logger.error(f"Memory management error: {e}")
    
    async def _escalate_shutdown_after_timeout(self, seconds: int):
        """
        –ü–ª–∞–Ω–æ–≤–∞—è —ç—Å–∫–∞–ª–∞—Ü–∏—è –≤ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–π shutdown, –µ—Å–ª–∏ –∑–∞ –æ—Ç–≤–µ–¥—ë–Ω–Ω–æ–µ –≤—Ä–µ–º—è –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å.
        –û—Ç–º–µ–Ω—è–µ—Ç—Å—è –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º —Ä–µ-–∫–æ–Ω–Ω–µ–∫—Ç–µ.
        """
        try:
            await asyncio.sleep(seconds)
            if getattr(self, "network_supervisor", None):
                allow = await self.network_supervisor.should_allow_shutdown()
                if not allow:
                    logger.warning("Escalation skipped by NetworkSupervisor (recovery in progress)")
                    return
            logger.error(f"No reconnection for {seconds}s ‚Äî escalating to controlled shutdown")
            await self._shutdown(reason=f"escalation_no_recovery_{seconds}s")
        except asyncio.CancelledError:
            # –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª–∏—Å—å —Ä–∞–Ω—å—à–µ ‚Äî —ç—Å–∫–∞–ª–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞
            return

    def _cancel_planned_shutdown(self):
        """–û—Ç–º–µ–Ω—è–µ—Ç –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é —ç—Å–∫–∞–ª–∞—Ü–∏—é shutdown, –µ—Å–ª–∏ —Ç–∞–∫–∞—è –µ—Å—Ç—å."""
        task = self._planned_shutdown_task
        if task and not task.done():
            task.cancel()

    async def _shutdown(self):
        """‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã Stage-1 (c —É—á—ë—Ç–æ–º —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä–∞)"""
        try:
            logger.info("Shutting down Final Trading Monitor System...")

            # 0) –±–æ–ª—å—à–µ –Ω–µ –∞–∫—Ç–∏–≤–Ω—ã ‚Äî –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–∞–º –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è
            self._system_active = False
            self.running = False
            self.should_stop = True

            # 1) –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥/—Ç–∞–π–º–µ—Ä—ã —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä–∞ –¥–æ –∑–∞–∫—Ä—ã—Ç–∏—è –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–æ–≤
            if getattr(self, "network_supervisor", None):
                try:
                    # –º—è–≥–∫–æ –≥–∞—Å–∏–º –µ–≥–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ü–∏–∫–ª—ã, —á—Ç–æ–±—ã –æ–Ω –Ω–µ –≤–º–µ—à–∏–≤–∞–ª—Å—è –≤ –∑–∞–∫—Ä—ã—Ç–∏–µ
                    await self.network_supervisor.stop_monitoring()
                except Exception as e:
                    logger.debug(f"NetworkSupervisor stop_monitoring error (ignored): {e}")

            # 2) –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–∏–≥–Ω–∞–ª–æ–≤
            if hasattr(self, "signal_processor") and self.signal_processor:
                try:
                    await self.signal_processor.stop_processing()
                except Exception as e:
                    logger.debug(f"Signal processor stop failed (ignored): {e}")

            # 3) –ó–∞–∫—Ä—ã–≤–∞–µ–º WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä)
            if hasattr(self, "websocket_manager") and self.websocket_manager:
                try:
                    await self.websocket_manager.close()
                except Exception as e:
                    logger.debug(f"WebSocket manager close failed (ignored): {e}")

            # 4) –û—Ç–º–µ–Ω—è–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ —ç—Ç–æ–≥–æ –º–æ–¥—É–ª—è
            if getattr(self, "active_tasks", None):
                alive = [t for t in list(self.active_tasks) if t and not t.done()]
                if alive:
                    logger.info(f"Cancelling {len(alive)} active tasks...")
                    for task in alive:
                        task.cancel()
                    try:
                        await asyncio.wait_for(
                            asyncio.gather(*alive, return_exceptions=True),
                            timeout=10.0
                        )
                    except asyncio.TimeoutError:
                        logger.warning("Some tasks didn't finish within shutdown timeout")
                self.active_tasks.clear()

            # 5) –û—á–∏—Å—Ç–∫–∞ API-–∫–ª–∏–µ–Ω—Ç–æ–≤ / –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–æ–≤ (aiohttp/httpx –∏ —Ç.–ø.)
            try:
                for client in (getattr(self, "source_client", None),
                               getattr(self, "main_client", None)):
                    if not client:
                        continue
                    if hasattr(client, "cleanup_connections"):
                        await client.cleanup_connections()
                    elif hasattr(client, "cleanup"):
                        res = client.cleanup()
                        if asyncio.iscoroutine(res):
                            await res
            except Exception as e:
                logger.error(f"Error during client cleanup: {e}")

            # 6) –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ ‚Äî –¥–∞—ë–º —Å–µ—Ç–µ–≤—ã–º —Ä–µ—Å—É—Ä—Å–∞–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã—Ç—å—Å—è
            await asyncio.sleep(0.5)

            # 7) –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (best-effort, –º–æ–∂–µ—Ç –Ω–µ –ø—Ä–æ–π—Ç–∏ –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö)
            try:
                await send_telegram_alert(
                    "‚úÖ Final Trading Monitor System stopped gracefully (WebSocket fixes confirmed working)"
                )
            except Exception as e:
                logger.debug(f"Error sending shutdown telegram alert: {e}")

            # 8) –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –æ—Ç–º–µ–Ω–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω—É—é –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é —ç—Å–∫–∞–ª–∞—Ü–∏—é
            try:
                if hasattr(self, "_cancel_planned_shutdown"):
                    self._cancel_planned_shutdown()
            except Exception:
                pass

            logger.info("‚úÖ System shutdown completed successfully")

        except Exception as e:
            logger.error(f"Shutdown error: {e}")
            logger.error(f"Full traceback: {traceback.format_exc()}")

    async def _run_buffer_drainer(self):
        """
        A single, long-running task that drains the _copy_signal_buffer when a
        callback becomes available. It is triggered by an asyncio.Event.
        """
        logger.info("Buffer drainer task started.")
        while True:
            try:
                await self._buffer_drainer_event.wait()

                if not self._copy_system_callback:
                    logger.warning("Drainer woken up, but callback is not available. Clearing event.")
                    self._buffer_drainer_event.clear()
                    continue

                logger.info(f"Draining signal buffer ({self._copy_signal_buffer.qsize()} items)...")
                while not self._copy_signal_buffer.empty():
                    signal = None
                    try:
                        signal = self._copy_signal_buffer.get_nowait()

                        max_retries = 3
                        for attempt in range(max_retries):
                            try:
                                start_time = time.time()
                                await self._copy_system_callback(signal)
                                latency_ms = (time.time() - start_time) * 1000
                                self.metrics['signals_forwarded_total'] += 1
                                logger.info(f"SIG_DRAIN_SUCCESS: symbol={signal.symbol}, latency_ms={latency_ms:.2f}")
                                break # Success
                            except Exception as e:
                                if attempt < max_retries - 1:
                                    delay = 0.5 * (2 ** attempt)
                                    logger.warning(
                                        f"Callback failed for {signal.symbol} (attempt {attempt+1}/{max_retries}). "
                                        f"Retrying in {delay}s. Error: {e}"
                                    )
                                    await asyncio.sleep(delay)
                                else:
                                    raise # Re-raise on final attempt

                        self._copy_signal_buffer.task_done()

                    except Exception as e:
                        if signal:
                            self.metrics['signals_failed_total'] += 1
                            logger.error(f"SIG_DRAIN_FAIL: symbol={signal.symbol} after max retries. Error: {e}", exc_info=True)
                        else:
                            logger.error(f"Buffer drainer error: {e}", exc_info=True)

                logger.info("Signal buffer drain complete.")
                self._buffer_drainer_event.clear()

            except asyncio.CancelledError:
                logger.info("Buffer drainer task cancelled.")
                break
            except Exception as e:
                logger.error(f"Unhandled error in buffer drainer task: {e}", exc_info=True)
                # In case of a major error, wait a bit before retrying to avoid spamming logs
                await asyncio.sleep(5)


# ================================
# ‚úÖ –ê–õ–ò–ê–°–´ –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –° –¢–ï–°–¢–ê–ú–ò
# ================================

# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∞–ª–∏–∞—Å—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏
EnhancedTradingMonitor = FinalTradingMonitor
ProductionTradingMonitor = FinalTradingMonitor
FixedTradingMonitor = FinalTradingMonitor
BybitWebSocketManager = FinalFixedWebSocketManager  
ProductionWebSocketManager = FinalFixedWebSocketManager
FixedWebSocketManager = FinalFixedWebSocketManager
SignalProcessor = ProductionSignalProcessor

# ================================
# ‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –¢–û–ß–ö–ê –í–•–û–î–ê
# ================================

async def main():
    """‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        print("üöÄ –ó–∞–ø—É—Å–∫ Final Trading Monitor System v5.0")
        print("=" * 80)
        print("‚úÖ –û–ö–û–ù–ß–ê–¢–ï–õ–¨–ù–û –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø")
        print("–ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø WEBSOCKET:")
        print("‚úÖ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–´ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–∑ websocket_fixed_functions.py")
        print("‚úÖ –ó–ê–ú–ï–ù–ï–ù–ê —Ñ—É–Ω–∫—Ü–∏—è is_websocket_open() –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤")
        print("‚úÖ –ó–ê–ú–ï–ù–ï–ù–ê —Ñ—É–Ω–∫—Ü–∏—è close_websocket_safely() –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤")
        print("‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û —Å–≤–æ–π—Å—Ç–≤–æ closed –≤ FinalFixedWebSocketManager")
        print("‚úÖ –î–û–ë–ê–í–õ–ï–ù–ê –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è diagnose_websocket_issue()")
        print("‚úÖ ws.state.name = 'OPEN' - –†–ê–ë–û–ß–ò–ô –ú–ï–¢–û–î –¥–ª—è websockets 15.0.1")
        print("‚úÖ ws.closed –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢ –≤ websockets 15.0.1 - –ò–°–ü–†–ê–í–õ–ï–ù–û")
        print("‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢: –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å websockets 15.0.1!")
        print("=" * 80)
        
        # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        monitor = FinalTradingMonitor()
        await monitor.start()

    except KeyboardInterrupt:
        logger.info("System stopped by user")
        print("\nüõë –°–∏—Å—Ç–µ–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    
        # ‚úÖ –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ–º graceful shutdown
        if 'prod_logger' in globals():
            try:
                prod_logger.logger.info("System gracefully stopped by user (Ctrl+C)")
            except:
                pass  # –ù–µ –ª–æ–º–∞–µ–º shutdown –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

    except Exception as e:
        # ‚úÖ –ù–û–í–û–ï: Production Logger –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
        if 'prod_logger' in globals():
            try:
                prod_logger.log_error(e, {
                    'operation': 'system_main_loop',
                    'context': 'critical_system_failure',
                    'component': 'main_application',
                    'error_type': type(e).__name__,
                    'traceback': traceback.format_exc()
                }, send_alert=True)
            except Exception as log_error:
                # Fallback –µ—Å–ª–∏ Production Logger –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
                logger.error(f"Production logger failed: {log_error}")
    
        # ‚úÖ –°–û–•–†–ê–ù–Ø–ï–ú: –°—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∫ fallback
        logger.error(f"Critical system error: {e}")
        logger.error(f"Full traceback: {traceback.format_exc()}")
    
        # ‚úÖ –°–û–•–†–ê–ù–Ø–ï–ú: Telegram alert
        try:
            await send_telegram_alert(f"Critical system error: {e}")
        except Exception as alert_error:
            logger.debug(f"Telegram alert failed: {alert_error}")
    
        # ‚úÖ –°–û–•–†–ê–ù–Ø–ï–ú: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")

if __name__ == "__main__":
    try:
        # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        if sys.platform != 'win32':
            # –ù–∞ Unix —Å–∏—Å—Ç–µ–º–∞—Ö –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–≥–Ω–∞–ª—ã
            asyncio.run(main())
        else:
            # –ù–∞ Windows –∏—Å–ø–æ–ª—å–∑—É–µ–º ProactorEventLoop
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
            asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\nüí• –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã:")
        print("pip install websockets aiohttp psutil")
